#!/usr/bin/python
#
# $Id$
#
# Copyright (C) 2006  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#

from optparse import OptionParser
import math
import matplotlib.cm
import numarray
import sys

from glue import segments
from glue.ligolw import lsctables
from pylal import llwapp
from pylal import rate
from pylal import SnglBurstUtils
from pylal.date import LIGOTimeGPS

__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#

def parse_command_line():
	parser = OptionParser(version="%prog CVS $Id$")
	parser.add_option("-b", "--base", metavar = "base", default = "plotburca_", help = "set the prefix for output filenames (default = plotburca_)")
	parser.add_option("-f", "--format", metavar = "format", default = "png", help = "set the output image format (default = png)")
	parser.add_option("-l", "--live-time-program", metavar = "program", default = "power", help = "set the name, as it appears in the process table, of the program whose search summary entries define the search live time (default = power)")
	parser.add_option("--plot", metavar = "number", action = "append", default = None, help = "only generate the given plot number")
	parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
	options, filenames = parser.parse_args()

	if options.plot:
		options.plot = map(int, options.plot)
	else:
		options.plot = [0, 1, 2, 3, 4, 5, 6]

	return options, (filenames or [None])


#
# =============================================================================
#
#                                    Input
#
# =============================================================================
#

def snglburst_init(self, attrs):
	lsctables.LSCTableUnique.__init__(self, attrs)
	self.rows = {}

def snglburst_append(self, row):
	self.rows[lsctables.ILWDID(row.event_id)] = row
	del row.event_id

def simburst_init(self, attrs):
	lsctables.LSCTableUnique.__init__(self, attrs)
	self.rows = {}

def simburst_append(self, row):
	pass

class CoincMap(object):
	__slots__ = ["sims", "bursts", "coincs"]

	def __init__(self):
		self.sims = []
		self.bursts = []
		self.coincs = []

def coinc_map_init(self, attrs):
	lsctables.LSCTableUnique.__init__(self, attrs)
	self.rows = {}

def coinc_map_append(self, row):
	id = lsctables.ILWDID(row.coinc_event_id)
	if id not in self.rows:
		self.rows[id] = CoincMap()
	if "sim_burst" in row.event_id:
		self.rows[id].sims.append(lsctables.ILWDID(row.event_id))
	elif "sngl_burst" in row.event_id:
		self.rows[id].bursts.append(lsctables.ILWDID(row.event_id))
	elif "coinc_event" in row.event_id:
		self.rows[id].coincs.append(lsctables.ILWDID(row.event_id))
	else:
		raise ValueError, "unrecognized coincident event ID: %s" % str(row.event_id)

def coinc_append(self, row):
	row.coinc_event_id = lsctables.ILWDID(row.coinc_event_id)
	row.time_slide_id = lsctables.ILWDID(row.time_slide_id)
	self.rows.append(row)

def timeslide_init(self, attrs):
	lsctables.LSCTableMulti.__init__(self, attrs)
	self.rows = {}

def timeslide_append(self, row):
	id = lsctables.ILWDID(row.time_slide_id)
	if id in self.rows:
		self.rows[id][row.instrument] = row.offset
	else:
		self.rows[id] = {row.instrument: row.offset}

lsctables.SnglBurstTable.loadcolumns = ["ifo", "central_freq", "confidence", "peak_time", "peak_time_ns", "event_id"]
lsctables.SnglBurstTable.__init__ = snglburst_init
lsctables.SnglBurstTable.append = snglburst_append
lsctables.SimBurstTable.__init__ = simburst_init
lsctables.SimBurstTable.append = simburst_append
lsctables.CoincTable.loadcolumns = ["coinc_event_id", "time_slide_id"]
lsctables.CoincTable.append = coinc_append
lsctables.CoincMapTable.__init__ = coinc_map_init
lsctables.CoincMapTable.append = coinc_map_append
lsctables.TimeSlideTable.__init__ = timeslide_init
lsctables.TimeSlideTable.append = timeslide_append


#
# =============================================================================
#
#                            Document Comprehension
#
# =============================================================================
#

class DocContents(object):
	def __init__(self, xmldoc, live_time_program):
		#
		# Extract tables
		#

		self.coinc_rows = llwapp.get_table(xmldoc, lsctables.CoincTable.tableName).rows
		tisi_rows = llwapp.get_table(xmldoc, lsctables.TimeSlideTable.tableName).rows
		self.tisi_rows = tisi_rows.values()

		#
		# Extract segmentlist dictionary
		#

		self.seglists = llwapp.segmentlistdict_fromsearchsummary(xmldoc, live_time_program)

		#
		# Replace ID attributes of each coinc_event row with
		# references to the corresponding objects in the other
		# tables.
		#

		coinc_map_rows = llwapp.get_table(xmldoc, lsctables.CoincMapTable.tableName).rows
		burst_rows = llwapp.get_table(xmldoc, lsctables.SnglBurstTable.tableName).rows
		i = 0
		while i < len(self.coinc_rows):
			coinc_map = coinc_map_rows[self.coinc_rows[i].coinc_event_id]
			if coinc_map.sims or coinc_map.coincs:
				# not a sngl_burst <--> sngl_burst coinc
				del self.coinc_rows[i]
				continue
			self.coinc_rows[i].coinc_event_id = coinc_map
			self.coinc_rows[i].time_slide_id = tisi_rows[self.coinc_rows[i].time_slide_id]
			coinc_map.bursts = map(burst_rows.__getitem__, coinc_map.bursts)
			i += 1


#
# =============================================================================
#
#                            Coincidence Iterators
#
# =============================================================================
#

def time_slide_is_null(offsetdict):
	"""
	Test for all-zero time slide.
	"""
	for offset in offsetdict.itervalues():
		if offset:
			return False
	return True


def CoincEventIter(doc):
	"""
	Generates a sequence of tuples, one for each coincidence in the
	data set.  The first element of each tuple is the time slide
	dictionary at which the coincidence was found, and the second is a
	list of the sngl_burst events in the coincidence.
	"""
	for row in doc.coinc_rows:
		yield row.time_slide_id, row.coinc_event_id.bursts


def CoincTisiIter(doc):
	"""
	Generates a sequence of time-slide dictionaries, one for each
	coincidence in the data set, indicating the time slide at which the
	corresponding coincidence was found.
	"""
	for row in doc.coinc_rows:
		yield row.time_slide_id


#
# =============================================================================
#
#                                Rate Contours
#
# =============================================================================
#

class RateContours(SnglBurstUtils.BurstPlot):
	def __init__(self, x_instrument, y_instrument, min_delta_t, max_delta_t):
		SnglBurstUtils.BurstPlot.__init__(self, "%s Offset (s)" % x_instrument, "%s Offset (s)" % y_instrument)
		self.fig.set_figsize_inches(16,16)
		self.x_instrument = x_instrument
		self.y_instrument = y_instrument
		self.tisi_rows = None
		self.seglists = None
		self.bins = rate.BinnedRatios(rate.Bins(min_delta_t, max_delta_t, 81, min_delta_t, max_delta_t, 81))

	def add_contents(self, doc):
		if self.tisi_rows == None:
			self.tisi_rows = doc.tisi_rows
		if self.seglists == None:
			self.seglists = doc.seglists
		else:
			for instrument, seglist in doc.seglists.iteritems():
				self.seglists[instrument] |= seglist
		for offsetdict in CoincTisiIter(doc):
			self.bins.incnumerator((offsetdict[self.x_instrument], offsetdict[self.y_instrument]))

	def finish(self):
		for row in self.tisi_rows:
			self.seglists.offsets.update(row)
			self.bins.incdenominator((row[self.x_instrument], row[self.y_instrument]), float(self.seglists.intersection(self.seglists.keys()).duration()))
		self.bins.logregularize()
		zvals = self.bins.ratio()
		rate.filter_array(zvals, rate.gaussian_window2d(8, 8))
		xcoords, ycoords = self.bins.centres()
		self.axes.contour(xcoords, ycoords, numarray.transpose(numarray.log(zvals)))
		for tisi in self.tisi_rows:
			if time_slide_is_null(tisi):
				self.axes.plot((tisi[self.x_instrument],), (tisi[self.y_instrument],), "r+")
			else:
				self.axes.plot((tisi[self.x_instrument],), (tisi[self.y_instrument],), "k+")

		self.axes.set_xlim([self.bins.bins.min[0], self.bins.bins.max[0]])
		self.axes.set_ylim([self.bins.bins.min[1], self.bins.bins.max[1]])
		self.axes.set_title(r"Coincident Event Rate vs. Offset\\(Logarithmic Contours)")


#
# =============================================================================
#
#                              Confidence Scatter
#
# =============================================================================
#

class ConfidenceContours(SnglBurstUtils.BurstPlot):
	def __init__(self, x_instrument, y_instrument, min_confidence, max_confidence):
		SnglBurstUtils.BurstPlot.__init__(self, "%s Confidence" % x_instrument, "%s Confidence" % y_instrument)
		self.fig.set_figsize_inches(16,16)
		self.axes.loglog()

		self.x_instrument = x_instrument
		self.y_instrument = y_instrument
		self.n_foreground = 0
		self.n_background = 0
		self.foreground_bins = rate.BinnedArray(rate.Bins(min_confidence, max_confidence, 1024, min_confidence, max_confidence, 1024, spacing = ["log", "log"]))
		self.background_bins = rate.BinnedArray(rate.Bins(min_confidence, max_confidence, 1024, min_confidence, max_confidence, 1024, spacing = ["log", "log"]))

	def add_contents(self, doc):
		for tisi, bursts in CoincEventIter(doc):
			if time_slide_is_null(tisi):
				self.n_foreground += 1
				for burst in bursts:
					if burst.ifo == self.x_instrument:
						x = -burst.confidence
					elif burst.ifo == self.y_instrument:
						y = -burst.confidence
				self.foreground_bins[x, y] += 1
			else:
				self.n_background += 1
				for burst in bursts:
					if burst.ifo == self.x_instrument:
						x = -burst.confidence
					elif burst.ifo == self.y_instrument:
						y = -burst.confidence
				self.background_bins[x, y] += 1

	def finish(self):
		self.axes.set_title(r"Distribution of Coincident Event Confidence\\(%d Foreground, %d Background Events)" % (self.n_foreground, self.n_background))
		xcoords, ycoords = self.background_bins.centres()

		# prepare the data
		rate.filter_array(self.background_bins.array, rate.gaussian_window2d(8, 8))
		rate.filter_array(self.foreground_bins.array, rate.gaussian_window2d(8, 8))
		self.background_bins.logregularize()
		self.foreground_bins.logregularize()

		# plot background contours
		max_density = math.log(self.background_bins.array.max())
		self.axes.contour(xcoords, ycoords, numarray.transpose(numarray.log(self.background_bins.array)), [max_density - n for n in xrange(0, 10, 1)], cmap = matplotlib.cm.Greys)

		# plot foreground (zero-lag) contours
		max_density = math.log(self.foreground_bins.array.max())
		self.axes.contour(xcoords, ycoords, numarray.transpose(numarray.log(self.foreground_bins.array)), [max_density - n for n in xrange(0, 10, 1)], cmap = matplotlib.cm.Reds)

		self.axes.set_xlim([self.background_bins.bins.min[0], self.background_bins.bins.max[0]])
		self.axes.set_ylim([self.background_bins.bins.min[1], self.background_bins.bins.max[1]])


#
# =============================================================================
#
#                              Delta-t Histogram
#
# =============================================================================
#

class DeltaTHistogram(SnglBurstUtils.BurstPlot):
	def __init__(self, instrument, interval, width):
		SnglBurstUtils.BurstPlot.__init__(self, "Offset (s)", "Events per Unit Offset")
		self.instrument = instrument
		self.n_foreground = 0
		self.n_background = 0
		self.foreground = rate.Rate(interval, width)
		self.background = rate.Rate(interval, width)

	def add_contents(self, doc):
		for tisi, bursts in CoincEventIter(doc):
			if self.instrument not in tisi:
				continue
			# sum = len(bursts) * peak_time for this instrument
			# - sum of peak times of all instruments.  Dividing
			# this by len(bursts) gives the peak time for this
			# instrument - the average of all peak times.  I
			# compute this the way I do to avoid a (very
			# expensive!) LIGOTimeGPS division operation.
			sum = 0
			for burst in bursts:
				peak = burst.get_peak() + tisi[burst.ifo]
				if burst.ifo != self.instrument:
					sum -= peak
				else:
					sum += (len(bursts) - 1) * peak
			if time_slide_is_null(tisi):
				self.n_foreground += 1
				self.foreground[float(sum) / len(bursts)] = 1.0
			else:
				self.n_background += 1
				self.background[float(sum) / len(bursts)] = 1.0

	def finish(self):
		self.axes.set_title(r"%s Peak Time Offset From Coincidence Mean\\(%d Foreground, %d Background Events)" % (self.instrument, self.n_foreground, self.n_background))
		self.axes.plot(self.background.xvals(), self.background.filtered(), "k")
		self.axes.plot(self.foreground.xvals(), self.foreground.filtered(), "r")


#
# =============================================================================
#
#                                     Plot
#
# =============================================================================
#

def new_plots(plots):
	deltat_seg = segments.segment(-0.3, +0.3)
	deltat_width = 0.03125
	l = [
		RateContours("H2", "H1", -100, +100),
		ConfidenceContours("H2", "H1", 30, 10**10),
		ConfidenceContours("H2", "L1", 30, 10**10),
		ConfidenceContours("L1", "H1", 30, 10**10),
		DeltaTHistogram("H1", deltat_seg, deltat_width),
		DeltaTHistogram("H2", deltat_seg, deltat_width),
		DeltaTHistogram("L1", deltat_seg, deltat_width)
	]
	return [l[i] for i in plots]

options, filenames = parse_command_line()

plots = new_plots(options.plot)

for n, filename in enumerate(llwapp.sort_files_by_size(filenames, options.verbose, reverse = True)):
	if options.verbose:
		print >>sys.stderr, "%d/%d:" % (n + 1, len(filenames)),
	if filename[-3:] == ".gz":
		doc = llwapp.load_filename(filename, options.verbose, gz = True)
	else:
		doc = llwapp.load_filename(filename, options.verbose)
	if options.verbose:
		print >>sys.stderr, "indexing..."
	contents = DocContents(doc, options.live_time_program)
	doc.unlink()
	del doc
	for n, plot in enumerate(plots):
		if options.verbose:
			print >>sys.stderr, "adding to plot %d..." % options.plot[n]
		plot.add_contents(contents)


#
# =============================================================================
#
#                                    Output
#
# =============================================================================
#

# delete the plots as we go to save memory
n = 0
format = "%%s%%0%dd.%%s" % (int(math.log10(len(plots))) + 1)
while len(plots):
	filename = format % (options.base, options.plot[n], options.format)
	if options.verbose:
		print >>sys.stderr, "finishing plot %d..." % options.plot[n]
	plots[0].finish()
	if options.verbose:
		print >>sys.stderr, "writing %s..." % filename
	plots[0].fig.savefig(filename)
	del plots[0]
	n += 1
if options.verbose:
	print >>sys.stderr, "done."

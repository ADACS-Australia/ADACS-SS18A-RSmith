#!/usr/bin/python
__author__ = "Ruslan Vaulin <vaulin@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]
__prog__="inspiral_search_summary"
__Id__ = "$Id$"


#loading standard modules
from optparse import *
import glob
import sys
#loading modules used for input/output of data 
from glue import lal
from glue.ligolw import lsctables
from pylal import CoincInspiralUtils
from pylal import SnglInspiralUtils
from pylal import SimInspiralUtils
from pylal import InspiralUtils
from glue.ligolw import ligolw
import numpy
import cPickle

######################################################################################################
# Functions
######################################################################################################
def cumhiststat(zerolag_stats=None, slide_stats=None, min_val = None, \
  max_val = None, nbins = 20, stat=None, scalebkg=False):
  """
  function to plot a cumulative histogram of the snr of coincident events
  in the zero lag and times slides
  
  @param zerolag_stats: array of zero lag statistic
  @param slide_stats: dictionary of time slide statistic
  @param min_val: minimum of snr to be plotted
  @param max_val: maximum of snr to be plotted
  @param nbins: number of bins to use in histogram
  @param stat: the statistic being used
  @param scalebkg: Use this option if plotting playground zero lag against
  full data time slides (it will rescale the time slides).
  """
  internal_min = numpy.inf
  internal_max = -numpy.inf

  if not zerolag_stats == None:
	  internal_max = max(internal_max, zerolag_stats.max())
	  internal_min = min(internal_min, zerolag_stats.min())

  if not slide_stats == None:
	max_slide_stat = 0.0
	min_slide_stat = 0.0
	for key in slide_stats.keys():
	  max_slide_stat = max(max_slide_stat, slide_stats[key].max())
	  min_slide_stat = min(min_slide_stat, slide_stats[key].min())

	internal_max = max(internal_max, max_slide_stat)
	internal_min = min(internal_min, min_slide_stat)

  # set up the bin boundaries
  if not max_val:
    max_val = internal_max
  if not min_val:
    min_val = internal_min

  if min_val >= max_val:
    # CHECKME: what should we do without any trigs or slide_trigs?
    # This is the old behavior.
    min_val = 5.
    max_val = 10.
  if min_val == max_val:
    # NB: this is numpy.histogram's default behavior for equal max and min
    min_val -= 0.5
    max_val += 0.5

  bins = numpy.linspace(min_val, max_val, nbins)

  # hist of the zero lag:
  if not zerolag_stats == None:
    zero_dist, xbin = numpy.histogram(zerolag_stats, bins)
    cum_dist_zero = zero_dist[::-1].cumsum()[::-1]

  # hist of the slides:
  if not slide_stats == None:
    cum_dist_slide = []
    for key in slide_stats.keys():
      num_slide, bin = numpy.histogram(slide_stats[key], bins)
      cum_slide = num_slide[::-1].cumsum()[::-1]
      cum_dist_slide.append(cum_slide)
    cum_dist_slide = numpy.array(cum_dist_slide)
    slide_mean = cum_dist_slide.mean(axis=0)
    slide_std = cum_dist_slide.std(axis=0)
    if scalebkg:
      slide_mean *= 600./6370.
      slide_std *= sqrt(600./6370.)
	  
  if ("bitten_l" in stat) or ("ifar" in stat):
     xvals=bins
  else:
     xvals=bins*bins

  figure()
  
  # plot zero lag
  if not zerolag_stats == None:
    semilogy(xvals,cum_dist_zero+0.0001,'r^',markerfacecolor="b",\
        markersize=12)

  # plot time slides
  if not slide_stats == None:
	ds = (bins[1] - bins[0]) / 2
	slide_min = []
	for i in range( len(slide_mean) ):
	  slide_min.append( max(slide_mean[i] - slide_std[i], 0.0001) )
	  slide_mean[i] = max(slide_mean[i], 0.0001)
	semilogy(xvals,asarray(slide_mean), 'r+', markersize=12)
	tmpx,tmpy = viz.makesteps(bins,slide_min,slide_mean+slide_std)
	if ("bitten_l" in stat) or ('ifar' in stat):
	  p=fill((tmpx-ds),tmpy, facecolor='y')
	else:
	  p=fill((tmpx-ds)*(tmpx-ds),tmpy, facecolor='y')
	setp(p, alpha=0.3)

  if stat == 'coherent_snr': xlab = 'Coherent SNR$^{2}$'
  elif stat == 'ifar': xlab = 'ifar'
  elif stat == 'lvS5stat': xlab = 'ranking statistic'
  elif stat: xlab = 'combined ' + stat.replace('_',' ')
  else: xlab = 'Combined Statistic'
  xlabel(xlab, size='x-large')
  ylabel('Number of events', size='x-large')
  title_text = 'Cum. hist. of num events vs ' + xlab
  title(title_text, size='x-large')





################################################################################
# Main program
################################################################################
usage= """
usage: %prog [options]

This code calculates false alarm probability for N loudest candidates in the search and prints them to a summary html page.
"""
###############################################################################
# Options to read in Input
###############################################################################
def parse_command_line():

  """
  Parser function dedicated
  """

  parser = OptionParser( usage=usage, version="%prog CVS $Id$ " )

  parser.add_option("","--slides-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB time slides files to read" )
	
  parser.add_option("","--zero-lag-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB zero-lag files to read" )
	
  parser.add_option("","--input-cache-file",action="store",type="string",\
      default=None, metavar="ZEROLAGCACHEFILE",help="name of the cache file including the path" )

  parser.add_option("","--slides-pattern",\
      default="", metavar="SLIDESPATTERN", help="the time slides files pattern the cache file, specified by --input-cache-file option, will be seived with.")
	
  parser.add_option("","--zero-lag-pattern",\
      default="", metavar="INJSPATTERN", help="the found injections files pattern the cache file, specified by --input-cache-file option, will be seived with.")

  parser.add_option("","--statistic",action="store",default='snr',\
      type="string",\
      help="choice of statistic used in building coinc table, valid arguments are: snr (DEFAULT), snr_over_chi, s3_snr_chi_stat, effective_snr, bitten_l, bitten_lsq, ifar")
	
  parser.add_option("", "--use-likelihood",action="store_true", default=False,\
      help="enables likelihood to be used as detection statistic")
		
  parser.add_option("","--num-events", action="store",type="int",\
      default = 1, help="number of loudest events to be printed" )
	
  parser.add_option("", "--save-background-stats",action="store_true", default=False,\
      help="save loudest events found in each time slide")
	  
  parser.add_option("","--output-background-file", action="store",type="string",\
      default = None, help="output file for loudest events found in each time slide" )

  parser.add_option("", "--skip-timeslides",action="store_true", default=False,\
      help="skip time slides, use loudest-background-events-file instead.")
	
  parser.add_option("","--loudest-background-stats-file", action="store",type="string",\
      default = None, help="file with loudest events found in each time slide" )
		
  parser.add_option("","--num-slides", action="store",type="int",\
      default = 0, metavar="numslides", help="number of time slides performed, must match the corresponding parameter from the .ini file of the search" )
		
  parser.add_option("","--verbose", action="store_true",\
      default=False, help="print information" )

  parser.add_option("-u","--user-tag",action="store",type="string",\
      default=None, metavar=" USERTAG",\
      help="The user tag used in the name of the figures" )

  
  parser.add_option("-P","--output-path",action="store",\
      type="string",default=None,  metavar="PATH",\
      help="path where the figures would be stored")


  parser.add_option("-O","--enable-output",action="store_true",\
      default="false",  metavar="OUTPUT",\
      help="enable the generation of the html and cache documents")


  parser.add_option("", "--figure-resolution",action="store",type="int",\
      default=50, metavar="FIGURERESOLUTION", \
      help="resolution of the thumbnails (50 by default)" )

  parser.add_option("", "--html-for-cbcweb",action="store",\
      default=False, metavar = "CVS DIRECTORY", help="publish the html "\
      "output in a format that can be directly published on the cbc webpage "\
      "or in CVS. This only works IF --enable-output is also specified. The "\
      "argument should be the cvs directory where the html file will be placed "\
      "Example: --html-for-cbcweb protected/projects/s5/yourprojectdir")


  (opts,args) = parser.parse_args()

  return opts, sys.argv[1:]
#####################################################################
opts, args = parse_command_line()
# Sanity checks
######################################################################

if opts.skip_timeslides and not opts.loudest_background_events_file:
  print >> sys.stderr, "--loudest-background-events-file must be given if --skip-timeslides option is used"
  sys.exit(1)
  
if not opts.skip_timeslides and not opts.num_slides:
  print >> sys.stderr, "number of time slides should be provided if running with time slides triggers,"
  print >> sys.stderr, "use --num-slides option"
  sys.exit(1)
   
  

if not (opts.input_cache_file or opts.slides_glob):
  print >>sys.stderr, "Some of the options specifying the input files containing single inspiral tables are missing." 
  print >> sys.stderr, " Either --input-cache-file or --slides-glob must be given."
  sys.exit(1)
  
# Initializing the html output
InspiralUtils.message(opts, "Initialisation...")
opts = InspiralUtils.initialise(opts, __prog__, __version__)
fnameList = []
tagList = []
fig_num = 0
comments = ""

# Change to Agg back-end if show() will not be called 
# thus avoiding display problem
import matplotlib
matplotlib.use('Agg')
from pylab import *
from pylal import viz

#Calculating statistic for coincidences
statistic = CoincInspiralUtils.coincStatistic(opts.statistic) 

  
# contsructing lists of data files containing time slides and zero-lag triggers respectively
########################################################################################################	
if opts.input_cache_file:
  InspiralUtils.message(opts, "Reading input-cache-file ...")
  slidesfiles = []
  zero_lag_files = []
  SnglInspiralCache = lal.Cache.fromfile(open(opts.input_cache_file))
  if not opts.skip_timeslides:
    slidesfiles = SnglInspiralCache.sieve(description = opts.slides_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
  zero_lag_files = SnglInspiralCache.sieve(description = opts.zero_lag_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
else:
  slidesfiles = []
  zero_lag_files = []
  if not opts.skip_timeslides:
    slidesfiles = glob.glob(opts.slides_glob)
  zero_lag_files = glob.glob(opts.zero_lag_glob)

  
# check if file lists are not empty
if not opts.skip_timeslides:
  if not len(slidesfiles) > 0:
    print >>sys.stderr, "List of time slides files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
    sys.exit(1)
if  not len(zero_lag_files) > 0:
  print >>sys.stderr, "List of zero-lag files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
  sys.exit(1) 


# Finding loudest events in each of the time slides
########################################################################################################################


if not opts.skip_timeslides:
  InspiralUtils.message(opts, "Finding loudest events in each of the time slides ...")

  # define dictionary to hold stats for each time slide
  stats_dic = {}
  for slide in range(1, opts.num_slides + 1):
	stats_dic[slide] = numpy.zeros(1)
	stats_dic[-slide] = numpy.zeros(1)
	
  # define array that stores maximum statistic for each of the time slide
  max_stat_array = numpy.zeros(2*opts.num_slides, dtype = float)

  InspiralUtils.message(opts," reading in time slides ...")
  for file in slidesfiles:
    # read in time slides triggers 
    slidesTriggers = None
    InspiralUtils.message(opts," reading in " + file)
    slidesTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles([file], non_lsc_tables_ok=True)
    InspiralUtils.message(opts,"reconstructing coins ...")
    # construct the time slides coincs
    slidesCoincTriggers = CoincInspiralUtils.coincInspiralTable(slidesTriggers, statistic)

    # read InspiralLikelihoodTable if necessary and add likelihood values to coincs  
    if opts.use_likelihood:
      slidesLikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles([file])
      # add likelihood values to coincs
      inspiral_likelihood.add_likelihood(slidesCoincTriggers, slidesLikelihoodTriggers)       


    for slide in range(1, opts.num_slides + 1):
      #  triggers in each time slide are sorted in descending order in statistic which is passed to an array

      # for slide forward
      # get coincs from the current slide
      forward_slide_coincs = slidesCoincTriggers.getslide(slide)

      # store this slide's maximum statistic
      if len(forward_slide_coincs) > 0:
        if opts.use_likelihood:
		  max_stat_array[slide - 1] = max(max_stat_array[slide - 1], numpy.max(forward_slide_coincs.getlikelihood()))
		  stats_dic[slide] = numpy.append(stats_dic[slide], forward_slide_coincs.getlikelihood())
        else:
		  max_stat_array[slide - 1] = max(max_stat_array[slide - 1], numpy.max(forward_slide_coincs.getstat()))
		  stats_dic[slide] = numpy.append(stats_dic[slide], forward_slide_coincs.getstat())
 	
      # for slide backward
      # get coincs from the current slide
      backward_slide_coincs = slidesCoincTriggers.getslide(-slide)

      # store this slide's  maximum statistic
      if len( backward_slide_coincs) > 0:    
        if opts.use_likelihood:
		  max_stat_array[slide - 1 + opts.num_slides] = max(max_stat_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getlikelihood()))
		  stats_dic[-slide] = numpy.append(stats_dic[-slide], backward_slide_coincs.getlikelihood())
        else:
		  max_stat_array[slide - 1 + opts.num_slides] = max(max_stat_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getstat()))
		  stats_dic[-slide] = numpy.append(stats_dic[-slide], backward_slide_coincs.getstat())


      # end of the loop over slides
  
  # get rid of zeros
  for key in stats_dic.keys():
	stats_dic[key] = numpy.trim_zeros(stats_dic[key])
  
  if opts.save_background_stats:
  
	InspiralUtils.message(opts,"saving max_stat_array into a file ...")
	
	#open output file
	file = open(opts.output_background_file, "w")

	#saving max_stat_array
	cPickle.dump(max_stat_array, file)

	#close file
	file.close()

  InspiralUtils.message(opts, "Done." )
else:
  InspiralUtils.message(opts, "Skiping time slides...")
  InspiralUtils.message(opts, "using max_stat_array from " + str(opts.loudest_background_stats_file))
  
  # open file
  max_stat_file = open(opts.loudest_background_stats_file, "rb")
  
  # get max_stat_array
  max_stat_array = cPickle.load(max_stat_file)


# reading in zero lag files
###########################################################################################################################

#sort background stats
max_stat_array = numpy.sort(max_stat_array)

InspiralUtils.message(opts,"Reading zero-lag files ...")
# read in sngl inspiral table
Triggers = SnglInspiralUtils.ReadSnglInspiralFromFiles(zero_lag_files, mangle_event_id=False, non_lsc_tables_ok=True)

InspiralUtils.message(opts," reconstructing coincs ...")

# construct coincidence 
CoincTriggers = CoincInspiralUtils.coincInspiralTable(Triggers, statistic)

# read InspiralLikelihoodTable if necessary  
if opts.use_likelihood:

  LikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles(zero_lag_files)
  
  # add likelihood values to coincs
  inspiral_likelihood.add_likelihood(CoincTriggers, LikelihoodTriggers)       
    

# making cumulative a plot of cumulative histogram

figure(1)
cumhiststat(CoincTriggers.getstat(), stats_dic, stat=statistic.name)
grid(True)
if opts.enable_output is True:  
  name = "cum_hist_" + statistic.name 
  text = "Cumulative histogram of " + statistic.name + " distribution"
  fname = InspiralUtils.set_figure_name(opts, name)
  fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
  close()
  fnameList.append(fname)
  tagList.append(text)

# making zoomed in cumulative histrogram

rescaled_zerolag_stat = numpy.log(numpy.exp(CoincTriggers.getstat()) - 1.0 + 10**(-20))

rescaled_stats_dic = copy.copy(stats_dic)

for key in rescaled_stats_dic.keys():
  rescaled_stats_dic[key] = numpy.log(numpy.exp(rescaled_stats_dic[key]) - 1.0 + 10**(-20))

figure(2)
cumhiststat(rescaled_zerolag_stat, rescaled_stats_dic, stat=statistic.name)
grid(True)
if opts.enable_output is True:  
  name = "zoomed in cum_hist_" + statistic.name 
  text = " Zoomed in cumulative histogram of " + statistic.name + " distribution"
  fname = InspiralUtils.set_figure_name(opts, name)
  fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
  close()
  fnameList.append(fname)
  tagList.append(text)


# getting N loudest zero-lag candidates
###########################################################################################################################

# sort coincs in descending order according to their statistic
CoincTriggers.sort()

#Make an empty table to put the first N coincs in
loudest_coincs = CoincInspiralUtils.coincInspiralTable(stat = CoincTriggers.stat)
loudest_coincs.extend(CoincTriggers[:opts.num_events])

# For each of the loudest coincs calculate false alarm probability
loudest_coincs.calculate_fap(stats = max_stat_array)

warn_msg = " "

if opts.enable_output is True:
  if opts.verbose: print >> sys.stdout, "Writing html file and cache."
  # make CoincSummTable
  coincTList = []
  commentList = []
  
  coincTList.append(loudest_coincs)
  commentList.append(str(opts.num_events) + ' loudest events of the search ' + 's' )
  coincSumm = InspiralUtils.write_coinc_summ_table(
        tableList = coincTList, commentList = commentList, stat = statistic,
        statTag = opts.statistic, number= opts.num_events, format='html')
  html_filename = InspiralUtils.write_html_output(opts, args, fnameList, tagList, comment=warn_msg,
        CoincSummTable=coincSumm)
  InspiralUtils.write_cache_output(opts, html_filename, fnameList)
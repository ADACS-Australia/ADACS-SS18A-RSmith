#!/usr/bin/python
__author__ = "Ruslan Vaulin <vaulin@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]
__prog__="inspiral_search_summary"
__Id__ = "$Id$"

#loading standard modules
from optparse import *
import glob
import sys
import os
#loading modules used for input/output of data 
from glue import lal
from glue.ligolw import lsctables
from pylal import CoincInspiralUtils
from pylal import SnglInspiralUtils
from pylal import SimInspiralUtils
from pylal import InspiralUtils
from glue.ligolw import ligolw
import numpy
import cPickle

######################################################################################################
# Functions
######################################################################################################
def cumhiststat(zerolag_stats=None, slide_stats=None, min_val = None, \
  max_val = None, nbins = 20, stat=None, scalebkg=False):
  """
  function to plot a cumulative histogram of the snr of coincident events
  in the zero lag and times slides
  
  @param zerolag_stats: array of zero lag statistic
  @param slide_stats: dictionary of time slide statistic
  @param min_val: minimum of snr to be plotted
  @param max_val: maximum of snr to be plotted
  @param nbins: number of bins to use in histogram
  @param stat: the statistic being used
  @param scalebkg: Use this option if plotting playground zero lag against
  full data time slides (it will rescale the time slides).
  """
  internal_min = numpy.inf
  internal_max = -numpy.inf

  if not zerolag_stats == None:
	  internal_max = max(internal_max, zerolag_stats.max())
	  internal_min = min(internal_min, zerolag_stats.min())

  if not slide_stats == None:
	max_slide_stat = 0.0
	min_slide_stat = 0.0
	for key in slide_stats.keys():
	  max_slide_stat = max(max_slide_stat, slide_stats[key].max())
	  min_slide_stat = min(min_slide_stat, slide_stats[key].min())

	internal_max = max(internal_max, max_slide_stat)
	internal_min = min(internal_min, min_slide_stat)

  # set up the bin boundaries
  if not max_val:
    max_val = internal_max
  if not min_val:
    min_val = internal_min

  if min_val >= max_val:
    # CHECKME: what should we do without any trigs or slide_trigs?
    # This is the old behavior.
    min_val = 5.
    max_val = 10.
  if min_val == max_val:
    # NB: this is numpy.histogram's default behavior for equal max and min
    min_val -= 0.5
    max_val += 0.5

  bins = numpy.linspace(min_val, max_val, nbins)

  # hist of the zero lag:
  if not zerolag_stats == None:
    zero_dist, xbin = numpy.histogram(zerolag_stats, bins)
    cum_dist_zero = zero_dist[::-1].cumsum()[::-1]

  # hist of the slides:
  if not slide_stats == None:
    cum_dist_slide = []
    for key in slide_stats.keys():
      num_slide, bin = numpy.histogram(slide_stats[key], bins)
      cum_slide = num_slide[::-1].cumsum()[::-1]
      cum_dist_slide.append(cum_slide)
    cum_dist_slide = numpy.array(cum_dist_slide)
    slide_mean = cum_dist_slide.mean(axis=0)
    slide_std = cum_dist_slide.std(axis=0)
    if scalebkg:
      slide_mean *= 600./6370.
      slide_std *= sqrt(600./6370.)
	  
  if ("bitten_l" in stat) or ("ifar" in stat) or ("lvS5stat" in stat):
     xvals=bins
  else:
     xvals=bins*bins

  figure()
  
  # plot zero lag
  if not zerolag_stats == None:
    semilogy(xvals,cum_dist_zero+0.0001,'r^',markerfacecolor="b",\
        markersize=12)

  # plot time slides
  if not slide_stats == None:
	ds = (bins[1] - bins[0]) / 2
	slide_min = []
	for i in range( len(slide_mean) ):
	  slide_min.append( max(slide_mean[i] - slide_std[i], 0.0001) )
	  slide_mean[i] = max(slide_mean[i], 0.0001)
	semilogy(xvals,asarray(slide_mean), 'r+', markersize=12)
	tmpx,tmpy = viz.makesteps(bins,slide_min,slide_mean+slide_std)
	if ("bitten_l" in stat) or ('ifar' in stat) or ('lvS5stat' in stat):
	  p=fill((tmpx-ds),tmpy, facecolor='y')
	else:
	  p=fill((tmpx-ds)*(tmpx-ds),tmpy, facecolor='y')
	setp(p, alpha=0.3)

  if stat == 'coherent_snr': xlab = 'Coherent SNR$^{2}$'
  elif stat == 'ifar': xlab = 'ifar'
  elif stat == 'lvS5stat': xlab = 'effective likelihood'
  elif stat: xlab = 'combined ' + stat.replace('_',' ')
  else: xlab = 'Combined Statistic'
  xlabel(xlab, size='x-large')
  ylabel('Number of events', size='x-large')
  title_text = 'Cum. hist. of num events vs ' + xlab
  title(title_text, size='x-large')

def writeProcessParams(name, version, command):
  """
  Convert input parameters from the process params that the code was called 
  with into a formatted string that can be saved within an other document 
  (e.g., HTML)

  @param name: name of the executable/script
  @param version:version of the executable/script
  @param command: command line arguments from a pylal script
  @return text
  """
  text = "Figure(s) produced with " + name + ", " \
      + version + ", invoked with the following command line arguments:" \
      + '<br>\n<p style="width:80%; color:blue">'+ name
  for arg in command:
    text += " " +  arg
  text+='</p>'

  return text

def write_cache_output(opts, html_filename,fnameList):
  """
  write the output cache file of theplotting functions
  """

  output_cache_name = opts.prefix + opts.suffix +'.cache'
  if opts.output_path:
    output_cache_name = opts.output_path + output_cache_name
  this = open(output_cache_name, 'w')
  if opts.enable_output is True:
    this.write(os.path.basename(html_filename) + '\n')
  for filename in fnameList:
    if str(filename).endswith('.png'):
      fname = "Images/"+os.path.basename(filename) # set the correct name for linking
    elif str(filename).endswith('.html'):
      fname = os.path.basename(str(filename)) # set the correct name for linking
    this.write(fname + '\n')
  this.close()

################################################################################
# Main program
################################################################################
usage= """
usage: %prog [options]

This code calculates false alarm probability for N loudest candidates in the search and prints them to a summary html page.
"""
###############################################################################
# Options to read in Input
###############################################################################
def parse_command_line():

  """
  Parser function dedicated
  """

  parser = OptionParser( usage=usage, version="%prog CVS $Id$ " )

  parser.add_option("","--slides-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB time slides files to read" )
	
  parser.add_option("","--zero-lag-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB zero-lag files to read" )

  parser.add_option("","--no-bg-zero-lag-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB no background zero lag files to read")
	
  parser.add_option("","--input-cache-file",action="store",type="string",\
      default=None, metavar="ZEROLAGCACHEFILE",help="name of the cache file including the path" )

  parser.add_option("","--slides-pattern",\
      default="", metavar="SLIDESPATTERN", help="the time slides files pattern the cache file, specified by --input-cache-file option, will be seived with.")
	
  parser.add_option("","--zero-lag-pattern",\
      default="", metavar="ZEROLAGPATTERN", help="the zero lag files pattern the cache file, specified by --input-cache-file option, will be seived with.")

  parser.add_option("","--no-bg-zero-lag-pattern",\
      default="", metavar="NO_BG_ZERO_LAG_PATTERN", help="the zero lag with no background files pattern the cache file, specified by"\
      " --input-cache-file option, will be seived with.")

  parser.add_option("","--statistic",action="store",default='snr',\
      type="string",\
      help="choice of statistic used in building coinc table, valid arguments are: snr (DEFAULT), snr_over_chi, s3_snr_chi_stat, effective_snr, bitten_l, bitten_lsq, ifar")
	
  parser.add_option("", "--use-likelihood",action="store_true", default=False,\
      help="enables likelihood to be used as detection statistic")

  parser.add_option("","--make_zoomed_histogram",action="store_true", default=False,\
      help="Make a zoomed-in histogram plot")
		
  parser.add_option("","--num-events", action="store",type="int",\
      default = 1, help="number of loudest events to be printed" )
	
  parser.add_option("", "--save-background-stats",action="store_true", default=False,\
      help="save loudest events found in each time slide")
	  
  parser.add_option("","--output-background-file", action="store",type="string",\
      default = None, help="output file for loudest events found in each time slide" )

  parser.add_option("", "--skip-timeslides",action="store_true", default=False,\
      help="skip time slides, use loudest-background-events-file instead.")
	
  parser.add_option("","--loudest-background-stats-file", action="store",type="string",\
      default = None, help="file with loudest events found in each time slide" )
		
  parser.add_option("","--num-slides", action="store",type="int",\
      default = 0, metavar="numslides", help="number of time slides performed, must match the corresponding parameter from the .ini file of the search" )
		
  parser.add_option("","--verbose", action="store_true",\
      default=False, help="print information" )

  parser.add_option("-u","--user-tag",action="store",type="string",\
      default=None, metavar=" USERTAG",\
      help="The user tag used in the name of the figures" )

  parser.add_option("-Z","--zero-lag-playground",action="store_true",\
      default=False,\
      help="scale number of bkg triggers in slide plots by 600/6370")
  
  parser.add_option("-P","--output-path",action="store",\
      type="string",default=None,  metavar="PATH",\
      help="path where the figures would be stored")


  parser.add_option("-O","--enable-output",action="store_true",\
      default="false",  metavar="OUTPUT",\
      help="enable the generation of the html and cache documents")


  parser.add_option("", "--figure-resolution",action="store",type="int",\
      default=50, metavar="FIGURERESOLUTION", \
      help="resolution of the thumbnails (50 by default)" )

  parser.add_option("", "--html-for-cbcweb",action="store",\
      default=False, metavar = "CVS DIRECTORY", help="publish the html "\
      "output in a format that can be directly published on the cbc webpage "\
      "or in CVS. This only works IF --enable-output is also specified. The "\
      "argument should be the cvs directory where the html file will be placed "\
      "Example: --html-for-cbcweb protected/projects/s5/yourprojectdir")


  (opts,args) = parser.parse_args()

  return opts, sys.argv[1:]
#####################################################################
opts, args = parse_command_line()


def init_markup_page( opts):
  """
  Load the markup module, and initialise the HTML document if the opts 
  argument contains enable_ouput option.

  @param  opts : the user arguments 
  @return page 
  @return extra 
  """
  # Initialise the html output file
  if opts.enable_output is True:
    try:
      from glue import markup
      from glue.markup import oneliner as extra_oneliner
    except:
      raise ImportError("Require markup.py to generate the html page")

    page = markup.page()
    try:
      page.init(title=__title__)
    except:
      page.init()

  return page, extra_oneliner


# Sanity checks
######################################################################

if opts.skip_timeslides and not opts.loudest_background_events_file:
  print >> sys.stderr, "--loudest-background-events-file must be given if --skip-timeslides option is used"
  sys.exit(1)
  
if not opts.skip_timeslides and not opts.num_slides:
  print >> sys.stderr, "number of time slides should be provided if running with time slides triggers,"
  print >> sys.stderr, "use --num-slides option"
  sys.exit(1)
   
  

if not (opts.input_cache_file or opts.slides_glob):
  print >>sys.stderr, "Some of the options specifying the input files containing single inspiral tables are missing." 
  print >> sys.stderr, " Either --input-cache-file or --slides-glob must be given."
  sys.exit(1)
  
# Initializing the html output
InspiralUtils.message(opts, "Initialisation...")
opts = InspiralUtils.initialise(opts, __prog__, __version__)
fnameList = []
tagList = []
fig_num = 0
comments = ""

# Change to Agg back-end if show() will not be called 
# thus avoiding display problem
import matplotlib
matplotlib.use('Agg')
from pylab import *
from pylal import viz

#Calculating statistic for coincidences
statistic = CoincInspiralUtils.coincStatistic(opts.statistic) 

  
# contsructing lists of data files containing time slides and zero-lag triggers respectively
########################################################################################################	
if opts.input_cache_file:
  InspiralUtils.message(opts, "Reading input-cache-file ...")
  slidesfiles = []
  zero_lag_files = []
  no_bg_zero_lag_files = []
  SnglInspiralCache = lal.Cache.fromfile(open(opts.input_cache_file))
  if not opts.skip_timeslides:
    slidesfiles = SnglInspiralCache.sieve(description = opts.slides_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
  zero_lag_files = SnglInspiralCache.sieve(description = opts.zero_lag_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
  no_bg_zero_lag_files = SnglInspiralCache.sieve(description = opts.no_bg_zero_lag_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
else:
  slidesfiles = []
  zero_lag_files = []
  no_bg_zero_lag_files = []
  if not opts.skip_timeslides:
    slidesfiles = glob.glob(opts.slides_glob)
  zero_lag_files = glob.glob(opts.zero_lag_glob)
  no_bg_zero_lag_files = glob.glob(opts.no_bg_zero_lag_glob)
  
# check if file lists are not empty
if not opts.skip_timeslides:
  if not len(slidesfiles) > 0:
    print >>sys.stderr, "List of time slides files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
    sys.exit(1)
if  not len(zero_lag_files) > 0:
  print >>sys.stderr, "List of zero-lag files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
if  not len(no_bg_zero_lag_files) > 0:
  print >>sys.stderr, "List of no-bg-zero-lag files is empty: your sieve (glob) pattern may be wrong or files do not exist in the location given by the cache file"
  sys.exit(1) 


# Finding loudest events in each of the time slides
########################################################################################################################


if not opts.skip_timeslides:
  InspiralUtils.message(opts, "Finding loudest events in each of the time slides ...")

  # define dictionary to hold stats for each time slide
  stats_dic = {}
  for slide in range(1, opts.num_slides + 1):
	stats_dic[slide] = numpy.zeros(1)
	stats_dic[-slide] = numpy.zeros(1)
	
  # define array that stores maximum statistic for each of the time slide
  max_stat_array = numpy.zeros(2*opts.num_slides, dtype = float)

  InspiralUtils.message(opts," reading in time slides ...")
  for file in slidesfiles:
    # read in time slides triggers 
    slidesTriggers = None
    InspiralUtils.message(opts," reading in " + file)
    slidesTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles([file], non_lsc_tables_ok=True)
    InspiralUtils.message(opts,"reconstructing coincs ...")
    # construct the time slides coincs
    slidesCoincTriggers = CoincInspiralUtils.coincInspiralTable(slidesTriggers, statistic)

    # read InspiralLikelihoodTable if necessary and add likelihood values to coincs  
    if opts.use_likelihood:
      slidesLikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles([file])
      # add likelihood values to coincs
      inspiral_likelihood.add_likelihood(slidesCoincTriggers, slidesLikelihoodTriggers)       


    for slide in range(1, opts.num_slides + 1):
      #  triggers in each time slide are sorted in descending order in statistic which is passed to an array

      # for slide forward
      # get coincs from the current slide
      forward_slide_coincs = slidesCoincTriggers.getslide(slide)

      # store this slide's maximum statistic
      if len(forward_slide_coincs) > 0:
        if opts.use_likelihood:
		  max_stat_array[slide - 1] = max(max_stat_array[slide - 1], numpy.max(forward_slide_coincs.getlikelihood()))
		  stats_dic[slide] = numpy.append(stats_dic[slide], forward_slide_coincs.getlikelihood())
        else:
		  max_stat_array[slide - 1] = max(max_stat_array[slide - 1], numpy.max(forward_slide_coincs.getstat()))
		  stats_dic[slide] = numpy.append(stats_dic[slide], forward_slide_coincs.getstat())
 	
      # for slide backward
      # get coincs from the current slide
      backward_slide_coincs = slidesCoincTriggers.getslide(-slide)

      # store this slide's  maximum statistic
      if len( backward_slide_coincs) > 0:    
        if opts.use_likelihood:
		  max_stat_array[slide - 1 + opts.num_slides] = max(max_stat_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getlikelihood()))
		  stats_dic[-slide] = numpy.append(stats_dic[-slide], backward_slide_coincs.getlikelihood())
        else:
		  max_stat_array[slide - 1 + opts.num_slides] = max(max_stat_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getstat()))
		  stats_dic[-slide] = numpy.append(stats_dic[-slide], backward_slide_coincs.getstat())


      # end of the loop over slides
  
  # get rid of zeros
  for key in stats_dic.keys():
	stats_dic[key] = numpy.trim_zeros(stats_dic[key])
  
  if opts.save_background_stats:
  
	InspiralUtils.message(opts,"saving max_stat_array into a file ...")
	
	#open output file
	file = open(opts.output_background_file, "w")

	#saving max_stat_array
	cPickle.dump(max_stat_array, file)

	#close file
	file.close()

  InspiralUtils.message(opts, "Done." )
else:
  InspiralUtils.message(opts, "Skiping time slides...")
  InspiralUtils.message(opts, "using max_stat_array from " + str(opts.loudest_background_stats_file))
  
  # open file
  max_stat_file = open(opts.loudest_background_stats_file, "rb")
  
  # get max_stat_array
  max_stat_array = cPickle.load(max_stat_file)


# reading in zero lag files
###########################################################################################################################

#sort background stats
max_stat_array = numpy.sort(max_stat_array)

InspiralUtils.message(opts,"Reading zero-lag files ...")
# read in sngl inspiral table
Triggers = SnglInspiralUtils.ReadSnglInspiralFromFiles(zero_lag_files, mangle_event_id=False, non_lsc_tables_ok=True)
NoBgTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles(no_bg_zero_lag_files, mangle_event_id=False, non_lsc_tables_ok=True)

InspiralUtils.message(opts," reconstructing coincs ...")

# construct coincidence 
CoincTriggers = CoincInspiralUtils.coincInspiralTable(Triggers, statistic)
NoBgCoincTriggers = CoincInspiralUtils.coincInspiralTable(NoBgTriggers, statistic)

# read InspiralLikelihoodTable if necessary  
if opts.use_likelihood:

  LikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles(zero_lag_files)
  NoBgLikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles(no_bg_zero_lag_files) 
 
  # add likelihood values to coincs
  inspiral_likelihood.add_likelihood(CoincTriggers, LikelihoodTriggers)       
  inspiral_likelihood.add_likeliihood(NoBgCoincTriggers, NoBgLikelihoodTriggers) 

# making cumulative a plot of cumulative histogram

figure(1)
cumhiststat(CoincTriggers.getstat(), stats_dic, stat=statistic.name, scalebkg=opts.zero_lag_playground)
grid(True)
if opts.enable_output is True:  
  name = "cum_hist_" + statistic.name 
  text = "Cumulative histogram of " + statistic.name + " distribution"
  fname = InspiralUtils.set_figure_name(opts, name)
  fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
  close()
  fnameList.append(fname)
  tagList.append(text)

# make a zoomed-in cumulative histogram
if opts.make_zoomed_histogram:

  rescaled_zerolag_stat = numpy.log(numpy.exp(CoincTriggers.getstat()) - 1.0 + 10**(-10))

  rescaled_stats_dic = copy.copy(stats_dic)

  for key in rescaled_stats_dic.keys():
    rescaled_stats_dic[key] = numpy.log(numpy.exp(rescaled_stats_dic[key]) - 1.0 + 10**(-10))

  figure(2)
  cumhiststat(rescaled_zerolag_stat, rescaled_stats_dic, stat=statistic.name, scalebkg=opts.zero_lag_playground)
  grid(True)
  if opts.enable_output is True:  
    name = "zoomed in cum_hist_" + statistic.name 
    text = " Zoomed in cumulative histogram of " + statistic.name + " distribution"
    fname = InspiralUtils.set_figure_name(opts, name)
    fname_thumb = InspiralUtils.savefig_pylal( filename=fname )
    close()
    fnameList.append(fname)
    tagList.append(text)


# getting N loudest zero-lag candidates
###########################################################################################################################

# sort coincs in descending order according to their statistic
CoincTriggers.sort()
NoBgCoincTriggers.sort()

#Make an empty table to put the first N coincs in
loudest_coincs = CoincInspiralUtils.coincInspiralTable(stat = CoincTriggers.stat)
loudest_coincs.extend(CoincTriggers[:opts.num_events])

# For each of the loudest coincs calculate false alarm probability
loudest_coincs.calculate_fap(stats = max_stat_array)

# For each of the no_bg loudest coincs, set the fap to 0 (since the beta column contains the efficiency factor)
for coinc in NoBgCoincTriggers:
  coinc.fap = 0.0

if opts.enable_output is True:
  if opts.verbose: print >> sys.stdout, "Writing html file and cache."

  coincTList = []
  nobgcoincTList = []

  commentList = []
  nobgcommentList = []
  
  coincTList.append(loudest_coincs)
  nobgcoincTList.append(NoBgCoincTriggers)
  
  commentList.append(str(opts.num_events) + ' loudest events of the search ' )
  nobgcommentList.append('Loudest events of the search that have no estimated background because they are louder than all time slides in their category' )

  # MAKE THE SUMMARY TABLE
  coincSumm = InspiralUtils.write_coinc_summ_table(
        tableList = coincTList, commentList = commentList, stat = statistic,
        statTag = opts.statistic, number= opts.num_events, format='html')

  # MAKE THE NO_BACKGROUND SUMMARY TABLE (LABEL THE STATISTIC EFFICIENCY)
  nobgcoincSumm = InspiralUtils.write_coinc_summ_table(
        tableList = nobgcoincTList, commentList = nobgcommentList, stat = statistic,
        statTag = 'Efficiency Factor', number= opts.num_events, format='html')

  page, extra = init_markup_page(opts)
  page.h1("Summary of Loudest Events")
  page.hr()
  html_filename = opts.output_path + "/loudesteventsummary.html"
  html_file = open(html_filename,"w")
 
  for tag,filename in zip(tagList,fnameList):
    fname = "Images/" + os.path.basename(filename)
    fname_thumb = fname[:-4] + "_thumb.png"
    page.a(extra.img(src=[fname_thumb], width=400, \
        alt=tag, border="2"), title=tag, href=[ fname])

  page.add("<hr/>")
  page.add(coincSumm)
  page.add(nobgcoincSumm)
  page.hr()
  text = writeProcessParams( opts.name, opts.version,  args)
  page.add(text)
  html_file.write(page(False))
  html_file.close()

  write_cache_output(opts, html_filename, fnameList)




#!/usr/bin/python

# =============================================================================
# Preamble
# =============================================================================

from __future__ import division

import os,sys,glob,numpy
from optparse import OptionParser
from pylal import MultiInspiralUtils
from glue.ligolw import table,lsctables,utils,ligolw,ilwd
from glue import segments,lal
from pylal.coh_PTF_pyutils import *
from math import pi
from glue import git_version

__author__  = "Ian Harry <ian.harry@astro.cf.ac.uk>"
__version__ = "git id %s" % git_version.id
__date__    = git_version.date

# =============================================================================
# Parse command line
# =============================================================================

def parse_command_line():

  usage = """usage: %prog [options] 

coh_PTF_trig_combiner is designed to coalesce the triggers made from each element of the split template bank used by the search. The required arguments are

--ifo-tag
--user-tag
--cache
"""

  parser = OptionParser( usage )

  parser.add_option( "-i", "--ifo-tag", action="store", type="string",\
                     default=None,\
                     help="The ifo tag, H1L1 or H1L1V1 for instance" )

  parser.add_option( "-u", "--user-tag", action="store", type="string",\
                     default='COH_PTF_INSPIRAL_FIRST',\
                     help="The user tag, COH_PTF_INSPIRAL_FIRST for instance" )

  parser.add_option( "-n", "--grb-name", action="store", type="string",\
                     default=None, help="GRB name, such as 090802 "+\
                                        "(will be appended to output user tag" )

  parser.add_option( "-T", "--num-trials", action="store", type="int",\
                     default=6,\
                     help="The number of off source trials, default: %default" )

  parser.add_option( "-a", "--segment-dir", action="store", type="string",\
                     help="directory holding buffer, on and off source "+\
                          "segment files." )

  parser.add_option( "-o", "--output-dir", action="store", type="string",\
                     default=os.getcwd(), help="output directory, "+\
                                               "default: %default" )

  parser.add_option( "-v", "--verbose", action="store_true", default=False,\
                     help="verbose output, default: %default" )

  parser.add_option( "-c", "--cache", action="store", type="string",\
                     default=None, help="read trigger files from this cache." )

  (opts,args) = parser.parse_args()

  if not opts.ifo_tag:
    parser.error( "must provide --ifo-tag" )

  if not opts.user_tag:
    parser.error( "must provide --user-tag" )

  if not opts.cache:
    parser.error( "must provide --cache" )

  if not opts.segment_dir:
    parser.error( "must provide --segment-dir" )

  return opts,args

# =============================================================================
# Main function
# =============================================================================

def main( cacheFile, ifoTag, userTag, segdir, outdir, grbTag=None, numTrials=6,\
          verbose=False ):

  if verbose:
    print >>sys.stdout, 'Getting segments...'

  # get segments
  lostTime       = 71
  segs           = readSegFiles(segdir)
  trialTime      = abs( segs['on'] )
  
  # construct off source trials
  offSourceSegs  = segments.segmentlist()
  offSourceSegs.append( segs['off'] )
  offSourceSegs.append( segments.segment( segs['off'][0]+lostTime,\
                                          segs['off'][0]+lostTime+trialTime ) )
  for i in xrange(numTrials-1):
    t = i+2
    offSourceSegs.append(segments.segment(tuple( map( trialTime.__add__,\
                                                      offSourceSegs[t-1]) )))
 
  if verbose:
    print >>sys.stdout, 'Constructed %d off source trials with segments:'\
                        % numTrials
    for i in xrange(numTrials):
      print >>sys.stdout, offSourceSegs[i+1]

  # get trigger files 
  if verbose:
    print >>sys.stdout
    print >>sys.stdout, 'Finding files...'

  cache = lal.Cache.fromfile(open( cacheFile, 'r' ))
  cache = cache.sieve( ifos=ifoTag, description=userTag )

  if len(cache)<1:
    print >>sys.stderr, 'No files found.'
    sys.exit(1)
 
  # prepare triggers
  trigs = {}
 
  if verbose:
    print >>sys.stdout
    print >>sys.stdout, 'Loading all triggers...'

  # load triggers
  trigs['ALL_TIMES'] =\
      MultiInspiralUtils.ReadMultiInspiralFromFiles([ e.path() for e in cache ])
  # Temporary hack to allow the code to work with tables that dont have
  # the new time slide ID column.
  if 'time_slide_id' not in trigs['ALL_TIMES'].columnnames:
    trigs['ALL_TIMES'].appendColumn('time_slide_id')
  for trig in trigs['ALL_TIMES']:
    try:
      tmp = trig.time_slide_id
    except AttributeError:
      trig.time_slide_id = ilwd.get_ilwdchar("multi_inspiral:time_slide_id:0")
  trigs['ONSOURCE'] = lsctables.New(lsctables.MultiInspiralTable)
  trigs['OFFSOURCE'] = lsctables.New(lsctables.MultiInspiralTable)
  for i in range(numTrials):
    trigs['OFFTRIAL_%d' % (i+1)] = lsctables.New(lsctables.MultiInspiralTable)

  if verbose:
    print >>sys.stdout
    print >>sys.stdout, 'Separating triggers by end time...'

  # separate into correct bins
  for trig in trigs['ALL_TIMES']:
    if trig.get_end() not in segs['buffer']:
      trigs['OFFSOURCE'].append(trig)
    elif trig.get_end() in segs['on']:
      trigs['ONSOURCE'].append(trig)
    for i in xrange(numTrials):
      if trig.get_end() in offSourceSegs[i+1]:
        trigs['OFFTRIAL_%d' % (i+1)].append(trig)
        break

  if verbose:
    print >>sys.stdout
    print >>sys.stdout, 'Writing new xml files...'

  # prepare xmldocument 
  xmldoc = ligolw.Document()
  xmldoc.appendChild(ligolw.LIGO_LW())

  # append process params table
  xmldoc = append_process_params( xmldoc, sys.argv, __version__, __date__ )
 
  # get search summary table from old file
  oldxml   = utils.load_filename( cache[0].path(),\
                                  gz = cache[0].path().endswith("gz") )
  oldSearchSummTable = table.get_table( oldxml, "search_summary" )
  xmldoc.childNodes[-1].appendChild( oldSearchSummTable )

  # construct new xml file names
  allsegs = cache.to_segmentlistdict()[ifoTag].coalesce()
  allsegs.sort(key=lambda seg: (seg[0],seg[1]) )
  start   = allsegs[0][0]
  end     = allsegs[-1][-1]
  if grbTag:
    userTag = '%s_GRB%s' % ( userTag, grbTag )

  # write new xml files
  for trigTime in trigs.keys():
    xmlName = '%s/%s-%s_%s-%d-%d.xml.gz'\
              % ( outdir, ifoTag, userTag, trigTime, start, end-start )
    xmldoc.childNodes[-1].appendChild( trigs[trigTime] )
    utils.write_filename( xmldoc, xmlName, gz = xmlName.endswith('gz') )
    xmldoc.childNodes[-1].removeChild( trigs[trigTime] ) 
    if verbose: 
      print >>sys.stdout, xmlName

if __name__=='__main__':

  opts, args = parse_command_line()

  outdir    = os.path.abspath( opts.output_dir )
  segdir    = os.path.abspath( opts.segment_dir )
  ifoTag    = opts.ifo_tag
  userTag   = opts.user_tag
  cacheFile = opts.cache
  GRBname   = opts.grb_name
  numTrials = opts.num_trials
  verbose   = opts.verbose

  main( cacheFile, ifoTag, userTag, segdir, outdir,\
        grbTag=GRBname, numTrials=numTrials, verbose=verbose )

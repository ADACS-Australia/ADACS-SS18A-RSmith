#!/usr/bin/python
#
# Copyright (C) 2006  Kipp Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#

"""
LIGO Light Weight XML search summary table chunker.  Split LIGO
Light-Weight XML files into smaller files, each spanning an amount of time
not less than a given amount, by extracting data from the input files by
process.
"""

from optparse import OptionParser
import os
import sys

from glue.lal import CacheEntry
from glue import segments
from glue.ligolw import ligolw
from glue.ligolw import lsctables
from glue.ligolw import utils
from pylal import git_version

lsctables.use_in(ligolw.LIGOLWContentHandler)

__author__ = "Kipp Cannon <kipp.cannon@ligo.org>"
__version__ = "git id %s" % git_version.id
__date__ = git_version.date


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#

def parse_command_line():
	parser = OptionParser(
		version = "Name: %%prog\n%s" % git_version.verbose_msg
	)
	parser.add_option("-b", "--base", metavar = "base", default = "sschunk", help = "set base for output files (default = \"sschunk\")")
	parser.add_option("--cache-comment", metavar = "comment", help = "set comment for cache output")
	parser.add_option("--cache-instrument", metavar = "instrument", help = "set instrument for cache output")
	parser.add_option("-d", "--duration", metavar = "seconds", default = 3600, type = "int", help = "set target duration (default = 3600 s)")
	parser.add_option("-r", "--remove-input", action = "store_true", help = "remove input files when done")
	parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
	parser.add_option("-w", "--write-cache", metavar = "path", help = "write a LAL cache of the output files to path")
	options, filenames = parser.parse_args()

	if options.write_cache and not (options.cache_comment and options.cache_instrument):
		raise ValueError("must set both --cache-comment and --cache-instrument when writing a cache file")

	return options, (filenames or [None])

options, filenames = parse_command_line()


#
# =============================================================================
#
#                                 Preparation
#
# =============================================================================
#

def build_id_seglist_pairs(doc):
	"""
	Construct a list of process_id, segment list pairs sorted by
	segment list start time.
	"""
	if options.verbose:
		print >>sys.stderr, "extracting and indexing search summary table..."
	seglists = segments.segmentlistdict()
	for row in lsctables.table.get_table(doc, lsctables.SearchSummaryTable.tableName):
		if row.process_id not in seglists:
			seglists[row.process_id] = segments.segmentlist()
		seglists[row.process_id].append(row.get_out())
	pairs = seglists.coalesce().items()
	pairs.sort(lambda a, b: cmp(a[1].extent(), b[1].extent()))
	return pairs


#
# =============================================================================
#
#                                   Chunking
#
# =============================================================================
#

class Chunk(object):
	def __init__(self):
		self.doc = ligolw.Document()
		self.doc.appendChild(ligolw.LIGO_LW())
		self.seglist = segments.segmentlist()

	def addtable(self, template):
		try:
			table_elem = lsctables.table.get_table(self.doc, template.tableName)
		except:
			table_elem = self.doc.childNodes[0].appendChild(lsctables.table.new_from_template(template))
		return table_elem


def chunk_document(doc, verbose = False):
	chunk = Chunk()
	for process_id, seglist in build_id_seglist_pairs(doc):
		if verbose:
			print >>sys.stderr, "extracting %s (duration = %f)..." % (process_id, float(abs(seglist)))
		chunk.seglist |= seglist
		for source in doc.getElementsByTagName(ligolw.Table.tagName):
			try:
				source.getColumnByName("process_id")
			except:
				raise ValueError, "table %s has no process_id column" % source.tableName
			dest = chunk.addtable(source)
			for row in source:
				if row.process_id == process_id:
					dest.append(row)
		if abs(chunk.seglist) > options.duration:
			yield chunk.doc, chunk.seglist
			chunk = Chunk()
	if abs(chunk.seglist):
		yield chunk.doc, chunk.seglist


#
# =============================================================================
#
#                                 Library API
#
# =============================================================================
#

def write_sschunks(doc, **kwargs):
	"""
	Write the XML tree in doc to a sequence of files of approximately
	some given duration, according to the process descriptions in the
	search summary table.
	"""
	cache = ""
	for chunk, seglist in chunk_document(doc, verbose = kwargs["verbose"]):
		segment = seglist.extent()
		chunkname = "%s-%d-%d.xml" % (kwargs["base"], int(segment[0]), int(abs(segment)))
		utils.write_filename(chunk, chunkname, gz = (chunkname or "stdout").endswith(".gz"), verbose = kwargs["verbose"])
		if kwargs["write_cache"]:
			cache += "%s\n" % str(CacheEntry(kwargs["cache_instrument"], kwargs["cache_comment"], segment, "file://localhost%s" % os.path.abspath(chunkname)))
	return cache


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#

cache = ""
for filename in filenames:
	doc = utils.load_filename(filename, verbose = options.verbose, contenthandler = ligolw.LIGOLWContentHandler)
	cache += write_sschunks(doc, **options.__dict__)
	doc.unlink()
	if filename and options.remove_input:
		if options.verbose:
			print >>sys.stderr, "removing %s..." % filename
		os.remove(filename)
if options.write_cache:
	if options.verbose:
		print >>sys.stderr, "writing %s..." % options.write_cache
	file(options.write_cache, "w").write(cache)


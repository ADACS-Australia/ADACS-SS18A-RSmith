#!/usr/bin/python

from optparse import OptionParser

try:
        import sqlite3
except ImportError:
        # pre 2.5.x
        from pysqlite2 import dbapi2 as sqlite3
import sys, os, re, string, tempfile, copy
import ConfigParser

from glue import segments
from glue import segmentsUtils
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw import utils
from glue import pipeline
from pylal import db_thinca_rings
from pylal import stfu_pipe
from lalapps import inspiral

#from pylal.fu_Condor import *
from pylal.xlal.datatypes.ligotimegps import LIGOTimeGPS
dbtables.lsctables.LIGOTimeGPS = LIGOTimeGPS

###############################################################################
##### UTILITY FUNCTIONS #######################################################
###############################################################################

def mkdir(output):
	# MAKE SURE WE CAN WRITE TO THE OUTPUT DIRECTORY
	if not os.access(output,os.F_OK): os.makedirs(output)
	else:
		if not os.access(output,os.W_OK):
			print >> sys.stderr, 'path '+output+' is not writable'
			sys.exit(1)


def figure_out_type(time, ifo):
	"""
	Run boundaries (from CBC analyses):
	VSR1: 863557214 - 875232014
	S5:   815155213 - 875232014
	VSR2/S6: 931035296 - ...
	Frame types for S5/VSR1:
	() For RDS_R_L1 data set:
	type    channel_name
	RDS_R_L1     H1:LSC-DARM_ERR
	RDS_R_L1     H2:LSC-DARM_ERR
	RDS_R_L1     L1:LSC-DARM_ERR
	() For hoft data:
	type    channel_name
	H1_RDS_C03_L2  H1:LSC-STRAIN
	H2_RDS_C03_L2  H2:LSC-STRAIN
	L1_RDS_C03_L2  L1:LSC-STRAIN
	HrecV2_16384Hz      V1:h_16384Hz
	CODE RETURNS HOFT DATA
	"""
	L1Types=(
		("L1_RDS_C03_L2","L1:LSC-STRAIN",815155213,875232014),
		("L1_RDS_R_L1","L1:LSC-DARM_ERR",931035296,999999999)
		)
	H1Types=(
		("H1_RDS_C03_L2","H1:LSC-STRAIN",815155213,875232014),
		("H1_RDS_R_L1","H1:LSC-DARM_ERR",931035296,999999999)
		)
	H2Types=(
		("H2_RDS_C03_L2","H2:LSC-STRAIN",815155213,875232014),
		("H1_RDS_R_L1","H1:LSC-DARM_ERR",931035296,999999999)
		)
	V1Types=(
		("HrecV2_16384Hz","V1:h_16384Hz",863557214,875232014),
		("HrecOnline","V1:h_16384Hz",931035296,999999999)
		)
	channelMap={
		"L1":L1Types,
		"H1":H1Types,
		"H2":H2Types,
		"V1":V1Types
		}
	#Use the IFO type to select the channel type
	foundType=""
	foundChannel=""
	for type,channel,start,stop in channelMap[ifo]:
		if ((start<=time) and (time<=stop)):
			foundType=type
			foundChannel=channel
			break
	if foundType == "":
		print time,ifo
		os.abort()
	return str(foundType), str(foundChannel)


###############################################################################
##### DB SUMMARY CLASS ########################################################
###############################################################################

class DB_summary(object):
	
	def __init__(self, connection, live_time_program, file_name, veto_segments_name = None, verbose = False, base=None):
		"""
		Compute and record some summary information about the
		database.
		"""

		self.base = base
		self.connection = connection
		xmldoc = dbtables.get_xml(connection)
		self.file_name = filename
		self.sim_file_name = None

		cursor = connection.cursor()

		# find the tables
		try:
			self.sngl_inspiral_table = table.get_table(xmldoc, dbtables.lsctables.SnglInspiralTable.tableName)
		except ValueError:
			self.sngl_inspiral_table = None
		try:
			self.sim_inspiral_table = table.get_table(xmldoc, dbtables.lsctables.SimInspiralTable.tableName)
			# write out the injection file to use in later inspiral jobs
			newxmldoc = ligolw.Document()
			newxmldoc.appendChild(ligolw.LIGO_LW())
			newxmldoc.childNodes[-1].appendChild(self.sim_inspiral_table)
			self.sim_file_name = "sim_"+os.path.split(filename)[1].replace('sqlite','xml')
			utils.write_filename(newxmldoc, self.sim_file_name, gz=False, verbose=verbose)

		except ValueError:
			self.sim_inspiral_table = None
		try:
			self.coinc_def_table = table.get_table(xmldoc, dbtables.lsctables.CoincDefTable.tableName)
			self.coinc_table = table.get_table(xmldoc, dbtables.lsctables.CoincTable.tableName)
			self.time_slide_table = table.get_table(xmldoc, dbtables.lsctables.TimeSlideTable.tableName)
		except ValueError:
			self.coinc_def_table = None
			self.coinc_table = None
			self.time_slide_table = None
		try:
			self.coinc_inspiral_table = table.get_table(xmldoc, dbtables.lsctables.CoincInspiralTable.tableName)
		except ValueError:
			self.coinc_inspiral_table = None


		# determine a few coinc_definer IDs
		# FIXME:  don't hard-code the numbers
		if self.coinc_def_table is not None:
			try:
				self.ii_definer_id = self.coinc_def_table.get_coinc_def_id("inspiral", 0, create_new = False)
			except KeyError:
				self.ii_definer_id = None
			try:
				self.si_definer_id = self.coinc_def_table.get_coinc_def_id("inspiral", 1, create_new = False)
			except KeyError:
				self.si_definer_id = None
			try:
				self.sc_definer_id = self.coinc_def_table.get_coinc_def_id("inspiral", 2, create_new = False)
			except KeyError:
				self.sc_definer_id = None
		else:
			self.ii_definer_id = None
			self.si_definer_id = None
			self.sc_definer_id = None

		# retrieve the distinct on and participating instruments
		self.on_instruments_combos = [frozenset(dbtables.lsctables.instrument_set_from_ifos(x)) for x, in cursor.execute("SELECT DISTINCT(instruments) FROM coinc_event WHERE coinc_def_id == ?", (self.ii_definer_id,))]

		# get the segment lists
		self.seglists = db_thinca_rings.get_thinca_zero_lag_segments(connection, program_name = live_time_program)
		self.playground_segs = segmentsUtils.S2playground(self.seglists.extent_all())
		self.instruments = set(self.seglists)
		if veto_segments_name is not None:
			self.veto_segments = db_thinca_rings.get_veto_segments(connection, veto_segments_name)
		else:
			self.veto_segments = segments.segmentlistdict()
		self.seglists -= self.veto_segments

def create_is_playground_func(connection, playground_segs):
	"""
	Construct the is_playground() SQL function.
	"""
	connection.create_function("is_playground", 2, lambda seconds, nanoseconds: LIGOTimeGPS(seconds, nanoseconds) in playground_segs)

class ProcParam(object):
	def __init__(self, program, id, param, type, value):
		self.program = program
		self.process_id = id
		self.param = param
		self.type = type
		self.value = value

class Sngl(object):
	def __init__(self, row, contents,ignore_proc_params=False):
		self.data_tuple = row
		self.contents = contents
        	self.ifo = row[0]
		self.snr = float(row[1])
		self.chisq = float(row[2])
		self.mass1 = float(row[3])
		self.mass2 = float(row[4])
		self.time = float(row[5])
		self.process_id = row[6]
		self.row = contents.sngl_inspiral_table.row_from_cols(row[7:])
		self.inj_file_name = contents.sim_file_name

		self.process_params = []

		if not ignore_proc_params:
			for val in self.contents.connection.cursor().execute("""
SELECT
                program, process_id, param, type, value
        FROM
                process_params
        WHERE
                process_id == ?
			""", (self.process_id,) ):
				self.process_params.append(ProcParam(val[0], val[1], val[2], val[3], val[4]))	

	def get_gps_start_time(self):
		#FIXME probably really slow
		for row in self.process_params:
			if row.param == '--gps-start-time': 
				return int(row.value)

	def get_gps_end_time(self):
		#FIXME probably really slow
		for row in self.process_params:
			if row.param == '--gps-end-time': 
				return int(row.value)

	def switch_ifo(self,ifo):
		self.ifo = ifo
		self.process_params = []

		for val in self.contents.connection.cursor().execute("""
SELECT program, process_id, param, type, value FROM process_params AS proc_params WHERE proc_params.process_id = (SELECT p1.process_id FROM process_params AS p1 JOIN process_params AS p2 ON p1.process_id == p2.process_id JOIN search_summary ON search_summary.process_id == p2.process_id WHERE p1.param = '--gps-start-time' AND p1.value <= ? AND p2.param = '--gps-end-time' AND p2.value > ? AND search_summary.ifos = ? LIMIT 1)
		""", (self.time, self.time, self.ifo) ):
			self.process_params.append(ProcParam(val[0], val[1], val[2], val[3], val[4]))
		#change necessary values in process params table
		channel = None
		for row in self.process_params:
			if row.param == '--channel-name':  
				type, channel = figure_out_type(self.time,ifo)
				row.value = channel
				break
		if not channel: 
			print sys.stderr, "Coudn't find process params for trigger aborting"
			sys.exit(1)
		#change necessary values in sngl_inspiral table
		self.row.ifo = ifo	
		self.row.channel = channel.split(':')[1]
		


class Coinc(object):
	def __init__(self, row, contents):
		self.contents = contents
		self.sngl_inspiral = {}
		self.sngl_inspiral_coh = {}
		self.coinc_event_id = row[0]
		self.combined_far = float(row[1])
		self.snr = float(row[2])
		self.time = float(row[3])
		self.mass = float(row[4])
		self.mchirp = float(row[5])
		self.ifos = row[6]
		self.ifos_set = frozenset(dbtables.lsctables.instrument_set_from_ifos(self.ifos))
		self.instruments = row[7]
		self.instruments_set = frozenset(dbtables.lsctables.instrument_set_from_ifos(self.instruments))
		for val in self.contents.connection.cursor().execute("""
SELECT
                sngl_inspiral.ifo, sngl_inspiral.snr, sngl_inspiral.chisq, sngl_inspiral.mass1, sngl_inspiral.mass2, sngl_inspiral.end_time + sngl_inspiral.end_time_ns * 1.0e-9, sngl_inspiral.process_id, sngl_inspiral.*
        FROM
                sngl_inspiral
                JOIN coinc_event_map ON (
                        coinc_event_map.coinc_event_id == ?
                )
        WHERE
                sngl_inspiral.event_id == coinc_event_map.event_id
		""", (str(self.coinc_event_id),) ): 
			self.sngl_inspiral.setdefault(val[0],None)
			self.sngl_inspiral[val[0]] = Sngl(val, contents)

		# add instruments that were on but didn't participate in coinc
		for ifo in self.instruments_set:
			if ifo not in self.ifos_set:
				self.sngl_inspiral[ifo] = self.make_sngl_from_max_ifo(ifo)
		# make a list of sngls appropriate for the coherent code (use max template)
		for ifo in self.instruments_set:
			self.sngl_inspiral_coh[ifo] = self.make_sngl_from_max_ifo(ifo)
		
	def max_trigger_ifo(self):
		snr_tuple = [(sngl.snr, sngl.ifo) for sngl in self.sngl_inspiral.values()]
		return max(snr_tuple)[1]

	def make_sngl_from_max_ifo(self, ifo):
		max_sngl = self.sngl_inspiral[self.max_trigger_ifo()]
		sngl = Sngl(max_sngl.data_tuple, max_sngl.contents, ignore_proc_params=True)
		sngl.switch_ifo(ifo)
		return sngl
		

		
			

class FUTriggers(object):
	def __init__(self, num=10):
		self.num = num
		self.playground_candidates = []
		self.candidates = []

	def add_contents(self, contents, stat='combined_far'):
		if contents.sim_inspiral_table:
			#For now we only return summary information on non injections
			return
		for i,row in enumerate(contents.connection.cursor().execute("""
SELECT
	coinc_inspiral.coinc_event_id,
        coinc_inspiral.combined_far,
        coinc_inspiral.snr,
        coinc_inspiral.end_time + coinc_inspiral.end_time_ns * 1.0e-9,
        coinc_inspiral.mass,
        coinc_inspiral.mchirp,
        coinc_inspiral.ifos,
        coinc_event.instruments
FROM
        coinc_inspiral
        JOIN coinc_event ON (
                coinc_event.coinc_event_id == coinc_inspiral.coinc_event_id
        )
WHERE
        is_playground(coinc_inspiral.end_time, coinc_inspiral.end_time_ns)
        AND NOT EXISTS(
                SELECT
                        *
                FROM
                        time_slide
                WHERE
                        time_slide.time_slide_id == coinc_event.time_slide_id
                AND
                        time_slide.offset != 0
        )
ORDER BY
        ?
LIMIT ?
		""", (stat, self.num) )):
			#print sys.stderr, "...processing coinc %d / %d\r" %(i+1, self.num),
			self.playground_candidates.append(Coinc(row, contents))

		for i, row in enumerate(contents.connection.cursor().execute("""
SELECT
	coinc_inspiral.coinc_event_id,
        coinc_inspiral.combined_far,
        coinc_inspiral.snr,
        coinc_inspiral.end_time + coinc_inspiral.end_time_ns * 1.0e-9,
        coinc_inspiral.mass,
        coinc_inspiral.mchirp,
        coinc_inspiral.ifos,
        coinc_event.instruments
FROM
        coinc_inspiral
        JOIN coinc_event ON (
                coinc_event.coinc_event_id == coinc_inspiral.coinc_event_id
        )
WHERE
        NOT EXISTS(
                SELECT
                        *
                FROM
                        time_slide
                WHERE
                        time_slide.time_slide_id == coinc_event.time_slide_id AND time_slide.offset != 0
        )
ORDER BY
        ?
LIMIT ?
		""", (stat, self.num) )):
			#print sys.stderr, "...processing coinc %d / %d\r" %(i+1, self.num),
			self.candidates.append(Coinc(row, contents))

	def topN(self):
		if len(self.candidates) < self.num: self.num = len(self.candidates)
		trigs = [(t.combined_far, t) for t in self.candidates]
		trigs.sort()
		self.candidates = [t[1] for t in trigs[0:self.num] ]

                if len(self.playground_candidates) < self.num: self.num = len(self.playground_candidates)
		trigs = [(t.combined_far, t) for t in self.playground_candidates]
		trigs.sort()
		self.playground_candidates = [t[1] for t in trigs[0:self.num] ]

###############################################################################
###### UTILITY FUNCTIONS ######################################################
###############################################################################

def link_data_find(cp):
	cache = cp.get('fu-input', 'ihope-cache')
	path = os.path.split(cache)[0]
	datafind_dir = path + '/datafind/cache'
	try:os.symlink(datafind_dir, 'cache')
	except: pass

def parse_command_line():
	parser = OptionParser(
		version = "%prog",
		description = "The sqlite triggered follow-up pipeline"
	)
	parser.add_option("-b", "--base", metavar = "base", default = "cbc_followup_", help = "Set the prefix for output filenames (default = \"cbc_followup_\")")
	parser.add_option("-l", "--live-time-program", metavar = "program", default = "thinca", help = "Set the name, as it appears in the process table, of the program whose search summary entries define the search live time (default = \"thinca\").")
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")
	parser.add_option("-n", "--number", default=10,help = "Number of triggers to follow up (default 10).")
	parser.add_option("-f", "--config-file", default="stfu_pipe.ini", help="the config file, default stfu_pipe.ini")
	options, filenames = parser.parse_args()

	return options, (filenames or [])

###############################################################################
##### MAIN ####################################################################
###############################################################################

# Parse options and config files
options, filenames = parse_command_line()
cp = ConfigParser.ConfigParser()
cp.read(options.config_file)

#link_data_find(cp)

# Initialize dag
dag = stfu_pipe.followUpDAG(options.config_file,cp)

trigs = FUTriggers(num=options.number)

###############################################################################
##### EXTRACT TRIGGER INFORMATION FROM DBs ####################################
###############################################################################

# Extract the triggers from the databases
for n, filename in enumerate(filenames):
	if options.verbose:
		print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
	working_filename = dbtables.get_connection_filename(filename, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)
	contents = DB_summary(connection, options.live_time_program, working_filename, veto_segments_name = "vetoes", verbose = options.verbose)
	#if contents.sim_inspiral_table is not None:
	#	create_sim_coinc_view(connection)
	create_is_playground_func(connection, contents.playground_segs)
	trigs.add_contents(contents)
	connection.close()
	dbtables.discard_connection_filename(filename, working_filename, verbose = options.verbose)

# find the top N triggers from all the databases
trigs.topN()

###############################################################################
##### CONSTRUCT DAG ###########################################################
###############################################################################

# generate a playground set and full data set
for search, candidates in [('playground',trigs.playground_candidates), ('full_data',trigs.candidates)]:

	# CONDOR JOB CLASSES
	ht_data_find_job	= htDataFindJob(cp)
	q_ht_data_find_job	= htDataFindJob(cp, 'qdatafind')
	qscan_job		= qscanJob(options,cp)
	insp_job		= followUpInspJob(cp)
	#inspJobNotrig   = followUpInspJob(cp,'notrig')
	plot_job		= plotSNRChisqJob(options,cp)
	#headInspJob     = followUpInspJob(cp, 'head')
	#cohInspJob      = followUpInspJob(cp, 'coh')
	#cohInspJobNotrig= followUpInspJob(cp, 'notrig')
	sky_map_job		= skyMapJob(options,cp)
	sky_plot_job		= skyMapPlotJob(options,cp)
	find_flags_job            = findFlagsJob(options,cp)
	find_vetos_job            = findVetosJob(options,cp)
	effD_ratio_job            = effDRatioJob(options,cp)
	
	# LOOP OVER COINC EVENTS
	for coinc in candidates:
		if options.verbose:
			 print >>sys.stderr,"processing coinc @ %f with combined FAR %f instruments %s" % (coinc.time, coinc.combined_far, coinc.instruments)

		# SETUP JOBS FOR IFOS FOUND IN COINCIDENCE
		for ifo, sngl_inspiral in coinc.sngl_inspiral.items():
			if options.verbose:
				print >>sys.stderr,"processing %s with snr: %f  and mass1: %f and mass2 %f" % (ifo, sngl_inspiral.snr, sngl_inspiral.mass1, sngl_inspiral.mass2)

			# h(t) QSCAN datafind Nodes
			ht_qscan_data_find_node = stfu_pipe.htDataFindNode(dag, q_ht_data_find_job, cp, options, sngl_inspiral, ifo, qscan=True)

			# h(t) QSCAN Nodes
			ht_qscan_node = stfu_pipe.htQscanNode(dag, qscan_job, cp, options, sngl_inspiral.time, ifo, p_nodes=[ht_qscan_data_find_node])

			#FIXME add inspiral datafind node
			insp_datafind_node = stfu_pipe.htDataFindNode(dag, ht_data_find_job, cp, options, sngl_inspiral, ifo)

			# inspiral Node FIXME add datafind as a parent			
			insp_node = stfu_pipe.followUpInspNode(dag, insp_job, cp, options, sngl_inspiral, insp_datafind_node.outputFileName, p_nodes=[insp_datafind_node])

			#for p in sngl_inspiral.process_params:
			#	print key, p.param, p.value

		# SETUP JOBS THAT REQUIRE COINC INFORMATION (trig if
		# of type Coinc)
		#effDRatioNode = stfu_pipe.effDRatioNode(dag,effDRatioJob,cp,options,trig)
		#findFlagsNode = stfu_pipe.findFlagsNode(dag,findFlagsJob,cp,options,trig.time)
		#findVetosNode = stfu_pipe.findVetosNode(dag,findVetosJob,cp,options,trig.time)

#### ALL FINNISH ####		
dag.write_sub_files()
dag.write_dag()
dag.write_script()


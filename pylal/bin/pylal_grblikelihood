#!/usr/bin/env python
#
# Copyright (C) 2007  Patrick Brady, Nickolas Fotopoulos
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
"""
This code computes the probabilities that go into the distance upper limits
for the CBC external trigger search.

There is a lot of advanced indexing technique here.  Reference:
http://scipy.org/Cookbook/Indexing
"""

from __future__ import division

__author__ = "Nickolas Fotopoulos <nvf@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"
__Id__ = "$Id$"
__prog__ = "pylal_grblikelihood"
__title__ = "GRB interpretation"

import optparse
import os.path as op
import cPickle as pickle
import shutil
import sys

import numpy
numpy.seterr(all="raise")  # throw an exception on any funny business

from pylal import CoincInspiralUtils
from pylal import grbsummary
from pylal import InspiralUtils

# which m2 bin to trace for diagnostics
trace_m2_bin = 0

################################################################################
# utility functions

class BackgroundEstimator(object):
    """
    Abstract class to define an interface for background estimation.
    After initializing with loudest (binned) background data, __call__
    becomes active and will return the ln(p(c|0)) (for each bin).
    """
    def __init__(self, loudest_in_bg_trials):
        self.loudest_in_bg_trials = loudest_in_bg_trials

    def __call__(self, loudest_in_trial):
        raise NotImplemented

class ConstantBackgroundEstimator(BackgroundEstimator):
    """
    BackgroundEstimator that assumes a constant value for loudest_in_trial
    greater than the loudest_bg.
    """
    def __init__(self, loudest_in_bg_trials, eps):
        """
        Initialize ConstantBackgroundEstimator to return a ln(pc0) such that
        pc0[pc0 < eps] = eps. loudest_in_bg_trials can be any shape as long
        as the first axis (axis=0) is the trials axis.  If eps is a vector,
        then we require eps.shape == loudest_in_bg_trials.shape[1:]
        """
        if not numpy.isscalar(eps) \
            and eps.shape != loudest_in_bg_trials.shape[1:]:
            raise ValueError, "eps.shape != loudest_in_bg_trials.shape[1:]"
        self.eps = eps
        BackgroundEstimator.__init__(self, loudest_in_bg_trials)

    def __call__(self, loudest_in_trial):
        """
        Return ln(p(c|0)).  Where p(c|0) < eps, we return eps.
        """
        num_louder = (self.loudest_in_bg_trials > loudest_in_trial[None, ...])\
            .sum(axis=0, dtype=float)
        pc0 = num_louder / self.loudest_in_bg_trials.shape[0]
        pc0[pc0 < self.eps] = self.eps
        return numpy.log(pc0)

class SimpleExpExtrapEstimator(BackgroundEstimator):
    """
    BackgroundEstimator that takes the Nth loudest point and extrapolates
    the p(c|0) distribution based on its value.
    """
    def __init__(self, loudest_in_bg_trials, N):
        """
        Initialize SimpleExpExtrapolator with the extrapolation parameters.
        Use the Nth point from the end as a fiducial point.
        """
        self.N = N

        sorted_loudest = loudest_in_bg_trials.copy()
        sorted_loudest.sort(axis=0)

        self.default_evaluator = \
            ConstantBackgroundEstimator(loudest_in_bg_trials, 1e-10)

        self.fiducial_x = sorted_loudest[-N, ...]
        self.fiducial_y = self.default_evaluator(self.fiducial_x)

    def __call__(self, loudest_in_trial):
        """
        Return ln(p(c|0)).  Where c is loudest than the Nth loudest, use the
        the simplest possible extrapolation based on the Nth loudest event.
        """
        log_pc0 = self.default_evaluator(loudest_in_trial)
        extrap = self.fiducial_y + \
            self.fiducial_x**2 - loudest_in_trial**2
        extrap_ind = loudest_in_trial > self.fiducial_x
        log_pc0[extrap_ind] = extrap[extrap_ind]
        return log_pc0

class ForegroundEstimator(object):
    """
    Abstract class to define an interface for foreground estimation.
    After initializing with loudest (binned) injection data, __call__
    becomes active and will return the ln(p(c(mc)|h(m2)) (for each bin).
    """
    def __init__(self, inj_loudest_by_inj_mc_m2, num_sims_by_m2):
        raise NotImplemented

    def __call__(self, trial_loudest_by_mc):
        raise NotImplemented

class ConstantForegroundEstimator(ForegroundEstimator):
    """
    ConstantForegroundEstimator evaluates the probability of getting events
    louder than any of the given events within each m2 bin.
    """
    def __init__(self, inj_loudest_by_inj_mc_m2, num_sims_by_m2,
        weight_by_inj=None, eps=None):
        """
        Initialize ConstantForegroundEstimator to return a ln(p(c|h)) such that
        pch[pch < eps] = eps.  If eps is a vector, then we require
        eps.shape == loudest_in_bg_trials.shape[1:].  If eps
        is None, then it will be set to half of 1 / num_sims_by_m2.
        """
        self.inj_loudest_by_inj_mc_m2 = inj_loudest_by_inj_mc_m2
        self.num_sims_by_m2 = num_sims_by_m2
        if weight_by_inj is not None:
            self.weight_by_inj = weight_by_inj
        else:
            self.weight_by_inj = numpy.ones(inj_loudest_by_inj_mc_m2.shape[0])
        self.total_weight = self.weight_by_inj.sum()
        if eps is not None:
            if numpy.isscalar(eps):
                self.eps = eps * numpy.ones(inj_loudest_by_inj_mc_m2.shape[1:],
                                            dtype=float)
            elif eps.shape == inj_loudest_by_inj_mc_m2.shape[1:]:
                self.eps = eps
            else:
                raise ValueError, "eps must be None, a scalar, or else "\
                    "eps.shape must be equal to "\
                    "inj_loudest_inj_mc_m2.shape[1:]."
        else:
            self.eps = 0.5 / (num_sims_by_m2[None, :]\
                .repeat(inj_loudest_by_inj_mc_m2.shape[1], axis=0) + 1e-10)

    def __call__(self, trial_loudest_by_mc):
        """
        Return ln(p(c|h)).  Where p(c|0) < eps, we return eps.
        """
        len_inj, len_mc, len_m2 = self.inj_loudest_by_inj_mc_m2.shape
        louder_by_inj_mc_m2 = \
            (self.inj_loudest_by_inj_mc_m2 > \
             trial_loudest_by_mc[None, :, None])

        # Use the BLAS call dot() to speed up this multiplication and sum.
        #num_louder_by_mc_m2 = (louder_by_inj_mc_m2 \
        #    * self.weight_by_inj[:, None, None]).sum(axis=0, dtype=float)
        num_louder_by_mc_m2 = numpy.dot(self.weight_by_inj,
            louder_by_inj_mc_m2.reshape((len_inj, len_mc * len_m2)))\
            .reshape((len_mc, len_m2))
        num_louder_by_mc_m2 *= len_inj / self.total_weight

        pch_by_mc_m2 = num_louder_by_mc_m2 \
            / (self.num_sims_by_m2[None, :] + 1e-10)
        zero_ind = (num_louder_by_mc_m2 < self.eps) \
            & (self.num_sims_by_m2[None, :] != 0)
        pch_by_mc_m2[zero_ind] = self.eps[zero_ind]

        return numpy.log(pch_by_mc_m2)

def parse_args():
    parser = optparse.OptionParser(version="%prog CVS $Id$ ")

    # cache input
    parser.add_option("--relic-onsource", help="output of pylal_relic "\
        "containing the onsource loudest coincs.")
    parser.add_option("--relic-offsource", help="output of pylal_relic "\
        "containing the offsource loudest coincs.")
    parser.add_option("--relic-injections", help="output of pylal_relic "\
        "containing the loudest injection coincs.")

    # odds and ends
    parser.add_option("--reweight-D", action="store_true", default=False,
        help="enable a reweighting of injections from a uniform distribution "\
        "in D to D^3.")
    parser.add_option("--user-tag", help="a tag with which to label outputs")
    parser.add_option("--verbose", action="store_true", default=False,
        help="extra information to the console")

    options, arguments = parser.parse_args()

    # check that mandatory switches are present
    for opt in ("relic_onsource", "relic_offsource", "relic_injections"):
        if getattr(options, opt) is None:
            raise ValueError, "--%s is required" % opt.replace("_", "-")

    return options, arguments

################################################################################
# parse arguments
opts, args = parse_args()

##############################################################################
# read everything into memory
# All vetoes have been taken into account

if opts.verbose:
    print "Reading in bin definitions and loudest statistics..."
statistic, mc_bins, onsource_loudest_by_mc \
    = pickle.load(open(opts.relic_onsource))
statistic, mc_bins, offsource_loudest_by_trial_mc \
    = pickle.load(open(opts.relic_offsource))
statistic, mc_bins, m2_bins, D_bins, num_sims_by_inj_m2_D, \
    inj_loudest_by_inj_mc_m2_D = pickle.load(open(opts.relic_injections))
if statistic != "effective_snr":
    raise NotImplemented

num_sims_by_m2_D = num_sims_by_inj_m2_D.sum(axis=0)
num_sims_by_m2 = num_sims_by_m2_D.sum(axis=1)
inj_loudest_by_inj_mc_m2 = inj_loudest_by_inj_mc_m2_D.max(axis=3)

empty_log_L_by_m2 = -numpy.inf * numpy.ones(len(m2_bins), dtype=float)

##############################################################################
# Initialize background and foreground estimation functions
# NB: start extrapolating 10% from the end of the tail for robustness.
num_offsource_trials = offsource_loudest_by_trial_mc.shape[0]
compute_log_pc0_by_mc = SimpleExpExtrapEstimator(offsource_loudest_by_trial_mc,
    int(0.1 * num_offsource_trials))

# Example of how to switch to constant extrapolator
# compute_log_pc0_by_mc = ConstantBackgroundEstimator(\
#     offsource_loudest_by_trial_mc,
#     0.5 / offsource_loudest_by_trial_mc.shape[0])

# Compute D^3 weighting.
# FIXME: This is a very crude D^3 reweighting based on the outer edge of an
# injection's distance bin rather than the specific distance of the injection.
if opts.reweight_D:
    if opts.verbose:
        print "Computing D^3 reweighting..."
    m2_D_mask_by_inj = (inj_loudest_by_inj_mc_m2_D != 0).sum(axis=1, dtype=bool)
    D_ind_by_inj = []
    for m2_D_mask in m2_D_mask_by_inj:
        if m2_D_mask.any():
            D_ind_by_inj.append(m2_D_mask.sum(axis=0, dtype=bool)\
                .nonzero()[0][0])
        else:
            # If the injection is missed, then we should never use the D index.
            # Use a NaN so that we know if we've accidentally used it.
            D_ind_by_inj.append(numpy.NaN)
    D3_values_by_inj = numpy.array(D_bins.upper())[D_ind_by_inj]
    compute_log_pch_by_mc_m2 = ConstantForegroundEstimator(\
        inj_loudest_by_inj_mc_m2, num_sims_by_m2,
        weight_by_inj=D3_values_by_inj)
else:
    compute_log_pch_by_mc_m2 = ConstantForegroundEstimator(\
        inj_loudest_by_inj_mc_m2, num_sims_by_m2)

################################################################################
# compute the likelihoods of the loudest on-source coincidences
if opts.verbose:
    print "Computing on-source likelihoods..."
log_pc0_by_mc = compute_log_pc0_by_mc(onsource_loudest_by_mc)
log_pch_by_mc_m2 = compute_log_pch_by_mc_m2(onsource_loudest_by_mc)

# NB: Here are examples of how to swap pure effective SNR or log IFAR.
# Just remember to do it for off-source and injection cases as well.

# log_L_by_mc_m2 = onsource_loudest_by_mc[:, None].repeat(len(m2_bins), axis=1)
# log_L_by_mc_m2 = -log_pc0_by_mc[:, None].repeat(len(m2_bins), axis=1)
log_L_by_mc_m2 = log_pch_by_mc_m2 - log_pc0_by_mc[:, None]

# if there are any candidates, take max over likelihoods from candidates
actual_candidate_mask = (onsource_loudest_by_mc > 0)
if numpy.any(actual_candidate_mask):
    log_L_by_m2 = log_L_by_mc_m2[actual_candidate_mask, :].max(axis=0)
else:
    log_L_by_m2 = empty_log_L_by_m2

# write the on-source likelihoods to disk
onsource_outname = __prog__ + "_onsource"
if opts.user_tag is not None:
    onsource_outname += "_" + opts.user_tag
onsource_outname += ".pickle"
pickle.dump((log_pc0_by_mc, log_pch_by_mc_m2, actual_candidate_mask,
    log_L_by_m2), open(onsource_outname, "wb"), -1)

################################################################################
# compute P(observation | 0), the false-alarm probability
# tabulate off-source likelihoods
if opts.verbose:
    print "Computing off-source likelihoods..."
offsource_pc0_by_trial_mc = numpy.zeros(\
    (num_offsource_trials, len(mc_bins)), dtype=numpy.float32)
offsource_pch_by_trial_mc_m2 = numpy.zeros(\
    (num_offsource_trials, len(mc_bins), len(m2_bins)), dtype=numpy.float32)
offsource_likelihood_by_trial_m2 = numpy.zeros(\
    (num_offsource_trials, len(m2_bins)), dtype=numpy.float32)
for i, offsource_loudest_by_mc in enumerate(offsource_loudest_by_trial_mc):
    offsource_pc0_by_trial_mc[i, :] = \
        compute_log_pc0_by_mc(offsource_loudest_by_mc)
    offsource_pch_by_trial_mc_m2[i, :] = \
        compute_log_pch_by_mc_m2(offsource_loudest_by_mc)
    off_log_L_by_mc_m2 = offsource_pch_by_trial_mc_m2[i, :] \
        - offsource_pc0_by_trial_mc[i, :, None]

    # if there are any candidates, take max over likelihoods from candidates
    offsource_candidate_mask = (offsource_loudest_by_mc > 0)
    if numpy.any(offsource_candidate_mask):
        offsource_likelihood_by_trial_m2[i, :] = \
            off_log_L_by_mc_m2[offsource_candidate_mask, :].max(axis=0)
    else:
        offsource_likelihood_by_trial_m2[i, :] = empty_log_L_by_m2

# write the off-source likelihoods to disk
offsource_outname = onsource_outname.replace("_onsource", "_offsource", 1)
pickle.dump((offsource_pc0_by_trial_mc, offsource_pch_by_trial_mc_m2,
    offsource_likelihood_by_trial_m2), open(offsource_outname, "wb"), -1)

################################################################################
# compute P(Lambda > Lambda_0(m2) | h(m2, D)) for the upper limit
# FIXME: Some of this section is convoluted because of the 4-D representation
# of inj_loudest_by_inj_mc_m2_D.
# FIXME: This can be done in O(N_{inj}) time because L is monotonic with SNR
# within an mc bin, so a threshold in L can be converted to a threshold in SNR
# for each mc bin.
if opts.verbose:
    print "Computing injection likelihoods..."

num_inj = len(inj_loudest_by_inj_mc_m2_D)
m2_by_inj = numpy.zeros(num_inj, dtype=float)
D_by_inj = numpy.zeros(num_inj, dtype=float)
inj_likelihood_by_trial_m2 = empty_log_L_by_m2[None, :].repeat(num_inj, axis=0)
log_pc0_by_inj_mc = []
log_pch_by_inj_mc = []
rho_by_inj_mc = []
for i, inj_trial_loudest_by_mc_m2_D in enumerate(inj_loudest_by_inj_mc_m2_D):

    # find (m2, D) bin
    m2_D_mask = (inj_trial_loudest_by_mc_m2_D != 0).sum(axis=0, dtype=bool)
    if m2_D_mask.sum() == 0:  # injection missed
        continue

    # sanity check: one m2, D pair contains something other than zero
    assert m2_D_mask.sum() == 1, "only one (m2, D) bin should be nonzero"
    m2_by_inj[i] = m2_D_mask.sum(axis=1, dtype=bool).nonzero()[0]
    D_by_inj[i] = m2_D_mask.sum(axis=0, dtype=bool).nonzero()[0]

    # compute likelihood of this (inj + noise) instance arising from m2'
    inj_trial_loudest_by_mc_m2 = inj_trial_loudest_by_mc_m2_D.max(axis=2)
    inj_trial_loudest_by_mc = inj_trial_loudest_by_mc_m2.max(axis=1)

    inj_trial_log_pc0_by_mc = compute_log_pc0_by_mc(inj_trial_loudest_by_mc)

    # this inner loop makes the algorithm O(n^2)
    inj_trial_log_pch_by_mc_m2 = \
        compute_log_pch_by_mc_m2(inj_trial_loudest_by_mc)

    inj_trial_log_L_by_mc_m2 = inj_trial_log_pch_by_mc_m2 \
        - inj_trial_log_pc0_by_mc[:, None]

    # if there are any candidates, take max over likelihoods from candidates
    inj_trial_candidate_mask = (inj_trial_loudest_by_mc > 0)
    assert numpy.any(inj_trial_candidate_mask)  # assert injection found
    inj_likelihood_by_trial_m2[i, :] = \
        inj_trial_log_L_by_mc_m2[inj_trial_candidate_mask, :].max(axis=0)

    # record diagnostics
    if m2_by_inj[i] == trace_m2_bin:
        log_pc0_by_inj_mc.append(inj_trial_log_pc0_by_mc)
        log_pch_by_inj_mc.append(inj_trial_log_pch_by_mc_m2[:, trace_m2_bin]\
            .squeeze())
        rho_by_inj_mc.append(inj_trial_loudest_by_mc)
log_pc0_by_inj_mc = numpy.array(log_pc0_by_inj_mc)
log_pch_by_inj_mc = numpy.array(log_pch_by_inj_mc)
rho_by_inj_mc = numpy.array(rho_by_inj_mc)

# write the injection likelihoods to disk
inj_outname = onsource_outname.replace("_onsource", "_injections", 1)
pickle.dump((inj_likelihood_by_trial_m2, log_pc0_by_inj_mc, log_pch_by_inj_mc,
             rho_by_inj_mc, m2_by_inj, D_by_inj, trace_m2_bin),
            open(inj_outname, "wb"), -1)


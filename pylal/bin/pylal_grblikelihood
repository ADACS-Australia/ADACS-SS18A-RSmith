#!/usr/bin/env python
#
# Copyright (C) 2007  Nickolas Fotopoulos
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
"""
Skeleton for pylal_grblikelihood revision.

Invasive internal changes:
* HTML output
* rate.py integration
* plotutils integration
* 3D arrays to pass around quantities of interest

There is a lot of advanced indexing technique here.  Reference:
http://scipy.org/Cookbook/Indexing
"""

from __future__ import division

__author__ = "Nickolas Fotopoulos <nvf@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"
__Id__ = "$Id$"
__name__ = "pylal_grblikelihood"
__title__ = "GRB interpretation"

import bisect
import glob
itertools = __import__("itertools")  # system-wide itertools
import optparse
import sys

import numpy
numpy.seterr(all="raise")  # throw an exception on any funny business

import matplotlib
matplotlib.use("Agg")
import pylab
pylab.rc("text", usetex=True)

from glue import iterutils
from glue import lal

from glue import segmentsUtils
from glue.segments import segment, segmentlist
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import utils
from glue.ligolw.utils import ligolw_add
from pylal import CoincInspiralUtils
from pylal import InspiralUtils
from pylal import SearchSummaryUtils
from pylal import SnglInspiralUtils
from pylal import grbsummary
from pylal import llwapp
from pylal import plotutils
from pylal import rate
from pylal import viz

################################################################################
# utility functions
def get_mean_mchirp(coinc):
    """
    Return the arithmetic average of the mchirps of all triggers in coinc.
    """
    return sum(t.mchirp for t in coinc) / coinc.numifos

def get_num_slides(xmldoc):
    """
    Return the value of --num-slides found in the process_params table of
    xmldoc.  If no such entry is found, return 0.
    """
    tbl_name = lsctables.ProcessParamsTable.tableName

    # don't be too picky what program had --num-slides
    for tbl in table.getTablesByName(xmldoc, tbl_name):
        for row in tbl:
           if row.param == "--num-slides":
               return int(row.value)
    return 0

class IrregularBins(rate.Bins):
    """
    Bins with arbitrary, irregular spacing.  We only require strict monotonicity
    of the bin boundaries.  N boundaries define N-1 bins.

    Example:

    >>> x = IrregularBins([0.0, 11.0, 15.0, numpy.inf])
    >>> len(x)
    3
    >>> x[1]
    0
    >>> x[1.5]
    0
    >>> x[13]
    1
    >>> x[25]
    2
    """
    def __init__(self, boundaries):
        """
        Initialize a set of custom bins with the bin boundaries.  This includes
        all left edges plus the right edge.  The boundaries must be monotonic
        and there must be at least two elements.
        """
        # check pre-conditions
        if len(boundaries) < 2:
            raise ValueError, "less than two boundaries provided"
        boundaries = numpy.array(boundaries)
        if (boundaries[:-1] > boundaries[1:]).any():
            raise ValueError, "non-monotonic boundaries provided"

        self.boundaries = boundaries
        self.n = len(boundaries) - 1

    def __getitem__(self, x):
        if isinstance(x, slice):
            if x.step is not None:
                raise NotImplementedError, x
            if x.start is None:
                start = 0
            else:
                start = self[x.start]
            if x.stop is None:
                stop = len(self)
            else:
                stop = self[x.stop]
            return slice(start, stop)
        ind = bisect.bisect_left(self.boundaries, x)
        # raise exception if x is outside of all bins
        # allow the "measure zero" corner case of (x == right boundary)
        if ind == 0 or (ind == len(self.boundaries) and \
                        x != self.boundaries[-1]):
            raise IndexError, x
        return ind - 1

    def lower(self):
        return self.boundaries[:-1]

    def upper(self):
        return self.boundaries[1:]

    def centres(self):
        return (self.lower() + self.upper()) / 2

def get_loudest_coinc_by_mc(xmldoc, mc_bins):
    # read unclustered on-source coincs
    onsource_trigs = table.get_table(xmldoc,
        lsctables.SnglInspiralTable.tableName)
    onsource_coincs = CoincInspiralUtils.coincInspiralTable(onsource_trigs,
        coinc_stat)

    # get loudest stat in each average mchirp bin
    num_discarded = 0
    loudest_by_mc = numpy.zeros(len(mc_bins), dtype=numpy.float32) - 1
    for coinc in onsource_coincs:
        try:
            ind = mc_bins[get_mean_mchirp(coinc)]
        except IndexError:
            num_discarded += 1
            continue
        loudest_by_mc[ind] = max(coinc.stat, loudest_by_mc[ind])
    if num_discarded > 0:
        print >>sys.stderr, "warning: %d on-source coincs fell outside "\
            "mchirp bins" % num_discarded

    return loudest_by_mc

def mark_loud_background_by_trial_mc(offsource_doc, onsource_loudest_by_mc,
    trial_bins, mc_bins):
    """
    Return a 2-D boolean array, binned by trial and mchirp,
    whose entries are True iff there is a coinc in a given bin louder
    than the loudest on-source event in its mchirp bin.
    """
    # read unclustered background coincs
    offsource_trigs = table.get_table(offsource_doc,
        lsctables.SnglInspiralTable.tableName)
    offsource_coincs = CoincInspiralUtils.coincInspiralTable(offsource_trigs,
        coinc_stat)

    # mark the (trial, average mchirp) bin where a coinc is louder than the
    # loudest on-source event
    num_discarded = 0
    louder_by_trial_mc = numpy.zeros((len(trial_bins), len(mc_bins)),
                                     dtype=numpy.bool8)
    for coinc in offsource_coincs:
        try:
            trial_ind = trial_bins[coinc.get_time()]
            mc_ind = mc_bins[get_mean_mchirp(coinc)]
        except IndexError:
            num_discarded += 1
            continue
        if coinc.stat > onsource_loudest_by_mc[mc_ind]:
            louder_by_trial_mc[trial_ind, mc_ind] = True
    if num_discarded > 0:
        print >>sys.stderr, "warning: %d of %d off-source coincs fell outside "\
            "mchirp bins" % (num_discarded, len(offsource_coincs))

    return louder_by_trial_mc

def mark_loud_injections_by_mc_m2_D(inj_doc, coinc_doc, onsource_loudest_by_mc,
    trial_bins, mc_bins, m2_bins, D_bins):
    """
    Return a 3-D integer array, binned by mean mchirp and injected m2 and D,
    and the number of sims in inj_doc.  The array tallies for how many
    injections there are coincs in a given bin are louder than the loudest
    on-source event in its mchirp bin.
    """
    # get injection info
    sims = table.get_table(inj_doc, lsctables.SimInspiralTable.tableName)
    sim_trials = [trial_bins[s.geocent_end_time] for s in sims]

    # sanity check: no two injections went into the same trial
    assert len(sim_trials) == len(set(sim_trials))

    # tabulate each sim and its properties
    num_discarded = 0
    num_sims_by_m2_D = numpy.zeros((len(m2_bins), len(D_bins)), dtype=int)
    m2_indices = []
    D_indices = []
    for sim in sims:
        try:
            m2_ind = m2_bins[sim.mass1]
            D_ind = D_bins[sim.distance]
        except IndexError:
            num_discarded += 1
            continue
        num_sims_by_m2_D[m2_ind, D_ind] += 1
        m2_indices.append(m2_ind)
        D_indices.append(D_ind)

    # reconstruct coincidences
    trigs = table.get_table(coinc_doc, lsctables.SnglInspiralTable.tableName)
    coincs = CoincInspiralUtils.coincInspiralTable(trigs, coinc_stat)

    # do the marking for each sim separately
    num_discarded = 0
    num_found_by_sim_mc_m2_D = numpy.zeros((len(sim_trials), len(mc_bins),
        len(m2_bins), len(D_bins)), dtype=numpy.bool8)
    for coinc in coincs:
        try:
            trial_ind = trial_bins[coinc.get_time()]
            mc_ind = mc_bins[get_mean_mchirp(coinc)]
        except IndexError:
            num_discarded += 1
            continue

        # filtered times from injections do not overlap
        if trial_ind not in sim_trials:
            num_discarded += 1
            continue
        sim_ind = sim_trials.index(trial_ind)

        if coinc.stat > onsource_loudest_by_mc[mc_ind]:
            num_found_by_sim_mc_m2_D[sim_ind, mc_ind,
                m2_indices[sim_ind], D_indices[sim_ind]] = True

    # now add up how many sims had coincs in each (mc, m2, D) bin
    num_found_by_mc_m2_D = num_found_by_sim_mc_m2_D.sum(axis=0, dtype=int)

    return num_found_by_mc_m2_D, num_sims_by_m2_D

def get_level_crossings(xy_array, level, y_bins):
    """
    Return the linearly interpolated y values where the xy_array dips first
    dips below level, iterating upwards.
    """
    # sanity checks
    if xy_array.ndim != 2:
        raise ValueError, "require a two-dimensional xy_array"
    if xy_array.shape[1] != len(y_bins):
        raise ValueError, "xy_array y-dimension does not match y_bin length"

    def _first_below_val(column, target):
        """
        Return the index of the first entry that is less than target.
        If no entry is less than the target, return the length of the column.
        """
        for i, val in enumerate(column):
            if column[i] < target:
                return i
        return len(column)

    def _interp_column(column, level, y_vals):
        """
        Return the linearly interpolated value of y where the column first
        dips below level.
        """
        ind = _first_below_val(column, level)
        if ind == 0:
            return 0
        elif ind == len(column):
            return y_vals[-1]
        else:
            # interpolate between ind-1 and ind
            slope = (y_vals[ind] - y_vals[ind-1]) / \
                    (column[ind] - column[ind-1])
            return y_vals[ind-1] + (level - column[ind-1]) * slope

    y = y_bins.centres()
    return numpy.array([_interp_column(col, level, y) for col in xy_array])

def parse_args():
    parser = optparse.OptionParser(version="%prog CVS $Id$ ")

    # cache input
    parser.add_option("--cache-file", help="LAL-formatted cache file "
        "containing entries for all XML filies of interest")
    parser.add_option("--onsource-pattern", metavar="PAT", help="sieve the "
        "cache descriptions for on-source coincidences files with PAT")
    parser.add_option("--offsource-pattern", metavar="PAT", help="sieve the "
        "cache descriptions for off-source coincidence files with PAT")
    parser.add_option("--injection-pattern", metavar="PAT",
        help="sieve the cache descriptions for injection files with PAT")
    parser.add_option("--inj-coinc-pattern", metavar="PAT",
        help="sieve the cache descriptions for injection THINCA files with PAT")

    # segments
    parser.add_option("--veto-segfiles", default="",
        help="comma-separated list of segwizard-formatted segment files that "
        "contain segments to veto")

    # binning
    parser.add_option("--m2-min", type="float", help="minimum of the range in "
        "injected companion mass")
    parser.add_option("--m2-max", type="float", help="maximum of the range in "
        "injected companion mass")
    parser.add_option("--m2-nbins", type="int", help="number of evenly-spaced "
        "bins in injected companion mass")
    parser.add_option("--D-min", type="float", help="minimum of the range in "
        "injected distance")
    parser.add_option("--D-max", type="float", help="maximum of the range in "
        "injected distance")
    parser.add_option("--D-nbins", type="int", help="number of evenly-spaced "
        "bins in injected distance")
    parser.add_option("--mc-boundaries", help="comma-delimited list of "
        "boundaries in average recovered chirp mass")

    # calibration uncertainty
    parser.add_option("--calibration-uncertainty", type="float", metavar="CAL",
        help="calibration uncertainty (D -> (1+/-CAL)*D)")

    # InspiralUtils compatibility
    parser.add_option("", "--gps-start-time", type="int",
        help="GPS start time of data analyzed")
    parser.add_option("", "--gps-end-time", type="int",
        help="GPS end time of data analyzed")
    parser.add_option("", "--ifo-tag", help="IFO coincidence time analyzed")
    parser.add_option("", "--user-tag", help="a tag to label your plots")
    parser.add_option("", "--output-path", help="root of the HTML output")
    parser.add_option("", "--enable-output", action="store_true",
        default=False, help="enable plots and HTML output")
    parser.add_option("", "--html-for-cbcweb", action="store_true",
        default=False, help="enable HTML output with the appropriate headers "
        "for the CBC website")
    parser.add_option("--show-plot", action="store_true", default=False,
        help="display the plots to screen if an X11 display is available")

    # odds and ends
    parser.add_option("--statistic", default="snr",
        help="choice of statistic used in making plots, valid arguments are: "
        "snr (DEFAULT), snr_over_chi, s3_snr_chi_stat, effective_snr")
    parser.add_option("--stat-threshold", default=0, type="float",
        help="default statistic to use in the case of no loudest event")
    parser.add_option("--verbose", action="store_true", default=False,
        help="print extra information to the console")

    opts, args = parser.parse_args()

    # check that mandatory switches are present
    for opt in ("cache_file", "onsource_pattern", "offsource_pattern",
        "injection_pattern", "inj_coinc_pattern", "veto_segfiles", "m2_min",
        "m2_max", "m2_nbins", "D_min", "D_max", "D_nbins", "mc_boundaries",
        "statistic"):
        if not hasattr(opts, opt):
            raise ValueError, "%s is required" % opt.replace("_", "-")

    # split comma-separated lists
    for opt in ("veto_segfiles", "mc_boundaries"):
        if hasattr(opts, opt):
            setattr(opts, opt, getattr(opts, opt).split(","))

    opts.mc_boundaries = map(float, opts.mc_boundaries)

    return opts, args

################################################################################
# parse arguments
opts, args = parse_args()

##############################################################################
# generic initialization
InspiralUtils.initialise(opts, __name__, __version__)
coinc_stat = CoincInspiralUtils.coincStatistic(opts.statistic)

##############################################################################
# read in non-injection documents (do so here to get num slides and segments)
cache = lal.Cache.fromfile(open(opts.cache_file))

onsource_doc = grbsummary.load_cache(ligolw.Document(), cache,
    opts.onsource_pattern, verbose=opts.verbose)
offsource_doc = grbsummary.load_cache(ligolw.Document(), cache,
    opts.offsource_pattern, verbose=opts.verbose)

nominal_num_slides = get_num_slides(offsource_doc)
total_num_slides = 2 * nominal_num_slides or 1

################################################################################
# choose segments/trials/vetoes (match grbtimeslide_stats)

trial_bins, trial_veto_mask, onsource_ind = \
    grbsummary.get_exttrig_trials(onsource_doc, offsource_doc,
                                  opts.veto_segfiles)
num_trials = len(trial_bins)

# count how many unvetoed trials we have
eff_num_trials = numpy.sum(~trial_veto_mask)

################################################################################
# choose other binnings: mchirp, m2, D
mc_bins = IrregularBins(opts.mc_boundaries)
m2_bins = rate.LinearBins(opts.m2_min, opts.m2_max, opts.m2_nbins)
D_bins = rate.LinearBins(opts.D_min, opts.D_max, opts.D_nbins)

################################################################################
# get loudest stats of on-source

# get loudest stat in each mchirp bin
onsource_loudest_by_mc = get_loudest_coinc_by_mc(onsource_doc, mc_bins)

# if no candidate, use threshold from command line
onsource_loudest_by_mc[onsource_loudest_by_mc <= 0] = opts.stat_threshold

# print summary
print "on-source loudest combined " + opts.statistic + " by mchirp category:"
for low, hi, stat in zip(mc_bins.lower(), mc_bins.upper(),
                         onsource_loudest_by_mc):
    print "  [%f, %f): %f" % (low, hi, stat)

################################################################################
# compute p(c|0)

# in (trial, mean mchirp) bins, mark the trials with a coinc louder than loudest
# on-source coinc in mchirp category
louder_by_trial_mc = mark_loud_background_by_trial_mc(offsource_doc,
    onsource_loudest_by_mc, trial_bins, mc_bins)

# for each mchirp bin, determine p(c|0) by summing across trials
pc0_by_mc = louder_by_trial_mc[~trial_veto_mask, :].sum(axis=0, dtype=float) \
    / eff_num_trials

print "p(c(mchirp) | 0):"
for low, hi, pc0 in zip(mc_bins.lower(), mc_bins.upper(), pc0_by_mc):
    print "  [%f, %f): %f" % (low, hi, pc0)

################################################################################
# compute p(c|h) using the optimal mchirp region for each m2 bin

# sieve down to just injection coinc files
injection_cache = cache.sieve(description=opts.injection_pattern)
inj_coinc_cache = cache.sieve(description=opts.inj_coinc_pattern)

# get all unique descriptions (can have multiple segments per description)
inj_patterns = set("*_" + "_".join(entry.description.split("_")[-2:]) \
                   for entry in inj_coinc_cache)

# tally up the numerator and denominator for p(c|h) for each inj pattern
if opts.verbose:
    print "Tallying injections:"
num_found_by_mc_m2_D = numpy.zeros((len(mc_bins), len(m2_bins), len(D_bins)),
                                   dtype=int)
num_sims_by_m2_D = numpy.zeros((len(m2_bins), len(D_bins)), dtype=int)
for pattern in inj_patterns:
    if opts.verbose:
        sys.stdout.write(".")
        sys.stdout.flush()

    # read injection and its corresponding coincs
    inj_doc = grbsummary.load_cache(ligolw.Document(), injection_cache,
                                    pattern, exact_match=True)
    coinc_doc = grbsummary.load_cache(ligolw.Document(), inj_coinc_cache,
                                      pattern, exact_match=True)

    # For each (mean mchirp, injected m2, injected D) bin, tally the found
    # coincs louder than the loudest on-source event in their recovered mchirp
    # bins.  Also, tally the total injections in each m2 bin
    # TODO: calibration uncertainty in distance
    tmp_found, tmp_total = \
        mark_loud_injections_by_mc_m2_D(inj_doc, coinc_doc,
            onsource_loudest_by_mc, trial_bins, mc_bins, m2_bins, D_bins)

    num_found_by_mc_m2_D += tmp_found
    num_sims_by_m2_D += tmp_total
if opts.verbose:
    print "Done. Tallied %d injections." % num_sims_by_m2_D.sum()

# for each m2 bin, find the mchirp that gives the max L=p(c|h)/p(c|0)
pch_by_mc_m2 = num_found_by_mc_m2_D.sum(axis=2) / \
    (num_sims_by_m2_D.sum(axis=1)[None, :] + 1e-10)
L_by_mc_m2 = pch_by_mc_m2 / (pc0_by_mc[:, None] + 1e-10)
mc_ind_by_m2 = L_by_mc_m2.argmax(axis=0)

# numpy indexer to pick the right mchirp category for each m2; returns (m2, D)
mc_indexer = (mc_ind_by_m2, range(len(m2_bins)), slice(None, None, None))

# get p(c|h) for each injected (m2, D) bin
pch_by_m2_D = num_found_by_mc_m2_D[mc_indexer] / (num_sims_by_m2_D + 1e-10)

# TODO: correct for MC counting uncertainty

################################################################################
# plots
fnameList = []
tagList = []

mc_latex = r"\langle \hat{M}_\mathrm{chirp} \rangle"

## injection count vs (m2, D) image
text = "Injection count"

plot = plotutils.ImagePlot("$m_2\ (M_\odot)$", "$D\ \mathrm{(Mpc)}$", r"Injections made")
plot.add_content(num_sims_by_m2_D.T, m2_bins, D_bins)
plot.finalize()

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "injection_count_by_m2_D")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## mchirp vs loudest stat horizontal bar graph
text = "mchirp vs loudest statistic"

plot = plotutils.NumberVsBinBarPlot(opts.statistic.replace("_", r"\_"),
    "$" + mc_latex + "$", "Loudest statistics by mchirp")
plot.add_content(mc_bins, onsource_loudest_by_mc)
plot.finalize(orientation="horizontal")

# add p(c|0) on top as text
for mc, pc0 in zip(mc_bins.centres(), pc0_by_mc):
    plot.ax.text(0.5, mc, "$p(c|0) = $" + str(pc0))

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "loudest_stats_by_mchirp")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## for each mchirp, p(c|h) vs (m2, D) image
# TODO: before and after MC and calibration systematics
text = "p(c|h(m2, D))"

plot = plotutils.ImagePlot(r"$m_2\ (M_\odot)$", r"$D\ \mathrm{(Mpc)}$",
    "$p(c|h)$")
plot.add_content(pch_by_m2_D.T, m2_bins, D_bins)
plot.finalize()

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "pch_by_m2_D")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## for L(c|h) vs (m2, mc) image
# TODO: before and after MC and calibration systematics
text = "L(c(mc)|h(m2))"

plot = plotutils.ImagePlot(\
    r"$" + mc_latex + r"(M_\odot;\textrm{ not to scale)$",
    r"$m_2\ (M_\odot)$",
    r"$L(c(" + mc_latex + r")|h(m_2))$")
plot.add_content(L_by_mc_m2.T, mc_bins, m2_bins)
plot.finalize()

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "L_by_mc_m2")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## upper limit contours (m2, D) image
text = "(m2, D) exclusion plot"

plot = plotutils.FillPlot(r"$m_2\ (M_\odot)$", r"$D\ \mathrm{(Mpc)}$",
    "Exclusion regions")

x = m2_bins.lower()
zero = numpy.zeros(len(m2_bins), dtype=float)

y = get_level_crossings(pch_by_m2_D, 0.25, D_bins)
tmpx, tmpy = viz.makesteps(x, zero, y)
plot.add_content(tmpx, tmpy, label=r"25\% exclusion")

y = get_level_crossings(pch_by_m2_D, 0.5, D_bins)
tmpx, tmpy = viz.makesteps(x, zero, y)
plot.add_content(tmpx, tmpy, label=r"50\% exclusion")

y = get_level_crossings(pch_by_m2_D, 0.75, D_bins)
tmpx, tmpy = viz.makesteps(x, zero, y)
plot.add_content(tmpx, tmpy, label=r"75\% exclusion")

y = get_level_crossings(pch_by_m2_D, 0.9, D_bins)
tmpx, tmpy = viz.makesteps(x, zero, y)
plot.add_content(tmpx, tmpy, label=r"90\% exclusion")

plot.finalize()

plot.ax.set_ylim((0, D_bins.upper()[-1]))

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "exclusion_by_m2_D")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()


#############################################################################
# Generate HTML and cache file
if opts.enable_output:
    html_filename = InspiralUtils.write_html_output(opts, sys.argv[1:],
        fnameList, tagList)
    InspiralUtils.write_cache_output(opts, html_filename, fnameList)

    if opts.html_for_cbcweb:
        html_filename_publish = InspiralUtils.write_html_output(opts,
            sys.argv[1:], fnameList, tagList, comment=info_text, cbcweb=True)

if opts.show_plot:
    pylab.show()

#!/usr/bin/env python
#
# Copyright (C) 2007  Patrick Brady, Nickolas Fotopoulos
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
"""
This code computes the probabilities that go into the distance upper limits
for the CBC external trigger search.

There is a lot of advanced indexing technique here.  Reference:
http://scipy.org/Cookbook/Indexing
"""

from __future__ import division

__author__ = "Nickolas Fotopoulos <nvf@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"
__Id__ = "$Id$"
__prog__ = "pylal_grblikelihood"
__title__ = "GRB interpretation"

import optparse
import cPickle as pickle
import sys

import numpy
numpy.seterr(all="raise")  # throw an exception on any funny business
from scipy import stats
import matplotlib
matplotlib.use("Agg")
import pylab
pylab.rc("text", usetex=True)
pylab.rc("lines", linewidth=2)

from pylal import InspiralUtils
from pylal import plotutils
from pylal import viz

################################################################################
# utility functions

class BackgroundEstimator(object):
    """
    Abstract class to define an interface for background estimation.
    After initializing with loudest (binned) background data, __call__
    becomes active and will return the ln(p(c|0)) (for each bin).
    """
    def __init__(self, loudest_in_bg_trials):
        self.loudest_in_bg_trials = loudest_in_bg_trials

    def __call__(self, loudest_in_trial):
        raise NotImplemented

class ConstantBackgroundEstimator(BackgroundEstimator):
    """
    BackgroundEstimator that assumes a constant value for loudest_in_trial
    greater than the loudest_bg.
    """
    def __init__(self, loudest_in_bg_trials, eps):
        """
        Initialize ConstantBackgroundEstimator to return a ln(pc0) such that
        pc0[pc0 < eps] = eps. loudest_in_bg_trials can be any shape as long
        as the first axis (axis=0) is the trials axis.  If eps is a vector,
        then we require eps.shape == loudest_in_bg_trials.shape[1:]
        """
        if not numpy.isscalar(eps) \
            and eps.shape != loudest_in_bg_trials.shape[1:]:
            raise ValueError, "eps.shape != loudest_in_bg_trials.shape[1:]"
        self.eps = eps
        BackgroundEstimator.__init__(self, loudest_in_bg_trials)

    def __call__(self, loudest_in_trial):
        """
        Return ln(p(c|0)).  Where p(c|0) < eps, we return eps.
        """
        num_louder = (self.loudest_in_bg_trials > loudest_in_trial[None, ...])\
            .sum(axis=0, dtype=float)
        pc0 = num_louder / self.loudest_in_bg_trials.shape[0]
        pc0[pc0 < self.eps] = self.eps
        return numpy.log(pc0)

class SimpleExpExtrapEstimator(BackgroundEstimator):
    """
    BackgroundEstimator that takes the Nth loudest point and extrapolates
    the p(c|0) distribution based on its value.
    """
    def __init__(self, loudest_in_bg_trials, N):
        """
        Initialize SimpleExpExtrapolator with the extrapolation parameters.
        Use the Nth point from the end as a fiducial point.
        """
        self.N = N

        sorted_loudest = loudest_in_bg_trials.copy()
        sorted_loudest.sort(axis=0)

        self.default_evaluator = \
            ConstantBackgroundEstimator(loudest_in_bg_trials, -1)

        self.fiducial_x = sorted_loudest[-N, ...]
        self.fiducial_y = self.default_evaluator(self.fiducial_x)

    def __call__(self, loudest_in_trial):
        """
        Return ln(p(c|0)).  Where c is loudest than the Nth loudest, use the
        the simplest possible extrapolation based on the Nth loudest event.
        """
        log_pc0 = self.default_evaluator(loudest_in_trial)
        extrap = self.fiducial_y + \
            self.fiducial_x*self.fiducial_x - loudest_in_trial*loudest_in_trial
        extrap_ind = loudest_in_trial > self.fiducial_x
        log_pc0[extrap_ind] = extrap[extrap_ind]
        return log_pc0

def compute_log_pch_by_mc_m2(inj_loudest_by_inj_mc_m2, num_sims_by_m2,
    onsource_loudest_by_mc):
    """
    Compute log(p(c \in neighborhood(c_0) | h(m2, D))) for each possible
    on-source loudest event, c_0.  What m_2 this corresponds to will be chosen
    later.
    """
    # for each mc, m2, count how many trials have c \in neighborhood(c_0)
    num_louder_by_mc_m2 = \
        (inj_loudest_by_inj_mc_m2 > onsource_loudest_by_mc[None, :, None])\
        .sum(axis=0)

    # minimum resolvable is ~0.5 / num_sims; pathological if num_sims == 0, but
    # we will be careful to apply it only if num_sims != 0.
    pch_eps_by_mc_m2 = 0.5 / \
        (num_sims_by_m2[None, :].repeat(len(mc_bins), axis=0) + 1e-10)

    # compute p(c|h) vs (mc, m2) for finding the loudest event in each m2 bin
    pch_by_mc_m2 = num_louder_by_mc_m2 / (num_sims_by_m2[None, :] + 1e-10)
    zero_ind = (num_louder_by_mc_m2 == 0) & (num_sims_by_m2[None, :] != 0)
    pch_by_mc_m2[zero_ind] = pch_eps_by_mc_m2[zero_ind]

    return numpy.log(pch_by_mc_m2)

def get_level_crossings(xy_array, level, y_bins):
    """
    Return the linearly interpolated y values where the xy_array dips first
    dips below level, iterating upwards.
    """
    # sanity checks
    if xy_array.ndim != 2:
        raise ValueError, "require a two-dimensional xy_array"
    if xy_array.shape[1] != len(y_bins):
        raise ValueError, "xy_array y-dimension does not match y_bin length"

    def _first_below_val(column, target):
        """
        Return the index of the first entry that is less than target.
        If no entry is less than the target, return the length of the column.
        """
        for i, val in enumerate(column):
            if val < target:
                return i
        return len(column)

    def _interp_column(column, level, y_vals, min_y=0, max_y=None):
        """
        Return the linearly interpolated value of y where the column first
        dips below level.
        """
        if max_y is None:
            max_y = y_vals[-1]
        ind = _first_below_val(column, level)
        if ind == 0:
            return min_y
        elif ind == len(column):
            return max_y
        else:
            # interpolate between ind-1 and ind
            slope = (y_vals[ind] - y_vals[ind-1]) / \
                    (column[ind] - column[ind-1])
            return y_vals[ind-1] + (level - column[ind-1]) * slope

    y_vals = y_bins.centres()
    return numpy.array([_interp_column(col, level, y_vals, min_y=0,
                                       max_y=y_bins.max) \
                        for col in xy_array])

def parse_args():
    parser = optparse.OptionParser(version="%prog CVS $Id$ ")

    # cache input
    parser.add_option("--relic-onsource", help="output of pylal_relic "\
        "containing the onsource loudest coincs.")
    parser.add_option("--relic-offsource", help="output of pylal_relic "\
        "containing the offsource loudest coincs.")
    parser.add_option("--relic-injections", help="output of pylal_relic "\
        "containing the loudest injection coincs.")

    # InspiralUtils compatibility
    parser.add_option("--gps-start-time", type="int",
        help="GPS start time of data analyzed")
    parser.add_option("--gps-end-time", type="int",
        help="GPS end time of data analyzed")
    parser.add_option("--ifo-tag", help="IFO coincidence time analyzed")
    parser.add_option("--user-tag", help="a tag to label your plots")
    parser.add_option("--output-path", help="root of the HTML output")
    parser.add_option("--enable-output", action="store_true",
        default=False, help="enable plots and HTML output")
    parser.add_option("--html-for-cbcweb", action="store_true",
        default=False, help="enable HTML output with the appropriate headers "
        "for the CBC website")
    parser.add_option("--show-plot", action="store_true", default=False,
        help="display the plots to screen if an X11 display is available")

    # odds and ends
    parser.add_option("--h1-calibration-uncertainty", metavar="FAC",
        type="float", default=0.,
        help="fractional uncertainty in the DC calibration of "
        "H1; rescale distances by (1 +/- max(FAC))*D")
    parser.add_option("--h2-calibration-uncertainty", metavar="FAC",
        type="float", default=0.,
        help="fractional uncertainty in the DC calibration of "
        "H2; rescale distances by (1 +/- max(FAC))*D")
    parser.add_option("--l1-calibration-uncertainty", metavar="FAC",
        type="float", default=0.,
        help="fractional uncertainty in the DC calibration of "
        "L1; rescale distances by (1 +/- max(FAC))*D")
    parser.add_option("--verbose", action="store_true", default=False,
        help="extra information to the console")

    options, arguments = parser.parse_args()

    # check that mandatory switches are present
    for opt in ("relic_onsource", "relic_offsource", "relic_injections"):
        if getattr(options, opt) is None:
            raise ValueError, "%s is required" % opt.replace("_", "-")

    return options, arguments

################################################################################
# parse arguments
opts, args = parse_args()

##############################################################################
# HTML initialization
InspiralUtils.initialise(opts, __prog__, __version__)
html_footer = ""

##############################################################################
# read in bin definitions and loudest stats
# All vetoes have been taken into account

html_footer += InspiralUtils.message(opts,
    "Reading in bin definitions and loudest statistics...")
statistic, mc_bins, m2_bins, D_bins, onsource_loudest_by_mc \
    = pickle.load(open(opts.relic_onsource))
statistic, mc_bins, m2_bins, D_bins, offsource_loudest_by_trial_mc \
    = pickle.load(open(opts.relic_offsource))
statistic, mc_bins, m2_bins, D_bins, num_sims_by_inj_m2_D, \
    inj_loudest_by_inj_mc_m2_D = pickle.load(open(opts.relic_injections))

num_sims_by_m2_D = num_sims_by_inj_m2_D.sum(axis=0)
num_sims_by_m2 = num_sims_by_m2_D.sum(axis=1)
inj_loudest_by_inj_mc_m2 = inj_loudest_by_inj_mc_m2_D.max(axis=3)

# print summary
html_footer += InspiralUtils.message(opts,
    "on-source loudest combined " + statistic + " by mchirp category:")
for low, hi, stat in zip(mc_bins.lower(), mc_bins.upper(),
                         onsource_loudest_by_mc):
    html_footer += InspiralUtils.message(opts, "  [%f, %f): %f" % (low, hi, stat))
html_footer += InspiralUtils.message(opts,
    "Number of injections read: %d" % len(inj_loudest_by_inj_mc_m2_D))

##############################################################################
# Take calibration systematics into account by rescaling D bins
# NB: Does not check what IFOs participated in the GRB search
calib_fac = 1 + max((opts.h1_calibration_uncertainty,
                     opts.h2_calibration_uncertainty,
                     opts.l1_calibration_uncertainty))
D_bins.min /= calib_fac
D_bins.max /= calib_fac
D_bins.delta /= calib_fac

##############################################################################
# initialize background estimation function
compute_log_pc0_by_mc = SimpleExpExtrapEstimator(offsource_loudest_by_trial_mc,
    2)

# Example of how to switch to constant extrapolator
#compute_log_pc0_by_mc = ConstantBackgroundEstimator(offsource_loudest_by_trial_mc,
#    0.5 / offsource_loudest_by_trial_mc.shape[0])

################################################################################
# compute the likelihoods of the loudest on-source coincidences by m2

log_pc0_by_mc = compute_log_pc0_by_mc(onsource_loudest_by_mc)

html_footer += InspiralUtils.message(opts, "ln(p(c(mchirp) | 0)):")
for low, hi, pc0 in zip(mc_bins.lower(), mc_bins.upper(), log_pc0_by_mc):
    html_footer += InspiralUtils.message(opts, "  [%f, %f): %f" % (low, hi, pc0))

log_pch_by_mc_m2 = compute_log_pch_by_mc_m2(inj_loudest_by_inj_mc_m2,
    num_sims_by_m2, onsource_loudest_by_mc)

html_footer += InspiralUtils.message(opts, "ln(p(c(mchirp) | h(m2))):")
for low, hi, pch_by_m2 in zip(mc_bins.lower(), mc_bins.upper(), log_pch_by_mc_m2):
    html_footer += InspiralUtils.message(opts,
        "  [%f, %f): %s" % (low, hi, str(pch_by_m2)))

log_L_mc_m2 = log_pch_by_mc_m2 - log_pc0_by_mc[:, None]

# Examples of how to swap in IFAR or pure effective SNR
# log_L_mc_m2 = numpy.ones(log_pch_by_mc_m2.shape) / log_pc0_by_mc[:, None]
# log_L_mc_m2 = onsource_loudest_by_mc[:, None].repeat(len(m2_bins), axis=1)

html_footer += InspiralUtils.message(opts, "ln(L(c(mchirp)) | h(m2)):")
for low, hi, pch_by_m2 in zip(mc_bins.lower(), mc_bins.upper(), log_L_mc_m2):
    html_footer += InspiralUtils.message(opts,
        "  [%f, %f): %s" % (low, hi, str(pch_by_m2)))

# for each m2 bin, find the max L=p(c|h)/p(c|0)
mc_ind_by_m2 = log_L_mc_m2.argmax(axis=0)
mc_m2_map = (mc_ind_by_m2, range(len(m2_bins)))
max_log_L_by_m2 = log_L_mc_m2[mc_m2_map]

################################################################################
# compute P(Lambda > Lambda_0(m2) | 0)

num_offsource_trials = offsource_loudest_by_trial_mc.shape[0]

# tabulate off-source likelihoods
offsource_likelihood_by_trial_m2 = numpy.zeros(\
    (num_offsource_trials, len(m2_bins)), dtype=numpy.float32)
for i, offsource_loudest_by_mc in enumerate(offsource_loudest_by_trial_mc):
    off_log_pc0_by_mc = compute_log_pc0_by_mc(offsource_loudest_by_mc)
    off_log_pch_by_mc_m2 = compute_log_pch_by_mc_m2(inj_loudest_by_inj_mc_m2,
        num_sims_by_m2, offsource_loudest_by_mc)
    off_log_L_mc_m2 = off_log_pch_by_mc_m2 - off_log_pc0_by_mc[:, None]
    offsource_likelihood_by_trial_m2[i, :] = off_log_L_mc_m2.max(axis=0)

# in each m2 bin, find what fraction of trials are louder than the on-source
pL0_by_m2 = \
    (offsource_likelihood_by_trial_m2 > max_log_L_by_m2[None, :])\
    .sum(axis=0, dtype=float) / num_offsource_trials

# for diagnostics, find P(L > L_* | 0) for various L_*
offsource_likelihood_by_trial_m2.sort(axis=0)
offsource_pL0_by_trial = numpy.arange(num_offsource_trials)[::-1] \
    / num_offsource_trials

################################################################################
# compute P(Lambda > Lambda_0(m2) | h(m2, D))
# FIXME: Some of this section is convoluted because of the 4-D representation
# of inj_loudest_by_inj_mc_m2_D.
# FIXME: This can be done in O(N_{inj}) time because L is monotonic with SNR
# within an mc bin, so a threshold in L can be converted to a threshold in SNR
# for each mc bin.

log_L_by_inj_mc = []
log_pc0_by_inj_mc = []
log_pch_by_inj_mc = []
rho_by_inj_mc = []
inj_louder_count_by_m2_D = numpy.zeros((len(m2_bins), len(D_bins)), dtype=int)
for inj_trial_loudest_by_mc_m2_D in inj_loudest_by_inj_mc_m2_D:

    # find D bin
    m2_D_mask = (inj_trial_loudest_by_mc_m2_D != 0).sum(axis=0, dtype=bool)
    if m2_D_mask.sum() == 0:
        continue
    # sanity check: one m2, D pair contains something other than zero
    assert m2_D_mask.sum() == 1, "only one (m2, D) bin should be nonzero"
    m2_ind = m2_D_mask.sum(axis=1, dtype=bool).nonzero()[0]
    D_ind = m2_D_mask.sum(axis=0, dtype=bool).nonzero()[0]

    # compute likelihood of this (inj + noise) instance arising from m2'
    inj_trial_loudest_by_mc_m2 = inj_trial_loudest_by_mc_m2_D.max(axis=2)
    inj_trial_loudest_by_mc = inj_trial_loudest_by_mc_m2.max(axis=1)

    inj_trial_log_pc0_by_mc = compute_log_pc0_by_mc(inj_trial_loudest_by_mc)

    # this inner loop makes the algorithm O(n^2)
    inj_trial_log_pch_by_mc_m2 = \
        compute_log_pch_by_mc_m2(inj_loudest_by_inj_mc_m2,
        num_sims_by_m2, inj_trial_loudest_by_mc)

    inj_trial_log_L_by_mc_m2 = inj_trial_log_pch_by_mc_m2 - inj_trial_log_pc0_by_mc[:, None]

    # Examples of how to swap in IFAR or pure effective SNR
    # inj_trial_log_L_mc_m2 = numpy.ones(inj_trial_log_pch_by_mc_m2.shape) / \
    #     inj_trial_log_pc0_by_mc[:, None]
    # inj_trial_log_L_mc_m2 = inj_trial_loudest_by_mc[:, None]\
    #     .repeat(len(m2_bins), axis=1)

    inj_trial_log_L = inj_trial_log_L_by_mc_m2[:, m2_ind].max()

    # record if anything is louder than the loudest on-source coinc for this m2
    if inj_trial_log_L > max_log_L_by_m2[m2_ind]:
        inj_louder_count_by_m2_D[m2_D_mask] += 1

    # record diagnostics
    if m2_ind == 8:
        log_L_by_inj_mc.append(inj_trial_log_L_by_mc_m2[:, m2_ind].squeeze())
        log_pc0_by_inj_mc.append(inj_trial_log_pc0_by_mc)
        log_pch_by_inj_mc.append(inj_trial_log_pch_by_mc_m2[:, m2_ind]\
            .squeeze())
        rho_by_inj_mc.append(inj_trial_loudest_by_mc)
log_L_by_inj_mc = numpy.array(log_L_by_inj_mc)
log_pc0_by_inj_mc = numpy.array(log_pc0_by_inj_mc)
log_pch_by_inj_mc = numpy.array(log_pch_by_inj_mc)
rho_by_inj_mc = numpy.array(rho_by_inj_mc)

pLh_by_m2_D = inj_louder_count_by_m2_D / (num_sims_by_m2_D + 1e-10)

################################################################################
# Take MC errors into account

MC_sigma = numpy.sqrt(pLh_by_m2_D * (1 - pLh_by_m2_D) / num_sims_by_m2_D)

################################################################################
# plots
fnameList = []
tagList = []

c_in_E = r"c \in \mathcal{E}(c_0)"
c_in_E_m2 = r"c \in \mathcal{E}(c_0(m_2))"
mc_latex = r"\langle \hat{M}_\mathrm{chirp} \rangle"
mc_ranges = zip(mc_bins.lower(), mc_bins.upper())

## mchirp vs loudest stat horizontal bar graph
text = "mchirp vs loudest statistic"

plot = plotutils.NumberVsBinBarPlot(statistic.replace("_", r"\_"),
    "$" + mc_latex + "$", "Loudest statistics by mchirp")
plot.add_content(mc_bins, onsource_loudest_by_mc)
plot.finalize(orientation="horizontal")

# add p(c|0) on top as text
for mc, log_pc0 in zip(mc_bins.centres(), log_pc0_by_mc):
    plot.ax.text(0.5, mc, r"$p(" + c_in_E + r"\,|\,0) = %7.5f$" % numpy.exp(log_pc0))

if plot.ax.get_xlim()[1] < 20:
    plot.ax.set_xlim(xmax=20)

plot.ax.set_ylim((mc_bins.min, mc_bins.max))

# add mchirp dividers
for divider in mc_bins.boundaries:
    plot.ax.plot(plot.ax.get_xlim(), (divider, divider),
        "k--", label="_nolegend_")

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "loudest_stats_by_mchirp")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## injection count vs (m2, D) image
text = "Injection count"

plot = plotutils.ImagePlot("$m_2\ (M_\odot)$", "$D\ \mathrm{(Mpc)}$",
    r"Injections made")
plot.add_content(num_sims_by_m2_D.T, m2_bins, D_bins)
plot.finalize()

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "injection_count_by_m2_D")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## p(c|h) vs rho for each mc bin
text = "ln p(c|h) vs rho for each mc bin for m2 = " \
    + str(m2_bins.centres()[8])

plot = plotutils.SimplePlot(r"$\rho_\mathrm{eff}$", "",
    r"$\ln p(" + c_in_E + r"\,|\,h)\textrm{ vs stat for }m_2 = %s$" \
    % str(m2_bins.centres()[8]))
for mc_ind, mc_range in enumerate(mc_ranges):
    x_data = rho_by_inj_mc[:, mc_ind]
    y_data = log_pch_by_inj_mc[:, mc_ind]
    plot.add_content(x_data, y_data, marker=".", linestyle="None",
        label="$" + mc_latex + r"\in [%4.2f, %4.2f)$" % mc_range)

plot.finalize(loc=4)

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "log_pch_vs_rho")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## p(c|0) vs rho for each mc bin
text = "ln p(c|0) vs rho for each mc bin for m2 = " \
    + str(m2_bins.centres()[8])

plot = plotutils.SimplePlot(r"$\rho_\mathrm{eff}$", "",
    r"$\ln p(" + c_in_E + r"\,|\,0)\textrm{ vs stat for }m_2 = %s$" \
    % str(m2_bins.centres()[8]))
for mc_ind, mc_range in enumerate(mc_ranges):
    x_data = rho_by_inj_mc[:, mc_ind]
    y_data = log_pc0_by_inj_mc[:, mc_ind]
    plot.add_content(x_data, y_data, marker=".", linestyle="None",
        label="$" + mc_latex + r"\in [%4.2f, %4.2f)$" % mc_range)

plot.finalize(loc=3)

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "log_pc0_vs_rho")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## L vs rho for each mc bin
text = "ln L vs rho for each mc bin for m2 = " + str(m2_bins.centres()[8])

plot = plotutils.SimplePlot(r"$\rho_\mathrm{eff}$", "",
    r"$\ln \Lambda\textrm{ vs stat for }m_2 = %s$" % str(m2_bins.centres()[8]))
for mc_ind, mc_range in enumerate(mc_ranges):
    x_data = rho_by_inj_mc[:, mc_ind]
    y_data = log_L_by_inj_mc[:, mc_ind]
    plot.add_content(x_data, y_data, marker=".", linestyle="None",
        label="$" + mc_latex + r"\in [%4.2f, %4.2f)$" % mc_range)

plot.finalize(loc=4)

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "log_L_vs_rho")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## for L(c|h) vs (m2, mc) image
# TODO: before and after MC and calibration systematics
text = "L(c(mc)|h(m2))"

plot = plotutils.ImagePlot(\
    r"$m_2\ (M_\odot)$",
    r"$" + mc_latex + r"(M_\odot;\textrm{ not to scale)}$",
    r"$\ln \Lambda(c(" + mc_latex + r") \in \mathcal{E}(c_0(m2))\,|\,h(m_2))$")
plot.add_content(log_L_mc_m2, m2_bins, mc_bins)
plot.finalize()

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "oldlog_L_mc_m2")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## L(c|h) vs m2
# TODO: before and after MC and calibration systematics
text = "ln L(c(mc)|h(m2))"

plot = plotutils.SimplePlot(\
    r"$m_2\ (M_\odot)$",
    r"$\ln \Lambda(c \in \mathcal{E}(c_0(m2))\,|\,h(m_2))$",
    r"$\ln \Lambda(c \in \mathcal{E}(c_0(m2))\,|\,h(m_2))$")
for mc_range, log_L_by_m2 in zip(mc_ranges, log_L_mc_m2):
    plot.add_content(m2_bins.centres(), log_L_by_m2,
                     label=r"$" + mc_latex + r"\in [%4.2f, %4.2f)$" % mc_range)
plot.finalize(loc=4)
plot.ax.set_ylim(ymin=-0.5)

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "log_L_mc_m2")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## P(L > L_0 | 0) vs m2
text = "P(L(m_2) > L_0(m_2) | 0) vs m_2"

plot = plotutils.SimplePlot(\
    r"$m_2\ (M_\odot)$",
    r"$P(\Lambda(m_2) > \Lambda_0(m_2) | 0)$",
    r"$P(\Lambda(m_2) > \Lambda_0(m_2) | 0)$")
plot.add_content(m2_bins.centres(), pL0_by_m2)
plot.finalize(loc=4)
plot.ax.set_ylim((0, 1))

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "pL0_by_m2")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## P(L > L_* | 0) vs L_*
text = "P(L(m_2) > L_*(m_2) | 0) vs ln L_*"

plot = plotutils.SimplePlot(\
    r"$\ln \Lambda_*$",
    r"$P(\Lambda(m_2) > \Lambda_* | 0)$",
    r"$P(\Lambda(m_2) > \Lambda_* | 0) \textrm{ vs } \ln \Lambda_*$")
m2_ranges = zip(m2_bins.lower(), m2_bins.upper())
for m2_range, Lstar_by_trial in \
    zip(m2_ranges, offsource_likelihood_by_trial_m2.T):
    plot.add_content(Lstar_by_trial, offsource_pL0_by_trial,
                     label=r"$m_2 \in [%4.1f, %4.1f) M_\odot$" % m2_range)
plot.finalize(loc=4)
plot.ax.set_ylim((0, 1))

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "pL0_by_L")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()


## p(c|h) from max L mchirp bins vs (m2, D) image
text = "p(L(m_2) > L_0(m_2)|h(m2, D)) before MC errors"

plot = plotutils.ImagePlot(r"$m_2\ (M_\odot)$", r"$D\ \mathrm{(Mpc)}$",
    r"$P(\Lambda(m_2) > \Lambda_0(m_2)\,|\,h(m_2, D))$")
plot.add_content(pLh_by_m2_D.T, m2_bins, D_bins)
plot.finalize()

# XXX: Hack around an apparent matplotlib API backwards-incompatibility
# When all clusters have 0.90 or higher, remove the try-except.
try:
  image = [c for c in plot.ax.get_children() \
           if isinstance(c, matplotlib.image.AxesImage)][0]
  image.set_clim((0, 1))
except AttributeError:
  pass

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "pLh_by_m2_D")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()


## p(c|h) from max L mchirp bins vs (m2, D) image
text = "p(L(m_2) > L_0(m_2)|h(m2, D)) after 90% MC errors"

num_sigmas = stats.norm.ppf(0.9)
plot = plotutils.ImagePlot(r"$m_2\ (M_\odot)$", r"$D\ \mathrm{(Mpc)}$",
    r"$P(\Lambda(m_2) > \Lambda_0(m_2)\,|\,h(m_2, D)) "
    r"\textrm{ incl. 90\% MC uncertainty}$")
plot.add_content(pLh_by_m2_D.T - num_sigmas * MC_sigma.T, m2_bins, D_bins)
plot.finalize()

# XXX: Hack around an apparent matplotlib API backwards-incompatibility
# When all clusters have 0.90 or higher, remove the try-except.
try:
  image = [c for c in plot.ax.get_children() \
           if isinstance(c, matplotlib.image.AxesImage)][0]
  image.set_clim((0, 1))
except AttributeError:
  pass

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "pLh_afterMCerr_by_m2_D")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()

## upper limit contours (m2, D) image
text = "(m2, D) exclusion plot including MC error"

plot = plotutils.FillPlot(r"$m_2\ (M_\odot)$", r"$D\ \mathrm{(Mpc)}$",
    "Exclusion regions")

exclusion_x = m2_bins.lower()
zero = numpy.zeros(len(m2_bins), dtype=float)

for exclusion_level in (0.25, 0.5, 0.75, 0.9):
    num_sigmas = stats.norm.ppf(exclusion_level)
    exclusion_y = get_level_crossings(pLh_by_m2_D - num_sigmas * MC_sigma,
        exclusion_level, D_bins)
    tmpx, tmpy = viz.makesteps(exclusion_x, zero, exclusion_y)
    plot.add_content(tmpx, tmpy,
        label=str(int(exclusion_level * 100)) + r"\% exclusion")

plot.finalize()
plot.ax.set_ylim((0, D_bins.max))

if opts.enable_output:
    fname = InspiralUtils.set_figure_name(opts, "exclusion_by_m2_D")
    fname_thumb = InspiralUtils.savefig_pylal(fname, fig=plot.fig)
    fnameList.append(fname)
    tagList.append(text)
if not opts.show_plot:
    plot.close()


#############################################################################
# Generate HTML and cache file
if opts.enable_output:
    html_filename = InspiralUtils.write_html_output(opts, sys.argv[1:],
        fnameList, tagList, comment=html_footer)
    InspiralUtils.write_cache_output(opts, html_filename, fnameList)

    if opts.html_for_cbcweb:
        html_filename_publish = InspiralUtils.write_html_output(opts,
            sys.argv[1:], fnameList, tagList, comment=html_footer, cbcweb=True)

if opts.show_plot:
    pylab.show()

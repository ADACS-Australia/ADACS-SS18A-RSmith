#!/usr/bin/python
#
# Copyright (C) 2007  Patrick Brady, Nickolas Fotopoulos
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#

from __future__ import division  # float division for integers

import sys
import os
import optparse
import glob
import re

import numpy
numpy.seterr('raise')  # throw an exception on floating point errors

from glue import segments
from glue import segmentsUtils
from glue.ligolw import lsctables
import pylal.date
from pylal import CoincInspiralUtils
from pylal import SnglInspiralUtils
from pylal import SimInspiralUtils

__author__ = "Patrick Brady <patrick@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]

##############################################################################
# Speed hack
##############################################################################
"""
lal.LIGOTimeGPS is horrifically slow.  Replace its use with the C version
from pylal.date.  This speeds up vetoes by an order of magnitude or so,
about 10\% of the total run time of this program in my tests.
"""

lsctables.LIGOTimeGPS = pylal.date.LIGOTimeGPS

##############################################################################
# Define a Square Array
##############################################################################
def square(xedges, yedges, coincTriggers, simtypeflag, calibration=1.0):
  """
  Histogram coincTriggers in the mass1-distance plane.

  @param xedges: bin boundaries for parameter x
  @param yedges: bin boundaries for parameter y
  @param coincTriggers: data to histogram
  @param simtypeflag: "missed" or "found"
  """
  ng_x_y = zeros(shape=(len(yedges), len(xedges)), dtype=int)
  xstep = xedges[1] - xedges[0]
  ystep = yedges[1] - yedges[0]

  for coinc in coincTriggers:
    if ((simtypeflag == "found" and coinc.stat >= 0) or\
        (simtypeflag == "missed" and coinc.stat < 0)):
      xdata = coinc.sim.mass1
      """@ivar xdata:  array of data for parameter x"""
      ydata = coinc.sim.distance * calibration
      """@ivar ydata:  array of data for parameter y"""
      k = int((xdata-xedges[0]) // xstep)
      l = int((ydata-yedges[0]) // ystep)

      if (k >= 0 and k < len(xedges)) and (l >= 0 and l < len(yedges)):
        ng_x_y[l][k] += 1

  return ng_x_y

#######################################################################
def get_contour(xedges, yedges, pcsignalsq, confidence,
                do_smooth_contour=False, width=3.0):
  """
  Return the vertices of a polygon bounding the region with
  pcsignalsq < confidence.  This is performed conservatively.  We assume
  uniform, linear spacing.  Optionally, smooth the contour with a 1-D Gaussian
  with a sigma of width.
  """
  clevel=zeros(len(xedges), dtype=float)
  dy = yedges[1]-yedges[0]
  centers = asarray(yedges) + dy/2
  
  # derive an exclusion distance for each mass bin
  for i in xrange(len(xedges)):
    # start the distance loop at 1 to handle a threshold crossing in the first
    # (index 0) bin; in this case, the code as written will correctly
    # extrapolate, rather than interpolate.
    for j in xrange(1, len(yedges)):
      if pcsignalsq[j,i]>confidence: 
        slope = dy / (pcsignalsq[j, i] - pcsignalsq[j-1, i])
        clevel[i] = centers[j-1] + (confidence-pcsignalsq[j-1,i])*slope
        break

  if do_smooth_contour:
    gauss = exp( - 0.5 * ( ( xedges - mean( xedges ) ) / width )**2  )\
      / sqrt( 2.0 * pi ) / width
    yarray= convolve(asarray(clevel),gauss,mode=1) 	 
    yarray = clevel[0] * yarray / yarray[0]
  else:
    yarray = clevel
  
  tmpx,tmpy = makesteps(xedges, zeros(len(xedges), dtype=float), yarray) 	 

  return tmpx,tmpy,yarray

class FitError(Exception):
    pass

def fit_sigmoids(xedges, yedges, image, new_yedges=None):
    """
    Apply a (logistic) sigmoid fit to each mass slice and return a replacement
    pcsignalsq, sampled on the grid new_yedges.  If new_yedges is None,
    the output will be sampled on yedges.
    """
    # make sure that we understand the image orientation
    assert image.shape[0] == len(yedges)
    assert image.shape[1] == len(xedges)
    
    if new_yedges is None:
      new_yedges = yedges
    
    old_dy = yedges[1] - yedges[0]
    new_dy = new_yedges[1] - new_yedges[0]
    
    old_centers = yedges + old_dy / 2
    new_centers = new_yedges + new_dy / 2
    
    from scipy import optimize
    
    # logistic sigmoid function
    fit_func = lambda p, x: (1 + tanh(p[0]*(x-p[1])/2)) / 2
    err_func = lambda p, x, y: fit_func(p, x) - y
    
    # initial guess
    p0 = [0.1, 15]
    
    # fit and resample
    output = zeros((len(new_yedges), len(xedges)), dtype=float)
    for i in xrange(len(xedges)):
        vals = image[:, i]
        
        # HACK: fill in gaps at the top; anything is better than 0
        ind = (vals == 0)  # find zeros
        ind[:len(vals)//2] = False  # ignore bottom half
        vals[ind] = 1  # set to 1
        
        p1, err_flag = optimize.leastsq(err_func, p0[:], args=(old_centers, vals))
        if err_flag != 1:
            raise FitError, "sigmoid fit did not converge"
        
        # sample at the prescribed distances
        output[:, i] = fit_func(p1, new_centers)
    return output

##############################################################################
usage = """%prog [options]

GRB Likelihood calculation

We attempt to compute the posterior distribution

p[ h(lambda) | c ]

where c is the event candidate and h(lambda) is a signal with
parameters lambda.
"""

parser = optparse.OptionParser(usage=usage, version="%prog CVS $Id$ ")
parser.add_option("-g", "--on-source-glob",
  help="GLOB on-source thinca files to read")
parser.add_option("-m", "--missed-glob",
  help="GLOB missed injection files to read")
parser.add_option("-u", "--found-glob",
  help="GLOB found injection files to read")
parser.add_option("-e", "--epsilon", type="float", default=0.,
  help="if metric distance squared > EPSILON, discard")
parser.add_option("-n", "--ntrials", type="int", default=0,
  help="number off source segments")
parser.add_option("-l", "--loudest-event-cut", action="store_true",
  default=False, help="evaluate probabilities with a loudest-event cut")
parser.add_option("-c", "--min-loudest-event-stat", type="float",
    default=0.0, help="if there are no candidates, use this as the loudest event statistic")
parser.add_option("-P", "--figure-type", default="ps",
  help="generate figures with this extension (e.g. ps or png")
parser.add_option("-x", "--min-snr", type="float",
  help="minimum value of snr on plot")
parser.add_option("-X", "--max-snr", type="float",
  help="maximum value of snr on plot")
parser.add_option("-o", "--open-box", action="store_true", default=False,
  help="run with the open box")
parser.add_option("-s", "--show-plot", action="store_true", default=False,
  help="display the figures on the terminal")
parser.add_option("-v", "--verbose", action="store_true", default=False,
  help="verbose debugging output")
parser.add_option("-B", "--h1-triggers",action="store_true", default=False,\
  help="input files contain triggers from H1")
parser.add_option("-C", "--h2-triggers",action="store_true", default=False,\
  help="input files contain triggers from H2")
parser.add_option("-D", "--l1-triggers",action="store_true", default=False,\
  help="input files contain triggers from L1")
parser.add_option("-E", "--g1-triggers",action="store_true", default=False,\
  help="input files contain triggers from G1")
parser.add_option("-S", "--statistic", default='snr',
  help="choice of statistic used in making plots, valid arguments are: "
       "snr (DEFAULT), snr_over_chi, s3_snr_chi_stat, effective_snr, "
       "bitten_l, bitten_lsq")
parser.add_option("-V","--veto-file",
  help="read in segments from FNAME (assumed segwizard format)")
parser.add_option("-F","--full-segs",
  help="read in segments from FNAME (assumed segwizard format)")
parser.add_option("-O","--on-source-segs",
  help="read in segments from FNAME (assumed segwizard format)")
parser.add_option("-N", "--nbins", type="float", default=20,\
  help="number of bins")
parser.add_option("-a", "--min-mass", type="float", default=0.5,\
  help="minimum value for the mass range in solar masses")
parser.add_option("-b", "--max-mass", type="float", default=20.0,\
  help="maximum value for the mass range in solar masses")
parser.add_option("-d", "--bins-mass", type="float", default=8.0,\
  help="number of bins for the mass range")
parser.add_option("-f", "--min-distance", type="float", default=1.0,\
  help="minimum value for the distance range in Mpc")
parser.add_option("-i", "--max-distance", type="float", default=20.0,\
  help="maximum value for the distance range in Mpc")
parser.add_option("-j", "--bins-distance", type="float",default=13.0,\
  help="number of bins for the distance range")

# efficiency errors
parser.add_option("-H","--h-calibration",action="store",type="float",
    default=None,metavar=" H_CAL",
    help="systematic error in h calibration, rescale distances D->(1+/-CAL)*D")
parser.add_option("-L","--l-calibration",action="store",type="float",
    default=None,metavar=" L_CAL",
    help="systematic error in y calibration, rescale distances D->(1+/-CAL)*D")

parser.add_option("-k","--known-distance",action="store",type="float",
    default=None, metavar=" KD",
    help="Distance at which GRB is thought to be in Mpc")
parser.add_option("-K", "--kd-epsilon", type="float", default=1e-6,
  help="for the known-distance calculation, accept injections at distances "\
       "in the range [KD - KD_EPSILON, KD + KD_EPSILON] (default: %default)")

parser.add_option("-y", "--fit-sigmoid", action="store_true", default=False,
  help="for each mass bin, fit a logistic sigmoid to the 1-D probability" \
       " distribution in distance")
parser.add_option("-Y", "--fit-oversample-factor", type=float, default=1.0,
  help="after fit parameters have been found, resample the distance a factor "\
       "of FIT_OVERSAMPLE_FACTOR more finely")


(opts,args) = parser.parse_args()

if opts.on_source_glob is None:
  print >>sys.stderr, "Must specify a GLOB of on-source files to read"
  print >>sys.stderr, "Enter 'plotthinca --help' for usage"
  sys.exit(2)

if (opts.full_segs is None) or (opts.on_source_segs is None):
  print >>sys.stderr, "There must be full-segs and on-source-segs"
  sys.exit(2)

# check that statistic is OK:
if opts.statistic not in ('snr', 'snr_over_chi', 's3_snr_chi_stat',
    'effective_snr', 'bitten_l', 'bitten_lsq'):
  print >>sys.stderr, "--statistic must be one of"
  print >>sys.stderr, "(snr|snr_over_chi|s3_snr_chi_stat|effective_snr|bitten_l|bitten_lsq)"
  sys.exit(2)

# check plot type; strip leading periods
opts.figure_type = opts.figure_type.strip(".")
assert opts.figure_type in ("png", "ps", "eps", "svg")

##############################################################################
# Set up plots

# Change to Agg back-end if show() will not be called
if not opts.show_plot:
  import matplotlib
  matplotlib.use('Agg')
from pylab import *
from pylal.viz import makesteps
rc('text', usetex=True)

# Adapted from http://www.scipy.org/Cookbook/Matplotlib/LaTeX_Examples
if opts.figure_type in ("ps", "eps"):
  fig_width_pt = 245.26653  # Get this from LaTeX using \showthe\columnwidth
  inches_per_pt = 1.0/72.27               # Convert pt to inch
  golden_mean = (sqrt(5)-1.0)/2.0         # Aesthetic ratio
  fig_width = fig_width_pt*inches_per_pt  # width in inches
  fig_height = fig_width*golden_mean      # height in inches
  fig_size =  [fig_width, fig_height]
  
  params = {'backend': 'ps',
  'font.size': 10,
  'axes.labelsize': 10,
  'text.fontsize': 10,
  'xtick.labelsize': 10,
  'ytick.labelsize': 10,
  'figure.figsize': fig_size}
  rcParams.update(params)

#####################################################################
# initialize some basic information

statistic = CoincInspiralUtils.coincStatistic(opts.statistic)

pat = re.compile(r"^(\w\d)_triggers")
ifo_list = [opt[:2].upper() for opt in opts.__dict__ \
            if (pat.match(opt) is not None) and getattr(opts, opt)]

ifo_combos = CoincInspiralUtils.get_ifo_combos(ifo_list)

#####################################################################
# Read in all the segment lists
fullseglist = segmentsUtils.fromsegwizard(open(opts.full_segs))
onsourceseglist = segmentsUtils.fromsegwizard(open(opts.on_source_segs))
trial_length = abs(onsourceseglist)

# take padding into account
fullseglist &= segments.segmentlist([fullseglist.extent().contract(72)])

# take veto into account
if opts.veto_file:
  vetolist = segmentsUtils.fromsegwizard(open(opts.veto_file))
  fullseglist -= vetolist

# define off-source segments
offsourceseglist = fullseglist - onsourceseglist

# make a list of off source trials
trial_segs = segments.segmentlist()
for seg in offsourceseglist:
  trial_segs.extend(segmentsUtils.segmentlist_range(seg[0], seg[1], trial_length))
num_trials = len(trial_segs)

if opts.verbose:
  print "The length of each trial is %d" % trial_length
  print "The number of trial segments is %i" % num_trials

#####################################################################
# read in on-source triggers
coincfiles = glob.glob(opts.on_source_glob)
inspTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles(coincfiles)

# perform the veto
if inspTriggers and opts.veto_file:
  inspTriggers = inspTriggers.veto(vetolist)

# construct the off source listing, including vetoes and quantization
offsourceTriggers = CoincInspiralUtils.coincInspiralTable(\
    inspTriggers.veto((~trial_segs).coalesce()), statistic)

# construct the coincs
if opts.open_box:
  coincTriggers = CoincInspiralUtils.coincInspiralTable(\
      inspTriggers.veto(offsourceseglist),statistic)
else:
  coincTriggers = CoincInspiralUtils.coincInspiralTable()
  coincTriggers.append(offsourceTriggers[0])

if opts.max_snr is None:
  if len(inspTriggers) > 0:
    xhigh = max(inspTriggers.get_column(opts.statistic))
  else:
    xhigh = 50.0
else:
  xhigh = opts.max_snr + 1

if opts.min_snr is None:
  if len(inspTriggers) > 0:
    xlow = min(inspTriggers.get_column(opts.statistic))
  else:
    xlow = 1.0
else:
  xlow = opts.min_snr

#####################################################################
# make the plot background and foreground
delta=xhigh-xlow
ds=0.5*delta/opts.nbins
bins = arange( xlow, xhigh, delta/opts.nbins)

# build the histogram. The return values are
#   the count per bin
#   the bin (lower) edges
#   the patches
# Note: the matplotlib hist function assumes that these are the lower
# edges of the bins. I have not looked into the code yet to confirm
# how it handles that last bin. Since all other bins are equally
# spaced, this doesn't really matter for us.
[zero_dist,bin,info] = hist(coincTriggers.getstat(),bins)

# add a zero to the beginning of the array containing count; this
# method is so that the cumulative distribution is plotted correctly
# as we'll see...
zero_dist = concatenate( (zeros(1),zero_dist) )

# construct the cumulative distribution. Here's what is done:
#   * sum up the total count - unaffected by the zeros(1) added above
#   * subtract from that the cumulative sum of the modified array
#   * the first element of the new array is the total number of events
#   above threshold
#   * note that the cumsum only creates an array with the same length as
#   bins
cum_dist_zero = numpy.sum(zero_dist)-cumsum(zero_dist[0:bin.size])
cum_dist_offsource = []
for seg in trial_segs:
  offsourcetrial = offsourceTriggers.getTriggersInSegment(seg) 
  [num_offsource,bin,info] = hist(offsourcetrial.getstat(),bins)
  num_offsource = concatenate( (zeros(1),num_offsource) )
  cum_offsource = sum(num_offsource)-cumsum(num_offsource[0:bin.size])
  # adds a row to the cum_dist_offsource
  cum_dist_offsource.append(cum_offsource)

cum_dist_offsource = array(cum_dist_offsource)
#cum_dist_offsource = reshape(array(cum_dist_offsource), \
      #(len(trial_segs),opts.nbins))

# takes the mean over rows for each column
offsource_mean = mean(cum_dist_offsource)
# takes the std over rows for each column
offsource_std = std(cum_dist_offsource)

####################################################################
# Plot the standard histogram of expected number of events based on
# the off source times.
clf()
figure()
if opts.figure_type in ("ps", "eps"):
  axes([0.127,0.21,0.95-0.128,0.95-0.24])
hold(True)
semilogy((bins+ds)**2,cum_dist_zero+0.0001,'r^',markerfacecolor="b",markersize=12)
semilogy((bins+ds)**2,offsource_mean, 'r+', markersize=12)

# The following loop is needed to make the plot nice when making
# logarithmic filled regions.
offsource_min = []
for i in range( len(offsource_mean) ):
  offsource_min.append( max(offsource_mean[i] - offsource_std[i], 0.0001) )
  offsource_mean[i] = max(offsource_mean[i], 0.0001)
tmpx,tmpy = makesteps(bins,offsource_min,offsource_mean+offsource_std)
p=fill(tmpx**2,tmpy, facecolor='y')
setp(p, alpha=0.3)
grid(True)
axis([ xlow*xlow, (xhigh-2*ds)*(xhigh-2*ds), 0.001, 10.0])
xlabel(r"$\rho_{\mathrm{eff}}^2$")
ylabel(r"Expected \# of events")

min_snr = min([t.stat for t in offsourceTriggers if t.stat >= 0])
xlim([min_snr**2, xlim()[1]])

savefig("snr_dist.%s" % opts.figure_type)

if not opts.show_plot:
  close()

#####################################################################
# Plot the number of events in each off-source segment
figure()
if opts.figure_type in ("ps", "eps"):
 axes([0.125,0.2,0.95-0.125,0.95-0.22])
trigsperoffsource=cum_dist_offsource[:,0]
offsourceindex=arange(len(trigsperoffsource))
plot(offsourceindex,trigsperoffsource,'ro')
hold(True)
plot(offsourceindex,mean(trigsperoffsource)+0.0*offsourceindex,'b',lw=2)
plot(offsourceindex,mean(trigsperoffsource)+std(trigsperoffsource)+0.0*offsourceindex,'g',lw=2)
plot(offsourceindex,mean(trigsperoffsource)-std(trigsperoffsource)+0.0*offsourceindex,'g',lw=2)
grid(True)
xlabel(r"Off-source segment")
ylabel(r"Number of triggers")
savefig("triggers_per_offsource.%s" % opts.figure_type)

if not opts.show_plot:
  close()

#####################################################################
# read in the missed and found files
injTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles(\
    glob.glob(opts.found_glob) )

coincInjTriggers = CoincInspiralUtils.coincInspiralTable(\
    injTriggers,statistic)
coincInjTriggers.add_sim_inspirals( \
    SimInspiralUtils.ReadSimInspiralFromFiles(glob.glob(opts.found_glob)) )
coincInjTriggers.add_missed_sims( \
    SimInspiralUtils.ReadSimInspiralFromFiles(glob.glob(opts.missed_glob)) )

#####################################################################
# do loudest event cut
if opts.loudest_event_cut:
  # determine loudest event statistic
  if len(coincTriggers) > 0:
    loudest_stat = coincTriggers.getstat().max()
  else:
    loudest_stat = opts.min_loudest_event_stat

  # trim off-source candidate list
  lt, eq, gt = offsourceTriggers.partition_by_stat(loudest_stat)
  offsourceTriggers = gt
  offsourceTriggers.extend(eq.rows)

  # mark found injections with smaller stat as missed
  for coinc in coincInjTriggers:
    if coinc.stat < loudest_stat:
      coinc.stat = -1

#####################################################################
# histogram triggers in mass1-distance space
dx=(opts.max_mass-opts.min_mass)/opts.bins_mass
xedges = arange( opts.min_mass, opts.max_mass, dx )
dy=(opts.max_distance-opts.min_distance)/opts.bins_distance
yedges = arange( opts.min_distance, opts.max_distance, dy )
distance_correction = 1.0
if opts.h_calibration:
  distance_correction = 1.0 - opts.h_calibration
if opts.l_calibration:
  distance_correction = min( 1.0 - opts.l_calibration, distance_correction )
foundsq = square(xedges, yedges, coincInjTriggers, "found", calibration=distance_correction)
missedsq = square(xedges, yedges, coincInjTriggers, "missed", calibration=distance_correction)

#####################################################################
# if there are coincident triggers on source
if coincTriggers and not opts.loudest_event_cut:
  # loop over each candidate
  for candidate in coincTriggers:
    found_array = zeros(len(trial_segs), dtype=int)

    # cut out those triggers near to the candidate, and
    # evaluate the p(c|0) based on that
    triggers_within_epsilon = \
        offsourceTriggers.getTriggersWithinEpsilon(candidate, opts.epsilon)

    for coinc in triggers_within_epsilon:
      # index by end time of alphabetically first IFO in coinc
      end_time = getattr(coinc, coinc.get_ifos()[1][0]).end_time
      if end_time in trial_segs:
        found_array[trial_segs.find(end_time)] = 1

    if opts.verbose: print found_array
    pczero = found_array.sum() / len(trial_segs)

    # c refers to *this* candidate
    print "p(c|0) = %f" % pczero

    # cut out those injection triggers near to the candidate, and
    # evaulate the p(c|signal with lambda) based on that
    injTriggers_within_epsilon = \
        coincInjTriggers.getTriggersWithinEpsilon(candidate, opts.epsilon)

    print "Number of injections within epsilon: %f" % \
        len(injTriggers_within_epsilon)

    foundwithinepsilonsq = \
        square(xedges, yedges, injTriggers_within_epsilon, "found", calibration=distance_correction)

    pcsignalsq = foundwithinepsilonsq / (missedsq + foundsq + 1.0e-10)
else:
  # p( triggers | no signal )
  #
  # number of segments without a trigger / total number of segments
  # this is also the correct branch to take for the loudest-event analysis
  found_array = zeros(len(trial_segs), dtype=int)

  for coinc in offsourceTriggers:
    # index by end time of alphabetically first IFO in coinc
    end_time = getattr(coinc, coinc.get_ifos()[1][0]).end_time
    if end_time in trial_segs:
      found_array[trial_segs.find(end_time)] = 1

  if opts.verbose: print found_array
  pczero = 1.0 - found_array.sum() / len(trial_segs)

  # c refers to *any* candidate
  print "p(c|0) = %f" % pczero

  # p(no triggers | signal with parameters lambda)
  #
  # number of missed injections with parameters lambda / total number
  # of injections with parameter lambda
  pcsignalsq = missedsq / (missedsq + foundsq + 1.0e-10)

  mcerrorsq = sqrt( pcsignalsq * ( 1.0 - pcsignalsq ) /\
         (missedsq + foundsq + 1.0e-10) )
  
  pcsignalsq =  pcsignalsq + 1.28*mcerrorsq

  if opts.known_distance:
    kd_yedges = [opts.known_distance-opts.kd_epsilon,
                 opts.known_distance+opts.kd_epsilon]
    kd_foundsq = square(xedges, kd_yedges, coincInjTriggers, "found")
    kd_missedsq = square(xedges, kd_yedges, coincInjTriggers, "missed")
    kd_pcsignalsq = kd_missedsq / (kd_missedsq + kd_foundsq + 1.0e-10)
    kd_mcerrorsq = sqrt( kd_pcsignalsq * (1.0 - kd_pcsignalsq) /\
         (kd_missedsq + kd_foundsq + 1.0e-10))
    kd_pcsignalsq += 1.28*kd_mcerrorsq

    print "The known distance p(0|h) per mass bin are", kd_pcsignalsq[0, :]
    print "The max, known distance p(c|h) is %e" % kd_pcsignalsq[0, :].max()

  pcsignal = missedsq.sum() / (missedsq.sum() + foundsq.sum() + 1.0e-10)
  print "p(c|h) = %f" % pcsignal

#####################################################################
# generate plots

im_extent = [min(xedges), max(xedges), min(yedges), max(yedges)]

new_yedges = linspace(yedges[0], yedges[-1], opts.fit_oversample_factor*(len(yedges)-1)+1)
if opts.fit_sigmoid:
  pcsignalsq = fit_sigmoids(xedges, yedges, pcsignalsq, new_yedges)

# figure()
# if opts.figure_type in ("ps", "eps"):
#  axes([0.125,0.2,0.95-0.125,0.95-0.22])
# #imshow(pcsignalsq, origin='lower')
# hold(True)
# IC = contourf(xedges, yedges, pcsignalsq)
# xlabel(r"$m_2 (M_\odot)$")
# ylabel(r"$D (\mathrm{Mpc})$")
# colorbar(IC)

figure()
if opts.figure_type in ("ps", "eps"):
  axes([0.125,0.2,0.95-0.125,0.95-0.22])
palette = cm
IM = imshow(pcsignalsq, origin='lower', extent=im_extent,
  interpolation='nearest')
hold(True)
contour(pcsignalsq, extent=im_extent)
colorbar(IM)
axis('tight')
#axvline(candmass)
title(r'$p[\mathrm{candidate}|h(m_2,D)]$')
xlabel(r"$m_2 (M_\odot)$")
ylabel(r"$D (\mathrm{Mpc})$")
savefig("pcsignal.%s" % opts.figure_type)

if not opts.show_plot:
  close()


figure()
if opts.figure_type in ("ps", "eps"):
  axes([0.125,0.2,0.95-0.125,0.95-0.22])
palette = cm
IM = imshow(foundsq + missedsq, origin='lower', extent=im_extent,
  interpolation='nearest')
hold(True)
contour(foundsq + missedsq, extent=im_extent)
colorbar(IM)
axis('tight')
#axvline(candmass)
title('Number of injections made')
xlabel(r"$m_2 (M_\odot)$")
ylabel(r"$D (\mathrm{Mpc})$")
savefig("made-injections.%s"  % opts.figure_type)

if not opts.show_plot:
  close()


figure()
if opts.figure_type in ("ps", "eps"):
  axes([0.125,0.2,0.95-0.125,0.95-0.22])
palette = cm
IM = imshow(foundsq / (foundsq + missedsq + 1.0e-10), origin='lower',
  extent=im_extent, interpolation='nearest')
hold(True)
contour(foundsq / (foundsq + missedsq + 1.0e-10), extent=im_extent)
colorbar(IM)
axis('tight')
#axvline(candmass)
title('Fraction of injections found')
xlabel(r"$m_2 (M_\odot)$")
ylabel(r"$D (\mathrm{Mpc})$")
savefig("found-fraction.%s" % opts.figure_type)

if not opts.show_plot:
  close()


figure()
if opts.figure_type in ("ps", "eps"):
  axes([0.125,0.2,0.95-0.125,0.95-0.22])
tmpx,tmpy,yarray = get_contour(xedges,new_yedges,pcsignalsq,0.75)
p1=fill(tmpx,tmpy, facecolor=(0.75, 0.75, 0.75), label='25\% exclusion')
tmpx,tmpy,yarray = get_contour(xedges,new_yedges,pcsignalsq,0.50)
p2=fill(tmpx,tmpy, facecolor=(0.5, 0.5, 0.5), label='50\% exclusion')
tmpx,tmpy,yarray = get_contour(xedges,new_yedges,pcsignalsq,0.25)
p3=fill(tmpx,tmpy, facecolor=(0.25, 0.25, 0.25), label='75\% exclusion')
tmpx,tmpy,yarray = get_contour(xedges,new_yedges,pcsignalsq,0.1)
p4=fill(tmpx,tmpy, facecolor=(0.1, 0.1, 0.1), label='90\% exclusion')

if opts.known_distance is not None:
  axhline(y=opts.known_distance, color=(0.75, 0.75, 0.75), linewidth=2,
    label='_nolegend_')

# label bin boundaries if it's not ridiculous to do so
if len(xedges) < 15:
    xticks(xedges, map(str, xedges))

axis([min(xedges), max(xedges), 0, max(yedges)])
xlabel(r"$m_2 (M_\odot)$")
ylabel(r"$D (\mathrm{Mpc})$")
if opts.figure_type not in ("ps", "eps"):
  legend(loc="upper right")
savefig("pcsignal-slice.%s" % opts.figure_type)

if not opts.show_plot:
  close()


if opts.show_plot:
  show()

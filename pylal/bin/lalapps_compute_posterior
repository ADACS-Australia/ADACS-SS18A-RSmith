#!/usr/bin/python

# $Id$
__author__ = "Patrick Brady <patrick@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]

import sys
import os
from optparse import *
import re
import exceptions
import glob
import ConfigParser
import random
from types import *

from glue import segmentsUtils

#####################################################################
# function to read in and populate information about each time
def read_png_file(file,time):
  """
  read an file which is formatted according to plotnumgalaxies output
  return a 2-d array with each line of the file as a row in the array
  @param file:  file name
  @param time:  analyzed time associated with this file
  """
  f = open( file , "r")
  lines = f.readlines()
  f.close()

  png_data = []
  for line in lines:
    if line[0] != '#':
      png_line = get_png_array([float(val) for val in line.split()], time)
      png_data.append(png_line)
           
  return png_data

#############################################################################
def get_png_array(data,time):
  """
  extract the data from a line in a png file, and store as a dictionary
  @param data:  a list of values read from a line of a png input file
  @param time:  the analyzed time associated to this png data
  """
  param = {}
  param["mlo"]                    = data[0]
  param["mhi"]                    = data[1]
  param["ng"]                     = max(data[2],1e-7)
  param["ngprime"]                = data[3]
  param["pb"]                     = data[4]
  param["pbprime"]                = data[5]
  param["dn_lummu"]               = log( param["ng"] )
  param["dn_lumsigma_lhocal"]     = log( 1. + data[6]/param["ng"])
  param["dn_lumsigma_llocal"]     = log( 1. + data[7]/param["ng"])
  param["dn_lumsigma_magnitude"]  = log( 1. + data[8]/param["ng"])
  param["dn_lumsigma_distance"]   = log( 1. + data[9]/param["ng"])
  param["dn_lumsigma_waveform"]   = log( 1. + data[10]/param["ng"])
  param["dn_lumsigma_mc"]         = log( 1. + data[11]/param["ng"])
  param["tobs"]                   = float(time)

  return param

#############################################################################
# function to write posterior
def write_file(rate, pdf, filename):
  """
  write out a posterior file
  @param filename: output file name
  """
  outfile = open( filename, 'w' )
  print >> outfile, "# Posterior computed using lalapps_compute_posterior"
  for i in range(len(rate)):
    print >> outfile, "%e\t%e" % (rate[i], pdf[i])
  outfile.close()


#############################################################################
# function to read posterior
def read_file( filename ):
   """
   read in a prior distribution for the rate, returns two 1-d arrays 
   containing the first column (rate) and second column (prior probability)
   @param source_file: input file name
   """
   f = open( filename , "r")
   lines = f.readlines()
   f.close()
 
   vals = []
   for line in lines:
     if line[0] != '#':
       vals.append([float(val) for val in line.split()[0:]])
           
   M = array(vals)
   x = M[:,0]
   y = M[:,1]

   return x,y

#############################################################################
# make steps so that fill will work properly
def makesteps(ularray,ymax,k):
  """
  make the arrays to shade the region above the limit
  @param ularray: the array containing the upper limit details
  @param ymax:    the maximum value for the y plo
  @param k:       the index of the value to be plotted on y-axis
  """
  xnew=[]
  ynew=[]
  for i in arange(len(ularray[:,0])):
    xnew.append(ularray[i,0])
    xnew.append(ularray[i,1])
    ynew.append(ularray[i,k])
    ynew.append(ularray[i,k])
  
  # fill in the top
  xnew.append(ularray[-1,1])
  ynew.append(ymax)
  xnew.append(ularray[0,0])
  ynew.append(ymax)

  xnew = asarray(xnew)
  ynew = asarray(ynew)

  return xnew,ynew

#############################################################################
# generate a lognormal distribution
def lognormal_pdf(x, mu, sigma, sides=2):
  yout = exp(-(log(x) - mu)**2./(2.*sigma**2.))/(x*sigma*(2.*pi)**.5)
  if sides == 1:
    step = []
    for idx in range(len(x)):
      if log(x[idx]) <= mu:
        step.append(1.)
      else:
        step.append(0.)
    step = array(step)
    yout *= step

  return array(yout)

##############################################################################
usage = """usage: %prog [options] file1 (file2 file3)

Computing Upperlimit

Calculates the final upperlimit results using the output
of plotnumgalaxies (png-output.ini). 

Example:

"""
parser = OptionParser( usage=usage, version="%prog CVS $Id$" )

parser.add_option("-p","--prior",action="store",type="string",\
    default=None,\
    help="which prior to use on the rate. (uniform|fromfile)" )
parser.add_option("-P","--prior-file",action="store",type="string",\
    default=None, metavar=" FILE", help="name of prior file" )
parser.add_option("-s","--show-plot",action="store_true",default=False,\
    help="display the figures on the terminal" )
parser.add_option("-V","--verbose",action="store_true",default=False,\
    help="display verbose output" )
parser.add_option("-c","--calibration-error",action="store_true",default=False,\
    help="marginalize over the calibration error" )
parser.add_option("-g","--magnitude-error",action="store_true",default=False,\
    help="marginalize over the magnitude error" )
parser.add_option("-o","--montecarlo-error",action="store_true",default=False,\
    help="marginalize over the monte carlo error" )
parser.add_option("-w","--waveform-error",action="store_true",default=False,\
    help="marginalize over the waveform error" )
parser.add_option("-i","--distance-error",action="store_true",default=False,\
    help="marginalize over the distance error" )
parser.add_option("-f","--galaxies-file",action="append",type="string",\
    default=None, metavar=" FNAME",\
    help="File containing the output from plotnumgalaxies" ) 
parser.add_option("-t","--observation-time",action="append",type="float",\
    default=None, metavar=" TOBS", help="observation time in units of years" ) 
parser.add_option("-m","--max-rate",action="store",type="float",\
    default=200.0, metavar=" MAXRATE", \
    help="max rate on integral for posterior" ) 
parser.add_option("-d","--dr",action="store",type="float",\
    default=0.01, metavar=" DR", \
    help="dr to use in rate integral" ) 
parser.add_option("-n","--ntrials",action="store",type="int",\
    default=1000, metavar=" NTRIALS", \
    help="number of trials for marginalization over errors" ) 
parser.add_option("-R","--mass-region-type",action="store",type="string",\
    default="none", metavar=" TYPE", \
    help="type of mass regions for rate vs mass plot" )

# plotting details
parser.add_option("-F","--figure-name",action="store",type="string",\
    default=None,metavar=" FNAME",\
    help="generate ps figures with name FNAME_PlotType.ps")
parser.add_option("-x","--xmax",action="store",type="float",\
    default=None, metavar=" XMAX", help=\
    "maximum value on x-axis in plots of distributions (default = rate-max)" ) 
parser.add_option("-y","--ymin",action="store",type="float",\
    default=0.01, metavar=" YMIN", help="minimum value on y-axis" ) 
parser.add_option("-Y","--ymax",action="store",type="float",\
    default=100.0, metavar=" YMAX", 
    help="maximum value on y-axis for rate vs mass plot (default = 100)" ) 

(opts,args) = parser.parse_args()


if not opts.prior:
  print >>sys.stderr, "Must supply a prior for calculation\n" 
  sys.exit(0)

if (len(opts.galaxies_file)-len(opts.observation_time)):
  print >>sys.stderr, "Must give same number of galaxy files and " +\
                      "observation times\n"
  print >> sys.stderr, "Number of galaxy-files (-f):" + \
      str(len(opts.galaxies_file)) + \
      "  number of observation times (-t):" + str(len(opts.observation_time))
  sys.exit(0)

#####################################################################
# Do the pylab import in such a way that doesn't require an X display
# if show() won't be invoked.
if not opts.show_plot:
  import matplotlib
  matplotlib.use('Agg')
from pylab import *
if not opts.show_plot:
  rc('text', usetex=True)


###########################################################################
# each time-type has a different file which can have parameters for a
# sequence of different masses.  The png_matrix is a list of lists of
# dictionaries.  The first index is the given by the number of epochs,
# the second by the number of mass windows.
png_matrix = []

# nepochs is the number of distinct time types 
nepochs = len(opts.galaxies_file)

for epoch in range(nepochs):
  png_matrix.append(read_png_file(opts.galaxies_file[epoch], \
      opts.observation_time[epoch]))


# note len(matrix) returns the number of rows in the matrix
# massBins is given by the number of rows in the png files 
# (assumed the same for all files)
massBins = len(png_matrix[0])
ularray = zeros((massBins,4),Float32)

# the confidence level to use in the upper limit calculation
confLevel=0.9

# loop over the mass bins
for bin in range(massBins):
  
  # generate the prior
  if opts.prior == "fromfile":
    rate,rateprior = read_file(opts.prior_file)
  elif opts.prior == "uniform":
    maxrate = opts.max_rate
    dr = opts.dr
    rate = arange(0,maxrate,dr)
    rateprior = ones([int(around(maxrate/dr))])/maxrate
  else:
    print >> sys.stderr, "--prior must be one of uniform or fromfile"

  # calculate the rate
  ngt = 0.0
  ngprimet = 0.0
  for epoch in range(nepochs):
    data = png_matrix[epoch][bin]
    ngt += data["ng"] * data["tobs"]
    ngprimet += data["ngprime"] * data["tobs"]
  ngt0 = ngt
  exprate = exp( - rate * ngt )
  nomarginpost = rateprior * exprate \
        * ( data["pbprime"] + data["pb"] * rate * ngprimet )

  # set exprate to zero to calculate marginalization calculation
  exprate *= 0.0

  # if only one epoch, do a convolution and integrate directly, otherwise
  # do a Monte Carlo integral
  if nepochs == 1:
    data = png_matrix[0][bin]
    numPoints = 1000
    xRange = 100
    ngs = arange(numPoints)*(log(xRange))/numPoints + \
        log(ngt0/(data["tobs"]*xRange**.5))
    ngs = exp(ngs)

    pdfNg = zeros(numPoints)*0.
    for idx in range(numPoints-1):
      if ngs[idx] <= ngt0/data["tobs"] and ngs[idx+1] > ngt0/data["tobs"]:
        pdfNg[idx] += 1.

    pdfNgErrorMag = lognormal_pdf(ngs, data["dn_lummu"],
        data["dn_lumsigma_magnitude"])
    pdfNgErrorCalH = lognormal_pdf(ngs, data["dn_lummu"],
        data["dn_lumsigma_lhocal"])
    pdfNgErrorCalL = lognormal_pdf(ngs, data["dn_lummu"],
        data["dn_lumsigma_llocal"])
    pdfNgErrorMC = lognormal_pdf(ngs, data["dn_lummu"],
        data["dn_lumsigma_mc"])
    pdfNgErrorWave = lognormal_pdf(ngs, data["dn_lummu"],
        data["dn_lumsigma_waveform"], sides=1)
    pdfNgErrorDist = lognormal_pdf(ngs, data["dn_lummu"],
        data["dn_lumsigma_distance"])

    pdfNg = convolve(pdfNg, pdfNgErrorMag,
        mode=2)[len(pdfNg)/2:len(pdfNg)+len(pdfNg)/2]
    pdfNg = convolve(pdfNg, pdfNgErrorCalH,
        mode=2)[len(pdfNg)/2:len(pdfNg)+len(pdfNg)/2]
    pdfNg = convolve(pdfNg, pdfNgErrorCalL,
        mode=2)[len(pdfNg)/2:len(pdfNg)+len(pdfNg)/2]
    pdfNg = convolve(pdfNg, pdfNgErrorMC,
        mode=2)[len(pdfNg)/2:len(pdfNg)+len(pdfNg)/2]
    pdfNg = convolve(pdfNg, pdfNgErrorWave,
        mode=2)[len(pdfNg)/2:len(pdfNg)+len(pdfNg)/2]
    pdfNg = convolve(pdfNg, pdfNgErrorDist,
        mode=2)[len(pdfNg)/2:len(pdfNg)+len(pdfNg)/2]

    ngts = ngs*data["tobs"]
    pdfNgt = pdfNg/sum(ngts*pdfNg*log(ngts[1]/ngts[0]))

    for p_ngt,ngt in zip(pdfNgt,ngts):
      # exprate = p_ngt * ngt * exp( - rate * ( ngt ) )
      # but since these ngt points are equally spaced on a log scale
      # we need to mutliply by another factor of ngt
      exprate += p_ngt * ngt * exp( - rate * ( ngt ) ) * ngt

  else:  
    # perform the marginalization by generating ntrials worth of samples
    # from the given distributions for the various systematics
    ngts = []
    for j in arange(opts.ntrials):
      ngt = 0
      for epoch in range(nepochs):
        data = png_matrix[epoch][bin]

        thisngt = data["ng"] * data["tobs"]
        # magnitude error is lognormal
        if opts.magnitude_error:
          thisngt *= random.lognormvariate(data["dn_lummu"],
              data["dn_lumsigma_magnitude"]) * data["tobs"] / ngt0

        # lho calibration error is lognormal
        if ( opts.calibration_error and data["dn_lumsigma_lhocal"] != 0.0 ):
          thisngt *= random.lognormvariate(data["dn_lummu"],
              data["dn_lumsigma_lhocal"]) * data["tobs"] / ngt0

        # llo calibration error is lognormal
        if ( opts.calibration_error and data["dn_lumsigma_llocal"] != 0.0 ):
          thisngt *= random.lognormvariate(data["dn_lummu"],
              data["dn_lumsigma_llocal"]) * data["tobs"] / ngt0

        # monte carlo error is lognormal
        if opts.montecarlo_error:
          thisngt *= random.lognormvariate(data["dn_lummu"],
              data["dn_lumsigma_mc"]) * data["tobs"] / ngt0

        # waveform error is lognormal and one-sided
        if opts.waveform_error:
          tmpngt = 2.*thisngt
          while (tmpngt > thisngt):
            tmpngt = thisngt * (random.lognormvariate(data["dn_lummu"],
                data["dn_lumsigma_waveform"]) * data["tobs"] / ngt0)
          thisngt = tmpngt

        # distance error is lognormal
        if opts.distance_error:
          thisngt *= random.lognormvariate(data["dn_lummu"],
              data["dn_lumsigma_distance"]) * data["tobs"] / ngt0

        ngt +=  thisngt
      ngts.append(ngt)
      exprate += ngt * exp( - rate * ( ngt ) )
    exprate /= float(opts.ntrials)

  # end if statement for integration by convolution or Monte Carlo
  # for calculating exprate  
  marginpost = rateprior * exprate \
        * ( data["pbprime"] + data["pb"] * rate * ngprimet )
  
  # normalize the distributions
  nomarginpost /= sum(nomarginpost)
  marginpost /= sum(marginpost)

  # create the cumulative distributions
  cumnomarginpost = cumsum(nomarginpost)
  cummarginpost = cumsum(marginpost)

  # find the NgT corresponding to the marginalized upper limit
  idx90pcnomargin = [idx for idx in range(len(cumnomarginpost)) \
      if cumnomarginpost[idx] >= confLevel][0]
  idx90pcmargin = [idx for idx in range(len(cummarginpost)) \
      if cummarginpost[idx] >= confLevel][0]
  ngtmargin = ngt0 * rate[idx90pcnomargin] / rate[idx90pcmargin]

  # check that we have neglible probability at max rate
  lastidx = len(nomarginpost)-1
  ratio = nomarginpost[lastidx]/max(nomarginpost)
  eps = 1e-4;

  if ratio > eps:
    print >>sys.stderr, "non neglible probability of obtaining maximum rate"
    print >>sys.stderr, "90% confidence upper limit may be wrong"
    print >>sys.stderr, "ratio of p(max_rate) to max(p(rate)) = %f" % ratio
    print >>sys.stderr, "reduce this ratio to <%f by increasing max-rate" % eps
    sys.exit(0)
  
  if opts.verbose:
    print "unmarginalized value at R=0 is %f" %  (nomarginpost[0])
    print "marginalized value at R=0 is %f" % (marginpost[0])
  
  if opts.figure_name:
    if massBins > 1:
      outputName = opts.figure_name + "-" + str(data["mlo"]) + "-" + \
          str(data["mhi"])
    else:
      outputName = opts.figure_name

  # write out the data to a text file
  if opts.figure_name:
    write_file(rate, marginpost, outputName + "-posterior-pdf.txt")

  # plot the NgT distribution
  figure()
  if nepochs == 1:
    plot(ngts, pdfNgt, 'r', linewidth=2)
  else:
    hist(ngts, bins=20, normed=True)
  hold(True)
  axvline(ngt0, color='k', linestyle='--', linewidth=2)
  axvline(ngtmargin, color='g', linestyle=':', linewidth=2)
  xlabel('$\mathcal{C}_{L} T (L_{10} \cdot yr)$', size='x-large')
  ylabel('Probability', size='x-large')
  grid()
  if opts.figure_name:
    savefig( outputName + "-ngt-dist.png" )

  # plot the posterior pdf
  figure()
  plot(rate,nomarginpost,rate,marginpost,linewidth=2)
  legend(('posterior','marginalized posterior'))
  xlabel('Rate / yr / $L_{10}$', size='x-large')
  ylabel('Probability', size='x-large')
  title('Posterior on the rate')
  grid()
  tmpv = asarray(axis())
  if opts.xmax: tmpv[1]=opts.xmax
  axis(tmpv)
  if opts.figure_name:
    savefig( outputName + "-posterior-pdf.png" )

  # plot the cumulative probability
  if opts.verbose:
    print "unmarginalized value at R=0 is %f" %  (cumnomarginpost[1])
    print "marginalized value at R=0 is %f" % (cummarginpost[1])
  
  figure()
  semilogy(rate,1.0-cumnomarginpost, rate,1.0-cummarginpost,linewidth=2)
  legend(('posterior','marginalized posterior'))
  xlabel('Rate / yr / $L_{10}$', size='x-large')
  ylabel('Cumulative Probability', size='x-large')
  title('Cumulative posterior on the rate')
  grid()
  if opts.xmax:  axis([0,opts.xmax,0.001,1])
  else: ylim([0.001,1])

  if opts.figure_name:
    savefig( outputName + "-posterior-cdf.png")
 
  # print out the upper limit based on the confidence level confLevel
  ularray[bin,0]=data["mlo"]
  ularray[bin,1]=data["mhi"]
  if (massBins > 1):
    print
    print "For the mass range between %f and %f" % (data["mlo"], data["mhi"])

  for i in range(len(rate)):
    if cumnomarginpost[i] >= confLevel:
      print "The rate upper limit (before marginalization) is %f" % rate[i]
      ularray[bin,2]=rate[i]
      break
  
  for i in range(len(rate)):
    if cummarginpost[i] >= confLevel:
      print "The rate upper limit (after marginalization) is %f" % rate[i]
      ularray[bin,3]=rate[i]
      break

# write the output to a file
if opts.figure_name:
  ulfile = open(opts.figure_name + "-upper-limit","w")
  ulfile.write("#M_low\tM_high\tUnmarginalized Rate\tMarginalized Rate\n")
  for k in range(len(ularray)):
    ulfile.write("%e\t%e\t%e\t%e\n" % (ularray[k,0], ularray[k,1], \
        ularray[k,2],ularray[k,3]))
  ulfile.close()

# and plot this result, if we have a range of masses
if (massBins > 1):
  figure()
  semilogy(ularray[:,0],opts.ymax + 0.0*ularray[:,0],'w+')

  # XXX This assumes that the mass bins are continuous, i.e. where one bin
  # ends, the next one starts.  If that is not the case, then the makesteps
  # function needs to be generalized XXX.

  # plot the unmarginalized upper limit
  x,y=makesteps(ularray,opts.ymax,k=2)

  p=fill(x,y, facecolor='0.8')
  setp(p, alpha=0.2)
  ylim(opts.ymin,opts.ymax)

  # plot the marginalized upper limit
  x,y=makesteps(ularray,opts.ymax,k=3)
  p=fill(x,y, facecolor='0.5')
  setp(p, alpha=0.4)

  ylim(opts.ymin,opts.ymax)
  xlim(min(ularray[:,0]), max(ularray[:,1]))
  legend(('','unmarginalized','marginalized'),loc='lower left')
  if opts.mass_region_type == "totalmass":
    xlabel('Total Mass $(M_{\odot})$', size='x-large')
  if opts.mass_region_type == "componentmass":
    xlabel('Black Hole Mass $(M_{\odot})$', size='x-large')
  ylabel('Rate / yr / $L_{10}$', size='x-large')
  title('Rate versus Mass')
  grid(True)

  if opts.figure_name:
    savefig( opts.figure_name  + "-rate-v-mass.png")
  
# show the plots is asked
if opts.show_plot:
  show()


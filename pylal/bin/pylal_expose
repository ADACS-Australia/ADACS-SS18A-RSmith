#!/usr/bin/env python
#
# Copyright (C) 2008  Nickolas Fotopoulos
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
"""
pylal_expose: EXternal-trigger POpulation SEarch

This code computes the probability that a set of loudest statistics from
searches for external triggers is drawn from the same distribution as a
set of loudest statistics from background trials.
"""

from __future__ import division

__author__ = "Nickolas Fotopoulos <nvf@gravity.phys.uwm.edu>, Alexander Dietz alexander.dietz@lapp.in2p3.fr"
__prog__ = "pylal_expose"
__title__ = "External Trigger Population Search"

import random
import optparse
import cPickle as pickle
                       
import numpy 
import pylab as plt
plt.rc('text', usetex=True)


from pylal import InspiralUtils
from pylal import rate
from pylal import git_version
from pylal import PopStatement

#
# Functions
#

def create_hist(data):
    """
    Create a histogram of the data
    """
    nbins = 30
    val_min = min(data)-1.0
    val_max = max(data)+1.0
    bins = rate.LinearBins(val_min, val_max, nbins)
    px = bins.lower()

    # create the histogram and fill it
    hist = numpy.zeros(nbins)
    for value in data:
        hist[bins[value]] += 1
    return px, hist
    
def parse_args():
    """
    Parsing the command line arguments. 
    """
    parser = optparse.OptionParser(version=git_version.verbose_msg)

    # inputs
    parser.add_option("--data-path", help="path to the data pickle files")   
    parser.add_option("--grb-pickle", default = "list_grb.pickle", \
                      help="pickle file containing the GRB data.")

    parser.add_option("--analyze", type="string",help="Specifies what to "\
                      "analyze. Possible values: {box,test}.")
    parser.add_option("--reject-redshift-grb", action="store_true",
                      help="Enables any GRB with a redshift value to be rejected. "\
                      "Not recommended.", default=False)
    parser.add_option("--reject-no-candidate", action="store_true",
                      help="Rejects any GRB which does not have any candidate"\
                      " for the population statement.", default=False)
    
    
    parser.add_option("--m2-min", type="float", help="minimum m2 value")
    parser.add_option("--m2-max", type="float", help="maximum m2 value")
    parser.add_option("--m2-nbins", type="int", help="number of m2 bins")

    # InspiralUtils compatibility
    parser.add_option("--gps-start-time", type="int",
        help="GPS start time of data analyzed")
    parser.add_option("--gps-end-time", type="int",
        help="GPS end time of data analyzed")
    parser.add_option("--ifo-tag", help="IFO coincidence time analyzed")
    parser.add_option("--user-tag", help="a tag to label your plots")
    parser.add_option("--output-path", help="root of the HTML output")
    parser.add_option("--enable-output", action="store_true",
        default=False, help="enable plots and HTML output")
    parser.add_option("--html-for-cbcweb", action="store_true",
        default=False, help="enable HTML output with the appropriate headers "
        "for the CBC website")
    parser.add_option("--show-plot", action="store_true", default=False,
        help="display the plots to screen if an X11 display is available")
       
    # odds and ends
    parser.add_option("--verbose", action="store_true", default=False,
        help="print extra information to stdout")

    options, arguments = parser.parse_args()


    if options.ifo_tag is not None:
        options.ifo_times = options.ifo_tag

    for opt in ["data_path"]:
        if getattr(options, opt) is None:
            raise ValueError,  "--%s is required" % opt.replace("_", "-")

    check_list = ['box','test','random','single','max']
    if options.analyze not in check_list:
        raise ValueError,  "Option '--analyze' must take one of the "\
              "following options: %s"% check_list


    # Default hack: Not nice, but FIXME, i.e. load the grbUL pickle file!!
    if options.m2_min is None:
        options.m2_min = 1
        options.m2_max = 40
        options.m2_nbins = 13

    return options, arguments


#########################################################
####################  MAIN  ############################
#########################################################

#
# initialization
#
opts, args = parse_args()
page = InspiralUtils.InspiralPage(opts)


# create the PopStatement instances which are used to handle the
# population statement calculations
grb_data = pickle.load(file(opts.grb_pickle))
pop_stat = PopStatement.PopStatement(grb_data,'condensed')


# create the PopStatement instances for the m2-bin analysis
pop_m2 = {}
m2_bins = rate.LinearBins(opts.m2_min, opts.m2_max, opts.m2_nbins )
for m2_low, m2_high in zip(m2_bins.lower(), m2_bins.upper()):
    mass_bin = "%.1f-%.1f" % (m2_low, m2_high)
    pop_m2[mass_bin] = PopStatement.PopStatement(grb_data, mass_bin)


# loop over each GRB in the list (22 of them)
list_grb = grb_data.keys()
list_grb.sort()
for grb_name in list_grb:

    file_on = opts.data_path+"/pylal_grblikelihood_onsource_GRB%s_OPENBOX.pickle"%grb_name
    file_off = opts.data_path+"/pylal_grblikelihood_offsource_GRB%s_OPENBOX.pickle"%grb_name    
    
    # read the data from the files
    dummy, dummy, dummy, onsource_L_by_m2, log_sum_L =\
           pickle.load(open(file_on))
    
    dummy, dummy, offsource_L_by_trial_m2, off_log_sum_L_by_trial =\
           pickle.load(open(file_off))
    n_trials = offsource_L_by_trial_m2.shape[0]


    # double check the detection statistic
    count_louder = (off_log_sum_L_by_trial > log_sum_L).sum(axis=0)
    stat = count_louder/n_trials
    text = "GRB%s p(c|0)= %.1f %% " % (grb_name, 100.0*stat)
    if log_sum_L == -numpy.infty:
        text+= "(no candidate)"    
    page.write(text)

    if opts.reject_no_candidate and log_sum_L == -numpy.infty:
        print "This GRB will not be used for the final population statement"
        continue

    # add data to the m2-pop statement instances
    for index_m2, (m2_low, m2_high) in \
        enumerate(zip(m2_bins.lower(), m2_bins.upper())):             
        mass_bin = "%.1f-%.1f" % (m2_low, m2_high)
        pop_m2[mass_bin].add_background_by_trial(grb_name, offsource_L_by_trial_m2[:,index_m2])
        pop_m2[mass_bin].add_foreground(grb_name, onsource_L_by_m2[index_m2])
                       

    # populate the popStatement instance with real background/onsource
    pop_stat.add_background_by_trial(grb_name, off_log_sum_L_by_trial)
    pop_stat.add_foreground(grb_name, log_sum_L)

# finalize the sampling
for pop_inst in pop_m2.values():
    pop_inst.finalize()
pop_stat.finalize()

page.write("Number of offsource trials used: %d" % len(pop_stat.off_lik))

# create overview plots (for the condense case)
plot = pop_stat.check_off_distribution_lik()
page.add_plot(plot.fig, "check_off_distribution-lik")

plot = pop_stat.check_off_distribution_far()
page.add_plot(plot.fig, "check_off_distribution-far")

# decide what to do: a general test or choose an onsource
if opts.analyze=='test':
    vec_lik = {}
    vec_ifar = {}
    
    for type in ['random']:
        print "Samples drawn from ", type
        
        dummy_lik = []
        dummy_ifar = []
        for i in range(5000):
            pop_stat.select_onsource(type)
            z_lik, z_ifar = pop_stat.compute_wmu()

            dummy_lik.append(z_lik)
            dummy_ifar.append(z_ifar)
            
        pickle.dump(dummy_lik, open('expose_random_z.pickle','w'))
        sys.exit(0)

        vec_lik[type]=dummy_lik
        vec_ifar[type]=dummy_ifar

    a1, a2 = create_hist(vec_lik['random'])
    b1, b2 = create_hist(vec_lik['single'])
    c1, c2 = create_hist(vec_lik['max'])     
    
    plt.clf()
    plt.plot(a1, a2, 'r-')
    plt.plot(b1, b2, 'b-')
    plt.plot(c1, c2, 'g-')
    plt.grid(True)
    plt.xlabel('sigma')
    plt.ylabel('number')
    plt.legend(('random','single','max'))
    page.add_plot(plt.gcf(), "test-lik")
        
    a1, a2 = create_hist(vec_ifar['random'])
    b1, b2 = create_hist(vec_ifar['single'])
    c1, c2 = create_hist(vec_ifar['max'])     
    
    plt.clf()
    plt.plot(a1, a2, 'r-')
    plt.plot(b1, b2, 'b-')
    plt.plot(c1, c2, 'g-')
    plt.grid(True)
    plt.xlabel('sigma')
    plt.ylabel('number')
    plt.legend(('random','single','max'))
    page.add_plot(plt.gcf(), "test-ifar")    
    
else:

    # prepare arrays to hold the data
    z_lik_by_m2 = numpy.zeros(opts.m2_nbins, float)
    z_ifar_by_m2 = numpy.zeros(opts.m2_nbins, float)
    p_by_m2 = numpy.zeros(opts.m2_nbins, float)

    # analyse each of the m2 pop instances
    for index_m2, (m2_low, m2_high) in \
            enumerate(zip(m2_bins.lower(), m2_bins.upper())):
                
        mass_bin = "%.1f-%.1f" % (m2_low, m2_high)
        pop_m2[mass_bin].select_onsource(opts.analyze)
        z_lik_by_m2[index_m2], z_ifar_by_m2[index_m2] = pop_m2[mass_bin].compute_wmu()
        p_by_m2[index_m2] = pop_m2[mass_bin].p_one_sided

        # create the plots
        plot = pop_m2[mass_bin].create_plot_hist()
        page.add_plot(plot.fig, "hist-"+mass_bin)
        plot = pop_m2[mass_bin].create_plot_qq()
        page.add_plot(plot.fig, "qq-"+mass_bin)

    # select either a fake trial or the box
    pop_stat.select_onsource(opts.analyze)
    z_lik, z_ifar = pop_stat.compute_wmu()

    plot = pop_stat.create_plot_hist()
    page.add_plot(plot.fig, "histCondense")
    plot = pop_stat.create_plot_qq()
    page.add_plot(plot.fig, "qqCondense")

    # write the basic result to the output and to the web page
    text = "The result of the analysis for the condense statement is: "+\
               "%.2f (LIK)  %.2f (IFAR) sigma (i.e. %.3e Perc. )" %\
               (z_lik, z_ifar, 100.0*pop_stat.p_one_sided)
    page.write(text)

    
    # create the final plot
    plt.clf()
    plt.plot(m2_bins.centres(), z_lik_by_m2, 'r-', linewidth = 3)
    plt.plot(m2_bins.centres(), z_ifar_by_m2, 'b-', linewidth = 3)    
    plt.grid(True)
    plt.xlabel('m2')
    plt.ylabel('sigma')
    plt.legend(('likelihood','IFAR'))
    page.add_plot(plt.gcf(), "condense_sigma-"+opts.analyze)

    plt.clf()
    plt.plot(m2_bins.centres(), p_by_m2, 'r-', linewidth = 3)
    plt.grid(True)
    plt.xlabel('m2')
    plt.ylabel('p (one sided)')
    page.add_plot(plt.gcf(), "condense_prob-"+opts.analyze)

    

# create the html page    
page.write_page()

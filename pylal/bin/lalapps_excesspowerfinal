#!/usr/bin/python
#
# $Id$
#
# Copyright (C) 2007  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


"""
Excess power upper limit final result tool.
"""


import bisect
import glob
import math
import numpy
from optparse import OptionParser
from pysqlite2 import dbapi2 as sqlite3
import sys


from glue.ligolw import ligolw
from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw import utils
from glue import segments
from pylal import ligolw_tisi
from pylal import rate
from pylal import SimBurstUtils
from pylal import SnglBurstUtils
from pylal.date import LIGOTimeGPS


__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]


#
# =============================================================================
#
#                                 Speed Hacks
#
# =============================================================================
#


def SearchSummary_get_out(self):
	return segments.segment(LIGOTimeGPS(self.out_start_time, self.out_start_time_ns), LIGOTimeGPS(self.out_end_time, self.out_end_time_ns))


lsctables.SearchSummary.get_out = SearchSummary_get_out


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	parser = OptionParser(
		version="%prog CVS $Id$",
		usage = "%prog [options] -i|--injection-glob pattern -b|--background-glob pattern",
		description = "%prog performs the final, summary, stages of an upper-limit excess power search for burst-like gravitational waves."
	)
	parser.add_option("-b", "--background-glob", metavar = "pattern", default = [], action = "append", help = "Shell filename pattern for non-injection files.")
	parser.add_option("-i", "--injection-glob", metavar = "pattern", default = [], action = "append", help = "Shell filename pattern for injection files.")
	parser.add_option("-l", "--live-time-program", metavar = "program", default = "lalapps_power", help = "Set the name, as it appears in the process table, of the program whose search summary entries define the search live time (default = \"lalapps_power\")")
	parser.add_option("--confidence-contour-slope", metavar = "slope", default = "-16.5", help = "Set the slope of the confidence-likelihood joint contours on which the final cut thresholds (default = -16.5).")
	parser.add_option("--foreground-survivors", metavar = "number", help = "Tune the coincidence likelihood threshold to result in this many survivors being expected in the foreground. (e.g., 0.1)")
	parser.add_option("--measure-min-confidences", action = "store_true", help = "After thresholds have been determined, rescan all input files for all sngl_burst events surviving the cuts, and measure the lowest surviving confidence by instrument.  Can be used to check that the confidence thresholds set on the pipeline's lalapps_power jobs are not unreasonable.")
	parser.add_option("--survivors-output", metavar = "filename", help = "Set the name of the XML file to which zero-lag survivors will be written.  Default is to not record zero-lag survivors file (keep the box closed).")
	parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
	options, filenames = parser.parse_args()

	if not options.background_glob:
		raise ValueError, "missing required --background-glob argument"
	if not options.injection_glob:
		raise ValueError, "missing required --injection-glob argument"
	if options.foreground_survivors is None:
		raise ValueError, "missing required --foreground-survivors argument"

	options.confidence_contour_slope = float(options.confidence_contour_slope)
	options.foreground_survivors = float(options.foreground_survivors)

	return options, (filenames or [None])


#
# =============================================================================
#
#           Thing for keeping only the highest values in a sequence
#
# =============================================================================
#


class Highest(list):
	def __init__(self, sequence = [], fraction = 1.0):
		list.__init__(self, sequence)
		self.n = list.__len__(self)
		self.fraction = fraction
		list.sort(self, reverse = True)
		del self[int(self.fraction * self.n):]

	def __len__(self):
		return self.n

	def append(self, value):
		hi = list.__len__(self)
		lo = 0
		while lo < hi:
			mid = (lo + hi) // 2
			if value > self[mid]:
				hi = mid
			else:
				lo = mid + 1
		self.insert(lo, value)
		self.n += 1
		del self[int(self.fraction * self.n):]

	def extend(self, sequence):
		before = list.__len__(self)
		list.extend(self, sequence)
		self.n += list.__len__(self) - before
		list.sort(self, reverse = True)
		del self[int(self.fraction * self.n):]

	def sort(*args, **kwargs):
		raise NotImplementedError


#
# =============================================================================
#
#                           Likelihood Book-Keeping
#
# =============================================================================
#


class Likelihood_Histogram(object):
	def __init__(self):
		self.slides = []
		self.injection_eff_confidences = []
		self.background_eff_confidences = Highest(fraction = 0.01)
		self.foreground_eff_confidences = []
		self.foreground_rate = rate.Rate(segments.segment(0.0, 1.0), 0.01)
		self.background_rate = rate.Rate(segments.segment(0.0, 1.0), 0.01)
		self.injection_rate = rate.Rate(segments.segment(0.0, 1.0), 0.01)

	def add_non_injections(self, contents):
		#
		# Iterate over burst<-->burst coincidences.  Assume there
		# are no injections in this file.
		#

		for likelihood, confidence, is_background in contents.connection.cursor().execute("""
SELECT coinc_event.likelihood, multi_burst.confidence, EXISTS (
	SELECT * FROM
		time_slide
	WHERE
		time_slide.time_slide_id == coinc_event.time_slide_id
		AND time_slide.offset != 0
) FROM
	coinc_event
	JOIN multi_burst ON (
		multi_burst.coinc_event_id == coinc_event.coinc_event_id
	)
WHERE
	coinc_event.coinc_def_id == ?
		""", (contents.bb_definer_id,)):
			if is_background:
				self.background_eff_confidences.append(effective_confidence(likelihood, confidence))
				self.background_rate[likelihood] += 1.0
			else:
				self.foreground_eff_confidences.append(effective_confidence(likelihood, confidence))
				self.foreground_rate[likelihood] += 1.0

	def add_injections(self, contents):
		#
		# Iterate over burst<-->burst coincidences involving one or
		# more events identified as being the result of injections.
		#

		for likelihood, confidence in contents.connection.cursor().execute("""
SELECT coinc_event.likelihood, multi_burst.confidence FROM
	coinc_event
	JOIN multi_burst ON (
		multi_burst.coinc_event_id == coinc_event.coinc_event_id
	)
WHERE
	coinc_event.coinc_def_id == ?
	AND EXISTS (
		-- Find an injection coinc containing at least one of the
		-- bursts in this coinc
		SELECT sim_coinc_event.coinc_event_id FROM
			coinc_event AS sim_coinc_event
			JOIN coinc_event_map AS a ON (
				a.coinc_event_id == sim_coinc_event.coinc_event_id
				AND a.table_name == 'sngl_burst'
			)
			JOIN coinc_event_map AS b ON (
				b.table_name == 'sngl_burst'
				AND b.event_id == a.event_id
			)
		WHERE
			b.coinc_event_id == coinc_event.coinc_event_id
			AND sim_coinc_event.coinc_def_id == ?
			AND sim_coinc_event.time_slide_id == coinc_event.time_slide_id
	)
		""", (contents.bb_definer_id, contents.sb_definer_id)):
			self.injection_eff_confidences.append(effective_confidence(likelihood, confidence))
			self.injection_rate[likelihood] += 1.0

	def finish_non_injections(self):
		self.foreground_rate.array /= numpy.sum(self.foreground_rate.array)
		self.background_rate.array /= numpy.sum(self.background_rate.array)
		self.foreground_rate.filter()
		self.background_rate.filter()

	def finish_injections(self):
		self.injection_rate.array /= numpy.sum(self.injection_rate.array)
		self.injection_rate.filter()

	def get_foreground_above_confidence_threshold(self, confidence_threshold):
		return [x for x in self.foreground_eff_confidences if x > confidence_threshold]

	def find_confidence_threshold(self, events_per_foreground, foreground_live_time, background_live_time):
		"""
		Given the desired average number of events per foreground
		live time, determine the likelihood threshold to cut
		coincidences on.  The interpretation is that coincidences
		with a likelihood greater than (not equal to) the value
		returned by this function are to be retained.
		"""
		#
		# How many events to retain from the non-zero-lag
		# coincidences in order to get events_per_foreground
		# survivors in the foreground, assuming the event rate is
		# the same in all time slides.
		#

		n_background = int(round(events_per_foreground * background_live_time / foreground_live_time))

		#
		# Effective confidence that will keep n_background
		# background events
		#

		return self.background_eff_confidences[n_background]


#
# =============================================================================
#
#                              Zero-Lag Survivors
#
# =============================================================================
#


class Survivors(object):
	def __init__(self, confidence_threshold):
		self.confidence_threshold = confidence_threshold
		self.xmldoc = None

	def add(self, contents):
		if self.xmldoc is None:
			self.xmldoc = ligolw.Document()
			self.xmldoc.appendChild(ligolw.LIGO_LW())
			self.sngl_burst_table = lsctables.New(lsctables.SnglBurstTable, contents.sngl_burst_table.columnnames)
			self.xmldoc.childNodes[0].appendChild(self.sngl_burst_table)

		for sngl_burst in map(contents.sngl_burst_table._row_from_cols, contents.connection.cursor().execute("""
SELECT sngl_burst.* FROM
	sngl_burst
WHERE
	sngl_burst.event_id IN (
		SELECT coinc_event_map.event_id FROM
			coinc_event_map
			JOIN coinc_event ON (
				coinc_event.coinc_event_id == coinc_event_map.coinc_event_id
			)
			JOIN multi_burst ON (
				multi_burst.coinc_event_id == coinc_event.coinc_event_id
			)
		WHERE
			coinc_event_map.table_name == 'sngl_burst'
			AND coinc_event.coinc_def_id == ?
			AND effective_confidence(coinc_event.likelihood, multi_burst.confidence) > ?
			AND NOT EXISTS (
				SELECT * FROM
					time_slide
				WHERE
					time_slide.time_slide_id == coinc_event.time_slide_id
					AND time_slide.offset != 0
			)
	)
		""", (contents.bb_definer_id, self.confidence_threshold))):
			self.sngl_burst_table.append(sngl_burst)

	def finish(self, filename, verbose = False):
		utils.write_filename(self.xmldoc, filename, verbose = verbose, gz = (filename or "stdout").endswith(".gz"))


#
# =============================================================================
#
#                                  Efficiency
#
# =============================================================================
#


def Efficiency_hrss_vs_freq_add_contents(self, contents):
	self.num_injections += len(contents.sim_burst_table)
	instruments = contents.seglists.keys()
	coinc_segs = contents.seglists.intersection(instruments)
	# FIXME: careful, the check for a coincidence will find any
	# coincidence, no matter which instruments participate.  For now,
	# I'm running fixed networks so this is not a problem, but if
	# variable configuration networks are adopted in the future, then
	# this will need to be re-thought to be sure that "found" means
	# found in the correct set of instruments.
	for values in contents.connection.cursor().execute("""
SELECT sim_burst.*, EXISTS (
	-- Find a burst<-->burst coinc containing a burst that participated
	-- in this injection, that was found in the same time slide as the
	-- injection, and whose likelihood and multi_burst confidence are
	-- both above threshold
	SELECT burst_coinc_event.coinc_event_id FROM
		coinc_event_map AS c
		JOIN coinc_event AS sim_coinc_event ON (
			sim_coinc_event.coinc_event_id == c.coinc_event_id
		)
		JOIN coinc_event_map AS a ON (
			a.coinc_event_id == c.coinc_event_id
			AND a.table_name == 'sngl_burst'
		)
		JOIN coinc_event_map AS b ON (
			b.table_name == 'sngl_burst'
			AND b.event_id == a.event_id
		)
		JOIN coinc_event AS burst_coinc_event ON (
			burst_coinc_event.coinc_event_id == b.coinc_event_id
			AND burst_coinc_event.time_slide_id == sim_coinc_event.time_slide_id
		)
		JOIN multi_burst ON (
			multi_burst.coinc_event_id == burst_coinc_event.coinc_event_id
		)
	WHERE
		c.table_name == 'sim_burst'
		AND c.event_id == sim_burst.simulation_id
		AND sim_coinc_event.coinc_def_id == ?
		AND burst_coinc_event.coinc_def_id == ?
		AND effective_confidence(burst_coinc_event.likelihood, multi_burst.confidence) > ?
) FROM
	sim_burst
	""", (contents.sb_definer_id, contents.bb_definer_id, self.confidence_threshold)):
		sim = contents.sim_burst_table._row_from_cols(values[:-1])
		found = values[-1]
		if found:
			self.injected_x.append(sim.freq)
			self.injected_y.append(sim.hrss)
			self.found_x.append(sim.freq)
			self.found_y.append(sim.hrss)
		# FIXME:  this assumes all injections are done at zero lag
		# (which is correct, for now, but watch out for this)
		elif SimBurstUtils.injection_was_made(sim, coinc_segs, instruments):
			self.injected_x.append(sim.freq)
			self.injected_y.append(sim.hrss)


SimBurstUtils.Efficiency_hrss_vs_freq.add_contents = Efficiency_hrss_vs_freq_add_contents


#
# =============================================================================
#
#                                  Live Time
#
# =============================================================================
#


def get_background_time_slides(contents):
	"""
	Query the database for the IDs and offsets of non-zero-lag time
	slides.
	"""
	time_slides = {}
	for id, instrument, offset in contents.connection.cursor().execute("""
SELECT time_slide_id, instrument, offset FROM
	time_slide
WHERE
	time_slide_id IN (
		SELECT time_slide_id FROM
			time_slide
		WHERE
			offset != 0
	)
	"""):
		if id not in time_slides:
			time_slides[id] = {}
		time_slides[id][instrument] = offset
	return time_slides


def zero_lag_livetime(seglists):
	"""
	Return the total live time in the zero lag time slide.
	"""
	seglists.offsets.clear()
	return float(abs(seglists.intersection(seglists.keys())))


def time_slides_livetime(seglists, time_slides, verbose = False):
	"""
	For each of the time slides, which are instrument --> offset
	mappings, compute the live time, and return the sum.
	"""
	livetime = 0
	old_offsets = seglists.offsets.copy()
	N = len(time_slides)
	for n, time_slide in enumerate(time_slides):
		if verbose:
			print >>sys.stderr, "\t%.1g%%" % (100.0 * n / N),
		seglists.offsets.update(time_slide)
		livetime += float(abs(seglists.intersection(time_slide.keys())))
	seglists.offsets.update(old_offsets)
	if verbose:
		print >>sys.stderr, "\t100.0%"
	return livetime


#
# =============================================================================
#
#               lalapps_power Confidence Threshold Safety Check
#
# =============================================================================
#


def lalapps_power_confidence_safety(filenames, confidence_threshold, verbose = False):
	"""
	For each instrument, find the lowest confidence associated with any
	sngl_burst event surviving the various thresholds.  Used to check
	that the confidences are too close but also not too much higher
	than the thresholds set in the lalapps_power jobs.
	"""

	min_confidence = {}

	for n, filename in enumerate(filenames):
		if verbose:
			print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
		connection = sqlite3.connect(filename)
		connection.create_function("effective_confidence", 2, effective_confidence)

		for ifo, confidence in connection.cursor().execute("""
SELECT sngl_burst.ifo, MIN(sngl_burst.confidence) FROM
	multi_burst
	JOIN coinc_event ON (
		coinc_event.coinc_event_id == multi_burst.coinc_event_id
	)
	JOIN coinc_event_map ON (
		coinc_event_map.coinc_event_id == coinc_event.coinc_event_id
	)
	JOIN sngl_burst ON (
		coinc_event_map.table_name == 'sngl_burst'
		AND coinc_event_map.event_id == sngl_burst.event_id
	)
WHERE
	effective_confidence(coinc_event.likelihood, multi_burst.confidence) > ?
GROUP BY
	sngl_burst.ifo
		""", (confidence_threshold,)):
			if ifo not in min_confidence:
				min_confidence[ifo] = confidence
			else:
				min_confidence[ifo] = min(min_confidence[ifo], confidence)

		connection.close()

	if verbose:
		print >>sys.stderr

	return min_confidence


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


#
# Command line.
#


options, filenames = parse_command_line()


#
# Set up book-keeping tools.
#


def effective_confidence(likelihood, confidence, m = options.confidence_contour_slope):
	# In the 2-D (likelihood, confidence) parameter space, the
	# background density contours for high-confidence events are found,
	# impirically, to be approximated by the family of curves given by
	#
	#    log10 likelihood = m log10 confidence + log10 b
	#
	# where m ~= -16.5.  b parameterizes the family of curves, and can
	# be interpreted as an "effective confidence".  Injections are
	# found to have high "b" values, and noise low "b" values.  Given a
	# likelihood and confidence pair,
	#
	#    b = likelihood * confidence^-m

	return likelihood * confidence**(-m)


likelihood_histogram = Likelihood_Histogram()
efficiency = SimBurstUtils.Efficiency_hrss_vs_freq(None, 0.1)
non_injection_seglists = segments.segmentlistdict()
injection_seglists = segments.segmentlistdict()
background_time_slides = []


#
# Iterate over background files.
#


if options.verbose:
	print >>sys.stderr, "=== Background & Foreground ==="

filenames = reduce(list.__add__, [glob.glob(g) for g in options.background_glob])
filenames.sort()

if not len(filenames):
	raise ValueError, "error:  no background files found"

for n, filename in enumerate(filenames):
	#
	# Open the database file.
	#

	if options.verbose:
		print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
	connection = sqlite3.connect(filename)
	connection.create_function("effective_confidence", 2, effective_confidence)
	dbtables.DBTable_set_connection(connection)
	database = SnglBurstUtils.CoincDatabase().summarize(dbtables.DBTable_get_xml(), options.live_time_program, options.verbose)

	#
	# Process database contents.
	#

	background_time_slides = ligolw_tisi.time_slide_list_merge(background_time_slides, get_background_time_slides(database).itervalues())
	likelihood_histogram.add_non_injections(database)
	non_injection_seglists |= database.seglists

	#
	# Done with this file.
	#

	connection.close()


#
# Determine likelihood threshold.
#


if options.verbose:
	print >>sys.stderr, "=== Threshold ==="
	print >>sys.stderr, "measuring live time ..."
foreground_live_time = zero_lag_livetime(non_injection_seglists)
background_live_time = time_slides_livetime(non_injection_seglists, background_time_slides)

if options.verbose:
	print >>sys.stderr, "filtering foreground and background likelihood histograms ..."
likelihood_histogram.finish_non_injections()

if options.verbose:
	print >>sys.stderr, "computing effective confidence threshold ..."
efficiency.confidence_threshold = confidence_threshold = likelihood_histogram.find_confidence_threshold(options.foreground_survivors, foreground_live_time, background_live_time)
if options.verbose:
	print >>sys.stderr, "Effective confidence threshold = %g" % confidence_threshold


#
# Retrieve survivors if box is to be opened.
#


if options.survivors_output is not None:
	if options.verbose:
		print >>sys.stderr, "retrieving zero-lag survivors ..."

	survivors = Survivors(confidence_threshold)

	for n, filename in enumerate(filenames):
		#
		# Open the database file.
		#

		if options.verbose:
			print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
		connection = sqlite3.connect(filename)
		connection.create_function("effective_confidence", 2, effective_confidence)
		dbtables.DBTable_set_connection(connection)
		database = SnglBurstUtils.CoincDatabase().summarize(dbtables.DBTable_get_xml(), options.live_time_program, options.verbose)

		#
		# Process database contents.
		#

		survivors.add(database)

		#
		# Done with this file.
		#

		connection.close()
else:
	survivors = None


#
# Iterate over injection files.
#


if options.verbose:
	print >>sys.stderr, "=== Injections =="

filenames = reduce(list.__add__, [glob.glob(g) for g in options.injection_glob])
filenames.sort()

if not len(filenames):
	raise ValueError, "error:  no injection files found"

for n, filename in enumerate(filenames):
	#
	# Open the database file.
	#

	if options.verbose:
		print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
	connection = sqlite3.connect(filename)
	connection.create_function("effective_confidence", 2, effective_confidence)
	dbtables.DBTable_set_connection(connection)
	database = SnglBurstUtils.CoincDatabase().summarize(dbtables.DBTable_get_xml(), options.live_time_program, options.verbose)

	#
	# Process database contents.
	#

	likelihood_histogram.add_injections(database)
	efficiency.add_contents(database)
	injection_seglists |= database.seglists

	#
	# Done with this file.
	#

	connection.close()


#
# Do lalapps_power threshold check.
#


if options.measure_min_confidences:
	print
	print "=== Minimum Surviving sngl_burst Confidence By Instrument ==="
	print
	filenames = reduce(list.__add__, [glob.glob(g) for g in options.background_glob + options.injection_glob])
	filenames.sort()
	for ifo, confidence in lalapps_power_confidence_safety(filenames, likelihood_threshold, verbose = options.verbose).items():
		print "Minimum surviving %s confidence = %g" % (ifo, confidence)


#
# Summary.
#


likelihood_histogram.finish_injections()
efficiency.finish()


print
print "=== Input Summary ==="
print "Total live time in background = %s s" % background_live_time
print "Total live time in foreground = %s s" % foreground_live_time
print "Number of events in background = %d" % len(likelihood_histogram.background_eff_confidences)
print "Average number of background events per foreground live time = %g" % (len(likelihood_histogram.background_eff_confidences) / background_live_time * foreground_live_time)
print "Number of events in foreground = %d" % len(likelihood_histogram.foreground_eff_confidences)

print
print "=== Threshold ==="
print "Effective confidence threshold for which is expected %g events in foreground = %g" % (options.foreground_survivors, confidence_threshold)

# FIXME: in the future, don't display this until the box is open.
#if survivors is not None:
print "Number of foreground events above effective confidence threshold = %d" % len(likelihood_histogram.get_foreground_above_confidence_threshold(confidence_threshold))

print
print "Writing plots ..."
SimBurstUtils.plot_Efficiency_hrss_vs_freq(efficiency).savefig("lalapps_excesspowerfinal_efficiency.png")

print
print "=== Done ==="

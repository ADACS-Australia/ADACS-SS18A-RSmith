#!/usr/bin/python
__author__ = "Ruslan Vaulin <vaulin@gravity.phys.uwm.edu>, Rahul Biswas <rahul@gravity.phys.uwm.edu>"
__prog__="findCutEfficiency"

#loading standard modules
from optparse import *
import glob
import sys
import cPickle
#loading modules used for input/output of data 
from glue import lal
from glue.ligolw import lsctables
from pylal import CoincInspiralUtils
from pylal import SnglInspiralUtils
from pylal import SimInspiralUtils
from pylal import InspiralUtils
from pylal import git_version
from glue.ligolw import ligolw
#loading modules used in calculations
import glue.iterutils
from pylal import inspiral_likelihood
import numpy
numpy.seterr("raise")
import cmath
from pylal import rate


############################################################################################
# Definitions of functions
############################################################################################

################################################################################
# Main program
################################################################################
usage= """
usage: %prog [options]

This code is a diagnostic tool for achieving optimal tuning of the threshold. Currently it does it for e-thinca parameter only.
"""
###############################################################################
# Options to read in Input
###############################################################################
def parse_command_line():

  """
  Parser function dedicated
  """

  parser = OptionParser( usage=usage, version=git_version.verbose_msg)

  parser.add_option("","--slides-glob",action="store",type="string",\
      default=None, metavar=" GLOB",help="GLOB time slides thinca files to read" )
	
  parser.add_option("","--input-cache-file",action="store",type="string",\
      default=None, metavar="ZEROLAGCACHEFILE",help="name of the cache file including the path" )

  parser.add_option("","--slides-pattern",\
      default="", metavar="SLIDESPATTERN", help="the time slides files pattern the cache file, specified by --input-cache-file option, will be seived with.")
	

################################################################################
# Options for plots and histograms
#################################################################################### Options to select ifo types.

  parser.add_option("", "--h1-triggers",action="store_true", default=False,\
      help="input files contain triggers from H1")

  parser.add_option("", "--h2-triggers",action="store_true", default=False,\
      help="input files contain triggers from H2")

  parser.add_option("", "--l1-triggers",action="store_true", default=False,\
      help="input files contain triggers from L1")

  parser.add_option("", "--g1-triggers",action="store_true", default=False,\
      help="input files contain triggers from G1")

  parser.add_option("", "--v1-triggers",action="store_true", default=False,\
      help="input files contain triggers from V1")

  parser.add_option("","--statistic",action="store",default='snr',\
      type="string",\
      help="choice of statistic used in building coinc table, valid arguments are: snr (DEFAULT), snr_over_chi, s3_snr_chi_stat, effective_snr, bitten_l, bitten_lsq, ifar, lvS5stat")
		
  parser.add_option("", "--use-likelihood",action="store_true", default=False,\
      help="enables likelihood to be used as detection statistic")
	  		
  parser.add_option("","--num-slides", action="store",type="int",\
      default = 0, metavar="numslides", help="number of time slides performed, must match the corresponding parameter from the .ini file of the search" )
		
  parser.add_option("","--verbose", action="store_true",\
      default=False, help="print information" )

  parser.add_option("-u","--output-file",action="store",type="string",\
      default=None, metavar=" USERTAG",\
      help="output file to store loudest stats" )

  (opts,args) = parser.parse_args()

  return opts, sys.argv[1:]
#####################################################################
opts, args = parse_command_line()


# constructing the list of the IFO's
ifo_list = [ifo for ifo in ("G1", "H1", "H2", "L1", "V1") \
            if getattr(opts, "%s_triggers" % ifo.lower())]

ifo_combos = CoincInspiralUtils.get_ifo_combos(ifo_list)


#Calculating statistic for coincidences
statistic = CoincInspiralUtils.coincStatistic(opts.statistic) 

Loudest_Stats = {}
max_stats_dic = {}
ifo_times = CoincInspiralUtils.get_ifo_combos(ifo_list)

mchirp_bins = ["2_8", "8_17", "17_35"]

for ifo_time in ifo_times[1:]:
  ifo_types_without_H1H2 = []
  ifo_types = CoincInspiralUtils.get_ifo_combos(ifo_time)
  for ifo_type in ifo_types:
	if not "".join(ifo_type) == 'H1H2':
	  ifo_types_without_H1H2.append(ifo_type)
  for ifo_type in ifo_types_without_H1H2:
	for mchirp_bin in mchirp_bins:
	
	  ifo_key = "".join(ifo_type) + "_" + "".join(ifo_time) + "_" + mchirp_bin
	  print ifo_key
	  ifo_pattern = "".join(ifo_time) + "_" + "".join(ifo_type)

	  Loudest_Stats[ifo_key] = 0.0
	  max_stats_dic[ifo_key] = numpy.zeros(2*opts.num_slides, dtype = float)
	  
	  # contsructing lists of data files containing time slides and injections triggers respectively
	  ########################################################################################################	
	  if opts.input_cache_file:
		InspiralUtils.message(opts, "Reading input-cache-file ...")
		slidesfiles = []
		SnglInspiralCache = lal.Cache.fromfile(open(opts.input_cache_file))
		slidesfiles = SnglInspiralCache.sieve(description = opts.slides_pattern, exact_match=True).checkfilesexist()[0].pfnlist()
	  else:
		slidesfiles = []
		slidesfiles = glob.glob(opts.slides_glob.replace("IFO_TIME", ifo_pattern).replace("bin", mchirp_bin))
		
	  # check if file lists are not empty
	  if not len(slidesfiles) > 0:
		print >>sys.stderr, "List of time slides files is empty: your sieve pattern may be wrong or files do not exist in the location given by the cache file"
		#sys.exit(1)

	  #InspiralUtils.message(opts, "calculating threshold statistics for " + ifo_pattern + "time ...")
	  #InspiralUtils.message(opts, "glob: " + opts.slides_glob.replace("IFO_TIME", ifo_pattern))
	  #InspiralUtils.message(opts, "number of files: " + str(len(slidesfiles)))

	  # define array that stores maximum statistic for each of the time slide
	  max_stats_array = numpy.zeros(2*opts.num_slides, dtype = float)

	  #InspiralUtils.message(opts," reading in time slides ...")
	  for file in slidesfiles:
		# read in time slides triggers 
		slidesTriggers = None
		slidesTriggers = SnglInspiralUtils.ReadSnglInspiralFromFiles([file], non_lsc_tables_ok=True)
		# construct the time slides coincs
		slidesCoincTriggers = CoincInspiralUtils.coincInspiralTable(slidesTriggers, statistic)

		# read InspiralLikelihoodTable if necessary and add likelihood values to coincs  
		if opts.use_likelihood:
		  slidesLikelihoodTriggers = inspiral_likelihood.ReadInspiralLikelihoodFromFiles([file])
		  # add likelihood values to coincs
		  inspiral_likelihood.add_likelihood(slidesCoincTriggers, slidesLikelihoodTriggers)       


		for slide in range(1, opts.num_slides + 1):
		  #  triggers in each time slide are sorted in descending order in statistic which is passed to an array

		  # for slide forward
		  # get coincs from the current slide
		  forward_slide_coincs = slidesCoincTriggers.getslide(slide)

		  # store this slide's maximum statistic
		  if len(forward_slide_coincs) > 0:
			if opts.use_likelihood:
			  max_stats_array[slide - 1] = max(max_stats_array[slide - 1], numpy.max(forward_slide_coincs.getlikelihood()))
			else:
			   max_stats_array[slide - 1] = max(max_stats_array[slide - 1], numpy.max(forward_slide_coincs.getstat()))
		  
		  # for slide backward
		  # get coincs from the current slide
		  backward_slide_coincs = slidesCoincTriggers.getslide(-slide)

		  # store this slide's  maximum statistic
		  if len( backward_slide_coincs) > 0:    
			if opts.use_likelihood:
			  max_stats_array[slide - 1 + opts.num_slides] = max(max_stats_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getlikelihood()))
			else:
			  max_stats_array[slide - 1 + opts.num_slides] = max(max_stats_array[slide - 1 + opts.num_slides], numpy.max(backward_slide_coincs.getstat()))

		  # end of the loop over slides
		  
	  max_stats_array.sort()
	  Loudest_Stats[ifo_key] = numpy.sort(max_stats_array)[-1]
	  #print ifo_key, Loudest_Stats[ifo_key], max_stats_array[-2], max_stats_array[-3], max_stats_array[-4], max_stats_array[-5], max_stats_array[-6], max_stats_array[-7], max_stats_array[-8], max_stats_array[-9], max_stats_array[-10]
	  print str(ifo_key) + " " + str(Loudest_Stats[ifo_key])
	  
	  max_stats_dic[ifo_key] = max_stats_array


# define dictionary to hold max stats arrays for different ifo times
max_stats_times_dic = {}

for ifo_time in ifo_times[1:]:
  max_stats_times_dic["".join(ifo_time)] = numpy.zeros(2*opts.num_slides,  dtype = float)

# populate the dictionary  
for ifo_time in ifo_times[1:]:

  ifo_types_without_H1H2 = []
  ifo_types = CoincInspiralUtils.get_ifo_combos(ifo_time)
  
  for ifo_type in ifo_types:
	if not "".join(ifo_type) == 'H1H2':
	  ifo_types_without_H1H2.append(ifo_type)
	  
  for ifo_type in ifo_types_without_H1H2:
	for mchirp_bin in mchirp_bins:
  
	  ifo_key = "".join(ifo_type) + "_" + "".join(ifo_time) + "_" + mchirp_bin
	  
	  max_stats_times_dic["".join(ifo_time)] = numpy.maximum(max_stats_times_dic["".join(ifo_time)], max_stats_dic[ifo_key])
	  
# calculate two sigma statistic for each ifo time	
mean_stat = {}
sigma_stat = {}
two_sigma_stat = {}
for ifo_time in ifo_times[1:]:
  trimmed_max_stat = numpy.trim_zeros(max_stats_times_dic["".join(ifo_time)])
  if len(trimmed_max_stat) > 0:
	mean_stat["".join(ifo_time)] = trimmed_max_stat.mean()
	sigma_stat["".join(ifo_time)] = trimmed_max_stat.std()
	two_sigma_stat["".join(ifo_time)] = mean_stat["".join(ifo_time)] + 2.0*sigma_stat["".join(ifo_time)]
  else:
	mean_stat["".join(ifo_time)] = 0.0
	sigma_stat["".join(ifo_time)] = 0.0
	two_sigma_stat["".join(ifo_time)] = 0.0


# if there is no background set the loudest stat to a threshold value

for key in Loudest_Stats.keys():
  if Loudest_Stats[key] == 0.0:
	number_of_triggers = float(len(key.split("_")[0])) / 2.0
	Loudest_Stats[key] = (number_of_triggers * 5.5**2.0)**(1.0/2.0)

for ifo_time in ifo_times[1:]:
  if two_sigma_stat["".join(ifo_time)] == 0.0:
	two_sigma_stat["".join(ifo_time)] = (len(ifo_time) * 5.5**2.0)**(1.0/2.0)

summary_file = open("summary.txt", "w")	
summary_file.write("Category Loudest_stat \n")

for ifo_time in ifo_times[1:]:

  ifo_types_without_H1H2 = []
  ifo_types = CoincInspiralUtils.get_ifo_combos(ifo_time)
  
  for ifo_type in ifo_types:
	if not "".join(ifo_type) == 'H1H2':
	  ifo_types_without_H1H2.append(ifo_type)
	  
  for ifo_type in ifo_types_without_H1H2:
	for mchirp_bin in mchirp_bins:
  
	  ifo_key = "".join(ifo_type) + "_" + "".join(ifo_time) + "_" + mchirp_bin

	  summary_file.write(str(ifo_key) + " " + str(Loudest_Stats[ifo_key]) + "\n")
summary_file.write("IFO_TIME Mean Sigma Mean+2Sigma + \n")
for ifo_time in ifo_times[1:]:
  summary_file.write("".join(ifo_time) + " " + str(mean_stat["".join(ifo_time)]) + " " + str(sigma_stat["".join(ifo_time)]) + " " + str(two_sigma_stat["".join(ifo_time)]) + "\n")
  
summary_file.close()

output_file = open(opts.output_file, "w")
cPickle.dump(Loudest_Stats, output_file)
cPickle.dump(two_sigma_stat, output_file)
output_file.close()
				
				  
					
					  
						
						  
							
							  
								
								  
									
									    

#!/usr/bin/env python
"""
GRB Summary Information

Generate a set of summary information and plots for on-source and off-source
segments around a GRB trigger.
"""
from __future__ import division

__author__ = "Nickolas Fotopoulos <nvf@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]

import ConfigParser
import glob
import optparse
import os
import os.path as p
import sys

import inspiral
import inspiralutils
from glue import lal
from glue import segments, segmentsUtils
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import utils
from pylal import grbsummary

def get_options():
    """
    Parse user input and return opts.
    """
    parser = optparse.OptionParser(usage=__doc__,
        version="%prog CVS $Id$")

    # always required parameters
    parser.add_option("-s", "--analyzable-segfile",
        help="segfile containing all analyzable time (Science Mode segments)")
    # the various config files
    parser.add_option("-c", "--plot-config-file",
        help="plotting ini-file with parameters to pass to plotting routines")
    parser.add_option("-f","--config-file",action="store",type="string",\
      default=None, metavar=" FILE", help="use configuration file FILE" )
    parser.add_option("-g","--injection-config",action="store",type="string",\
      default=None, metavar=" FILE", help="use configuration file FILE" )

    parser.add_option("-l","--list",action="store",type="string",\
        default=None, metavar=" GRB LIST",\
        help="path to the file with GRB data stored")

    parser.add_option("-P", "--log-path",
        help="directory in which to place Condor logs")

    parser.add_option("-C", "--xml-cache",
        help="name of the cache file containing all XML outputs from each trigger_hipe pipeline")

    # mode parameters - their presence turns on a feature
    parser.add_option("-d", "--dq-file", help="get data quality mask from file")
    parser.add_option("-q", "--query-dq", action="store_true", default=False,
        help="query for data quality flags from CIT daily dump")

    parser.add_option("-n", "--figure-name", help="tag for plot output")
    parser.add_option("-O", "--analyze-onsource", action="store_true",
        default=False,
        help="open the box and include on-source segments in the summary")

    # auxiliary parameters
    parser.add_option("-p", "--padding-time", type=int,
        help="pad analysis segments by PADDING_TIME seconds")
    parser.add_option("-m", "--num-trials", type=int,
        help="number of off-source segments to use for background estimation")
    parser.add_option("-a","--onsource-left",action="store",type="int",\
        default=120, metavar=" ONLEFT",\
        help="Specifies the left onsource time window (default: 120)")
    parser.add_option("-b","--onsource-right",action="store",type="int",\
        default=60, metavar=" ONRIGHT",\
        help="Specifies the right onsource time window (default:60)")

    ## ??
    parser.add_option("-o", "--overwrite-dir", action="store_true",default=False,\
      help="overwrite contents in already existing directories" )


    parser.add_option("-v", "--verbose", action="store_true", default=False,
        help="print additional information during pipeline construction")


    (opts, args) = parser.parse_args()

    error_if_missing = ["analyzable_segfile", "list", "log_path",
        "onsource_left", "onsource_right", "padding_time",
        "xml_cache"]
    
    for opt in error_if_missing:
        if getattr(opts, opt) is None:
            raise ValueError, "missing required option: --%s" % opt.replace("_", "-")

    return opts

def initialize_jobs_nodes_descr(cp):
    """
    Return dictionaries of jobs, node classes, and cache descriptions.
    """
    job_dict = {}
    job_dict["inspiral"] = inspiral.PlotInspiralJob(cp)
    job_dict["thinca"] = inspiral.PlotThincaJob(cp)
    job_dict["numtemplates"] = inspiral.PlotNumtemplatesJob(cp)
    job_dict["injnum"] = inspiral.PlotInjnumJob(cp)
    job_dict["ethinca"] = inspiral.PlotEthincaJob(cp)
    job_dict["inspmissed"] = inspiral.PlotInspmissedJob(cp)
    job_dict["inspinj"] = inspiral.PlotInspinjJob(cp)
    job_dict["snrchi"] = inspiral.PlotSnrchiJob(cp)
    
    node_class_dict = {}
    node_class_dict["inspiral"] = inspiral.PlotInspiralNode
    node_class_dict["thinca"] = inspiral.PlotThincaNode
    node_class_dict["numtemplates"] = inspiral.PlotNumtemplatesNode
    node_class_dict["injnum"] = inspiral.PlotInjnumNode
    node_class_dict["ethinca"] = inspiral.PlotEthincaNode
    node_class_dict["inspmissed"] = inspiral.PlotInspmissedNode
    node_class_dict["inspinj"] = inspiral.PlotInspinjNode
    node_class_dict["snrchi"] = inspiral.PlotSnrchiNode
    
    descr_dict = {} # sieve on this description to find input files
    descr_dict["inspiral"] = "SIRE"
    descr_dict["thinca"] = "COIRE"
    descr_dict["numtemplates"] = "TMPLTBANK"
    descr_dict["injnum"] = "INJECTION"
    descr_dict["ethinca"] = "COIRE"
    descr_dict["inspmissed"] = "MISSED"
    descr_dict["inspinj"] = "COIRE"
    descr_dict["snrchi"] = "COIRE"
    
    return job_dict, node_class_dict, descr_dict

def write_masked_segments(exttrig_time, exttrig_dir, before_time, after_time):
    # load all analyzable segments
    analyzable_seglist = segmentsUtils.fromsegwizard(open(opts.analyzable_segfile))

    # determine on-source and off-source intervals for the external trigger
    on_source_seg = segments.segment(exttrig_time-before_time,
                                     exttrig_time+after_time)
    full_seg = grbsummary.symmetric_protraction(analyzable_seglist,
        on_source_seg, opts.padding_time, quantization_time, opts.num_trials)

    full_filename = "%s/full_segs.txt" % exttrig_dir
    segmentsUtils.tosegwizard(open(full_filename, "w"), segments.segmentlist([full_seg]))
    on_source_filename = "%s/on_source_segs.txt" % exttrig_dir
    segmentsUtils.tosegwizard(open(on_source_filename, "w"), segments.segmentlist([on_source_seg]))

    # get DQ info
    dq_veto_seglist = segments.segmentlist()  # FIXME
    dq_veto_filename = "dq_veto.txt"
    segmentsUtils.tosegwizard(open(dq_veto_filename, "w"), dq_veto_seglist)

    # generate on-source and off-source veto segmentlists
    on_source_veto_segs, off_source_veto_segs = \
        grbsummary.compute_masked_segments(analyzable_seglist,
        on_source_seg, veto_seglist=dq_veto_seglist,
        quantization_time=quantization_time)
    on_source_veto_filename = "%s/on_source_veto.txt" % exttrig_dir
    segmentsUtils.tosegwizard(open(on_source_filename, "w"),
        segments.segmentlist([on_source_seg]))
    off_source_veto_filename = "%s/off_source_veto.txt" % exttrig_dir
    segmentsUtils.tosegwizard(open(off_source_veto_filename, "w"),
        off_source_veto_segs)

    return on_source_veto_filename, on_source_veto_filename

def prepare_node(exttrig_dir, source_cache, description, node_class, job, dag):
    """
    Find the entries of source_cache matching description exactly and write
    them to exttrig_dir/description.cache, then create a node of type
    node_class, set its figure_name and input, then add it to the DAG.
    If cache is empty, no node is created.
    
    TODO: allow veto files
    """
    cache_filename = description + ".cache"

    # sieve for files matching 'description' in the source_cache
    cache = source_cache.sieve(description=description)
    
    if len(cache) == 0:
        print >>sys.stderr, "Warning: No files matching description %s."\
            " Skipping plotinspiral jobs for them." % description
        return

    # write the sieved files to a new cache-file named 'cache-filename'
    cache.tofile(open(cache_filename, "w"))

    # set the nodes and all parameters
    node = node_class(job)
    #node.set_cache(cache_filename)
    node.set_ifo_tag('')  # IFO tags needs to be removed. How?
    #node.set_output( exttrig_dir )

    # set important things by hand...
    node.add_var_opt('cache-file', exttrig_dir +'/'+cache_filename)
    node.add_input_file( exttrig_dir +'/'+cache_filename)
    node.add_var_opt('output-path', exttrig_dir)
    node.add_input_file( exttrig_dir )


    #node.set_figure_name(description)

    dag.add_node(node)

##############################################################################
# Main
##############################################################################

if __name__ == "__main__":
    # parse input
    opts = get_options()
    quantization_time = opts.onsource_left + opts.onsource_right
    
    # load plotting configuration
    cp = ConfigParser.ConfigParser()
    cp.read(opts.plot_config_file)
    
    # load external trigger table
    doc = utils.load_filename( opts.list, verbose=opts.verbose )
    try:
       exttrig_table = table.get_table(doc, lsctables.ExtTriggersTable.tableName)
    except:
      print >>sys.stderr, "No tables named external_trigger:table found in %s" % opts.list
      sys.exit(1)
    
    # initialize DAG
    if opts.verbose:
        print "Initializing DAG and plotting Jobs"
    dag = grbsummary.GRBSummaryDAG(opts.plot_config_file, opts.log_path)
    job_dict, node_class_dict, descr_dict = initialize_jobs_nodes_descr(cp)
    
    # FIXME: make all plots for now
    plots_to_do = job_dict.keys()
    
    ### Loop over GRBs
    for trigger in exttrig_table:

        # get the GPS time of the trigger
        exttrig_time = trigger.start_time

        ### Setup directory with human readable GRB number
        exttrig_dir = "GRB%s_plot" % trigger.event_number_grb
        inspiralutils.mkdir(exttrig_dir)
        os.chdir(exttrig_dir)
        
        if opts.verbose:
            print "Designing workflow for %s" % exttrig_dir
        
        ### Fetch cache of files
        cache = lal.Cache.fromfile(open(opts.xml_cache), coltype=int).unique()
        
        ### Determine and write segments
        # on_source_veto_filename, off_source_veto_filename = \
        #     write_masked_segments(exttrig_time, exttrig_dir,
        #                           opts.search_before_trigger,
        #                           opts.search_after_trigger)
        
        ### Design Workflow
        for plot_type in plots_to_do: # e.g. 'inspiral' 'thinca' 'ethinca' ...
            descr = descr_dict[plot_type]
            node_class = node_class_dict[plot_type]
            job = job_dict[plot_type]
            
            prepare_node(exttrig_dir, cache, descr+"", node_class, job, dag)
            prepare_node(exttrig_dir, cache, descr+"_H1H2", node_class, job, dag)
        os.chdir("..")

    ### Write DAG
    dag.write_sub_files()
    dag.write_dag()
    dag.write_script()

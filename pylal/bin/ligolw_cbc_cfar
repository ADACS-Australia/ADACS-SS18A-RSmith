#!/usr/bin/env python

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#

from optparse import OptionParser
try:
    import sqlite3
except ImportError:
    # pre 2.5.x
    from pysqlite2 import dbapi2 as sqlite3
import sys
import os

from pylal import ligolw_sqlutils as sqlutils

from glue import git_version
from glue.ligolw import dbtables
from glue.ligolw.utils import process

__prog__ = "ligolw_cbc_cfar"
__author__ = "Collin Capano <cdcapano@physics.syr.edu>"

description = \
"Calculates false alarm rates (FAR) in units of yr^(-1) and stores to " + \
"specified output_column. Writes results out to a new database. "


# =============================================================================
#
#                                   Set Options
#
# =============================================================================


def parse_command_line():
    """
    Parse the command line, return options and check for consistency among the
    options.
    """
    parser = OptionParser(
        version = git_version.verbose_msg,
        usage   = "%prog [options]",
        description = description
        )

    # following are related to file input and output naming
    parser.add_option( "-i", "--input", action = "store", type = "string", default = None,
        help = 
            "Input database to read. Can only input one at a time."
            )
    parser.add_option( "-o", "--output", action = "store", type = "string", default = None,
        help = 
            "Name of output database to save to."
            )
    parser.add_option( "-t", "--tmp-space", action = "store", type = "string", default = None,
        metavar = "PATH",
        help = 
            "Requried. Location of local disk on which to do work. " +
            "This is used to enhance performance in a networked " +
            "environment, and to protect against accidently " +      
            "overwriting the input database."
            )
    parser.add_option( "-v", "--verbose", action = "store_true", default = False,
        help = 
            "Print progress information"
           )
    parser.add_option( "-D", "--debug", action = "store_true", default = False,
        help =
            "Print SQLite queries used and the approximate time taken to run each one." )
    # following are generic inspiral_sql options
    parser.add_option( "-P", "--param-name", action = "store", default = None,
        metavar = "PARAMETER", 
        help = 
            "Can be any parameter in the coinc_inspiral table. " + 
            "Specifying this and param-ranges defines the categories " +
            "which the uncombined_fars are calculated in and are " +
            "combined over in the combined far calculation. " +
            "If not specified, triggers will not be binned when calculating " +
            "the uncombined FAR and so the uncombined FAR will be the same as " +
            "the combined FAR."
             )
    parser.add_option( "-R", "--param-ranges", action = "store", default = None,
        metavar = " [ LOW1, HIGH1 ); ( LOW2, HIGH2]; etc.",
        help = 
            "Requires --param-name. Specify the parameter ranges " +
            "to bin the triggers in. A '(' or ')' implies an open " +
            "boundary, a '[' or ']' a closed boundary. To specify " +
            "multiple ranges, separate each range by a ';'. Any " +
            "coincidences that fall outside of the union of all " +
            "specified ranges will be deleted." 
            )
    parser.add_option( "-X", "--exclude-coincs", action = "store", type = "string", default = None,
        metavar = " [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];" +
            "[ALL in INSTRUMENTS_ON2]; etc.",
        help = 
            "Exclude coincident types in specified detector times, " + 
            "e.g., '[H2,L1 in H1,H2,L1]'. Some rules: " +             
                "* Coinc-types and detector time must be separated by " + 
                "an ' in '. When specifying a coinc_type or detector " +
                "time, detectors and/or ifos must be separated by " +
                "commas, e.g. 'H1,L1' not 'H1L1'. " + 
                "* To specify multiple coinc-types in one type of time, " +
                "separate each coinc-type by a '+', e.g., " +
                "'[H1,H2 + H2,L1 in H1,H2,L1]'. " +
                "* To exclude all coincs in a specified detector time " +
                "or specific coinc-type in all times, use 'ALL'. E.g., " +
                "to exclude all H1,H2 triggers, use '[H1,H2 in ALL]' " +
                "or to exclude all H2,L1 time use '[ALL in H2,L1]'. " +
                "* To specify multiple exclusions, separate each " +
                "bracket by a ';'. " +
                "* Order of the instruments nor case of the letters " +
                "matter. So if your pinky is broken and you're " +
                "dyslexic you can type '[h2,h1 in all]' without a " +
                "problem. " 
            )
    parser.add_option( "-I", "--include-only-coincs", action = "store", type = "string", default = None,
        metavar = " [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];" +
            "[ALL in INSTRUMENTS_ON2]; etc.",
        help =
            "Opposite of --exclude-coincs: fars will be calculated " +
            "for the specified coinc types only (all other coincs will be " +
            "deleted from the output database). To avoid confusing overlaps, " +
            "cannot specify both --exclude-coincs and --include-only-coincs." 
            )
    parser.add_option( "-V", "--vacuum", action = "store_true", default = False,
        help = 
            "If turned on, will vacuum the database before saving. " +
            "This cleans any fragmentation and removes empty space " +
            "left behind by all the DELETEs, making the output " +
            "database smaller and more efficient. " +
            "WARNING: Since this requires rebuilding the entire " +
            "database, this can take awhile for larger files." 
            )
    # following are options specific to this program
    parser.add_option( "-s", "--ranking-stat", action = "store", type = "string", default = None,
        help =
            "Required. The stat to use to rank triggers for calculating " +
            "the false alarm rate. Can be any column in the coinc_inspiral table." 
            )
    parser.add_option( "-b", "--rank-by", action = "store", type = "string", default = None, 
        metavar = "MAX or MIN",
        help = 
            "Requried. Options are MAX or MIN. " +
            "This specifies whether to rank triggers by ascending (MAX) or " +
            "descending (MIN) stat value." 
            )
    parser.add_option( "-c", "--output-column", action = "store", type = "string", default = None, 
        help = 
            "Required. Column in the coinc_inspiral table to store output to. " +
            "If it doesn't exist, it will be created. Column name must be all lower-case."
            )
    parser.add_option( "-G", "--group-by-ifos", action = "store_true", default = False, 
        help = 
            "Turning on will cause triggers to be grouped by coincident ifos when " +
            "calculating FARs."
            )
    parser.add_option( "-T", "--time-units", action = "store", default = 'yr',
        metavar = "s, min, hr, days, OR yr",
        help = 
            "Time units to use when calculating FARs (the units of the FARs will be the inverse of this). " +
            "Options are s, min, hr, days, or yr. Default is yr."
            )
  
    (options, args) = parser.parse_args()
  
    # check for required options and for self-consistency
    if not options.input:
        raise ValueError, "No input specified."
    if not options.output:
        raise ValueError, "No output specified."
    if not options.tmp_space:
        raise ValueError, "--tmp-space is a requred argument."
    if not options.ranking_stat:
        raise ValueError, "No ranking stat specified."
    if not (options.rank_by.strip().upper() == 'MAX' or options.rank_by.strip().upper() == 'MIN'):
        raise ValueError, "--rank-by must be specified and set to either MAX or MIN."
    if options.param_name and not options.param_ranges:
        raise ValueError, "param-name requires param-ranges"
    if options.param_ranges and not options.param_name:
        raise ValueError, "param-ranges requires param-name"
    if not options.output_column:
        raise ValueError, "output_column is a required argument"
    if ' ' in options.output_column.strip():
        raise ValueError, "output_column cannot have spaces in it"
    if options.exclude_coincs and options.include_only_coincs:
        raise ValueError, "Cannot specify both --exclude-coincs and --include-only-coincs."

    return options, sys.argv[1:]


# =============================================================================
#
#                                     Main
#
# =============================================================================

#
#       Generic Initilization
#

opts, args = parse_command_line()

sqlite3.enable_callback_tracebacks(opts.debug)

# get input database filename
filename = opts.input
if not os.path.isfile( filename ):
    raise ValueError, "The input file, %s, cannot be found." % filename

# Setup working databases and connections
if opts.verbose: 
    print >> sys.stdout, "Setting up temp. database..."
working_filename = dbtables.get_connection_filename( 
    filename, tmp_path = opts.tmp_space, verbose = opts.verbose )
connection = sqlite3.connect( working_filename )
if opts.tmp_space:
    dbtables.set_temp_store_directory(connection, opts.tmp_space, verbose = opts.verbose)
dbtables.DBTable_set_connection( connection )

# Add program to process and process params table

# FIXME: remove the following two lines once boolean type
# has been properly handled
from glue.ligolw import types as ligolwtypes
ligolwtypes.FromPyType[type(True)] = ligolwtypes.FromPyType[type(8)]

# create an xmldoc representation of the database for writing the
# process and process-params
xmldoc = dbtables.get_xml(connection)
# Add entries to process and process_params tables for this program
proc_id = process.register_to_xmldoc(xmldoc, __prog__, opts.__dict__, version = git_version.id)

# Get param and param-ranges if specified
if opts.param_name:
    param_parser = sqlutils.parse_param_ranges( 'coinc_inspiral', opts.param_name, 
      opts.param_ranges, verbose = opts.verbose )
    param_name = param_parser.get_param_name()
    param_filters = param_parser.get_param_filters()
else:
    param_filters = None

# Get exclude_coincs list if specified
if opts.exclude_coincs:
    exclude_coinc_filters = sqlutils.parse_coinc_options( opts.exclude_coincs, 
        verbose = opts.verbose ).get_coinc_filters()
else:
    exclude_coinc_filters = None

# Get include_coincs list if specified
if opts.include_only_coincs:
    include_coinc_filters = sqlutils.parse_coinc_options( opts.include_only_coincs, 
        verbose = opts.verbose ).get_coinc_filters()
else:
    include_coinc_filters = None

# Clear coinc_inspiral table of triggers outside of interested ranges
if param_filters or exclude_coinc_filters or include_coinc_filters:
    sqlutils.apply_inclusion_rules_to_coinc_inspiral( connection, 
        exclude_coincs = exclude_coinc_filters,
        include_coincs = include_coinc_filters, 
        param_filters = param_filters, verbose = opts.verbose )

#
#         Program-specific Initialization
# 

# validate ranking stats
ranking_stat = sqlutils.validate_option( opts.ranking_stat )
rank_by = sqlutils.validate_option( opts.rank_by, lower = False ).upper()

# create column to store output to if it doesn't already exist
output_table, output_column = sqlutils.create_column( connection, 'coinc_inspiral', opts.output_column )

# sqlitize desired conversion function

def convert_livetime( duration, unit = opts.time_units ):
    """
    Uses sqlutils.convert_duration to automatically convert the frg_durs
    to the desired unit.
    """
    unit = sqlutils.validate_option( unit, lower = True )
    return sqlutils.convert_duration( duration, unit )

connection.create_function( 'convert_livetime', 1, convert_livetime )

# sqlitize param_parser.group_by_param_range()
if opts.param_name:
    connection.create_function("group_by_param", 1, param_parser.group_by_param_range)
    param_grouping = ''.join([ 'group_by_param(', param_name, ')' ])
else:
    param_grouping = '0'

#
# Collect information about the background 
#
if opts.verbose:
    print >> sys.stderr, "Getting background statistics..."

# initialize Summaries class, call background
background = sqlutils.Summaries()

# get information about all rows in the experiment summary table
sqlquery = """
    SELECT
        experiment_summary.experiment_id,
        experiment_summary.experiment_summ_id,
        convert_livetime(experiment_summary.duration),
        experiment_summary.datatype
    FROM
        experiment_summary
    """
for eid, esid, duration, datatype in connection.cursor().execute( sqlquery ):
    background.append_duration(eid, esid, duration)
    if datatype != "slide":
        background.append_zero_lag_id( eid, esid )

# calculate the background duration for each experiment_summary_id 
background.calc_bkg_durs()

# get desired ifo grouping
if opts.group_by_ifos:
  ifo_grouping = 'coinc_inspiral.ifos'
else:
  ifo_grouping = '"ALL_IFOS"'

# get all the triggers
sqlquery = ''.join([ """
    SELECT 
        experiment_summary.experiment_id,
        experiment_summary.experiment_summ_id,
        """,
        ifo_grouping, """,
        """,
        param_grouping, """,
        coinc_inspiral.""", ranking_stat,"""
    FROM 
        coinc_inspiral
    JOIN 
        experiment_summary, experiment_map ON (
            experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
            AND experiment_map.coinc_event_id == coinc_inspiral.coinc_event_id)
    """])

if opts.debug:
    import time
    print >> sys.stderr, sqlquery
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

for eid, esid, ifos, param_group, stat in connection.cursor().execute(sqlquery):
    background.add_to_bkg_stats(eid, esid, ifos, param_group, stat)

if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

# sort the background lists
background.sort_bkg_stats()

if rank_by == "MIN":
    connection.create_function("calc_ufar", 5, background.calc_ufar_by_min)
else:
    connection.create_function("calc_ufar", 5, background.calc_ufar_by_max)


#
#     Calculate FAR
#

if opts.verbose:
    print >> sys.stderr, "Calculating FAR..."
# calculate the uncombined far for each trigger and store in coinc_inspiral table
sqlquery = ''.join(["""
    UPDATE
        coinc_inspiral
    SET
        """, output_column, """ = (
            SELECT
                calc_ufar(
                    experiment_summary.experiment_id,
                    experiment_summary.experiment_summ_id,
                    """, ifo_grouping, """,
                    """, param_grouping, """,
                    coinc_inspiral.""", ranking_stat, """
                    ) 
            FROM 
                experiment_summary, experiment_map
            WHERE
                experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
                AND experiment_map.coinc_event_id == coinc_inspiral.coinc_event_id)"""])
if opts.debug:
    print >> sys.stderr, sqlquery
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]

connection.cursor().execute(sqlquery)

if opts.debug:
    print >> sys.stderr, time.localtime()[3], time.localtime()[4], time.localtime()[5]


# Vacuum database if desired
if opts.vacuum:
    if opts.verbose:
        print >> sys.stderr, "Vacuuming database..."
    connection.cursor().execute( 'VACUUM' )
    if opts.verbose:
        print >> sys.stderr, "done."

#
#       Save and Exit
#

connection.commit()
connection.close()

# write output database
dbtables.put_connection_filename(opts.output, working_filename, verbose = opts.verbose)

if opts.verbose: 
    print >> sys.stdout, "Finished!"

# set process end time
process.set_process_end_time(proc_id)
sys.exit(0)


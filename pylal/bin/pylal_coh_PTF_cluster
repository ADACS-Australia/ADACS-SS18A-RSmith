#!/usr/bin/env python

# Copyright (C) 2012 Ian W. Harry, Duncan M. Macleod
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""Cluster MultiInspiral events generated by the CBC coherent (PTF) analysis.
"""

# =============================================================================
# Preamble
# =============================================================================

from __future__ import division
import os
import sys
import time
import optparse
import numpy
import itertools

from pylal import git_version, llwapp, MultiInspiralUtils, SimInspiralUtils
from pylal.xlal.date import XLALGPSTimeNow

from glue import lal as cache
from glue.ligolw import ligolw, lsctables, table
from glue.ligolw import utils as ligolw_utils
from glue.ligolw.utils import process as ligolw_process
from glue.ligolw.utils import search_summary as ligolw_search_summary
            
__author__ = "Ian W. Harry <ian.harry@astro.cf.ac.uk>, Duncan M. Macleod <duncan.macleod@ligo.org>"
__version__ = git_version.id
__date__ = git_version.date

# set up timer
start = time.time()
elapsed_time = lambda: time.time()-start

# global print options
VERBOSE = False
PROFLE = False


def print_verbose(message, verbose=True, stream=sys.stdout, profile=True):
    """
    Print verbose messages to a file stream.

    @param message
        text to print
    @param verbose
        flag to print or not, default: False (don"t print)
    @param stream
        file object stream in which to print
    @param profile
        flag to print timestamp, default: False
    """
    if stream != sys.stderr:
        profile &= PROFILE
        verbose &= VERBOSE
    if profile and message.endswith("\n"):
        message = "%s (%.2f)\n" % (message.rstrip("\n"), elapsed_time())
    if verbose:
        stream.write(message)
        stream.flush()


# =============================================================================
# Parse command line
# =============================================================================

def parse_command_line():
    """Parse command line arguments, performing sanity checks
    """
    epilog = "For help, just ask.ligo.org"
    # setup parser
    parser = optparse.OptionParser(description=__doc__, epilog=epilog,
                                   formatter=optparse.IndentedHelpFormatter(4))
    parser.add_option("-p", "--profile", action="store_true", default=False,
                      help="timestamp output, default: %default")
    parser.add_option("-v", "--verbose", action="store_true", default=False,
                      help="verbose output, default: %default")
    parser.add_option("-V", "--version", action="version",
                      help="show program's version number and exit")
    parser.version = __version__

    # input options
    inputopts = optparse.OptionGroup(parser, "Input options")
    inputopts.add_option("-t", "--trig-file", action="append", type="string",
                         default=[],
                         help="Path to xml file containing MultiInspiralTable")
    inputopts.add_option("-c", "--cache-file", action="store", type="string",
                         default=None,
                         help=("Path to LAL-format cache file containing "
                               "paths to xml files containing "
                               "MultiInspiralTables"))
    parser.add_option_group(inputopts)

    # output options
    outputopts = optparse.OptionGroup(parser, "Output options")
    outputopts.add_option("-o", "--output-file", action="store",
                          type="string", help="File path for output xml.")
    outputopts.add_option("-s", "--preserve-sim-inspiral", action="store_true",
                          help=("copy the unique sim_inspiral rows into "
                                "output file, default: %default"))
    parser.add_option_group(outputopts)

    # clustering options
    clusteropts = optparse.OptionGroup(parser, "Clustering options")
    clusteropts.add_option("-W", "--time-window", action="store",
                           type="float", default=None,
                           help="The cluster time window")
    clusteropts.add_option("-l", "--loudest-by", type="string", default="snr",
                           metavar="COLUMN",
                           help=("return only the loudest MultiInspiral event "
                                 "for each injection, as ranked by COLUMN."))
    parser.add_option_group(clusteropts)

    (opts,args) = parser.parse_args()

    if not opts.trig_file and not opts.cache_file:
        parser.error("Must provide either --trig-file or --cache-file.")

    if not opts.time_window or opts.time_window <= 0:
        parser.error("A positive --time-window must be given.")

    return opts, args


# =============================================================================
# Cluster MultiInspiralTable
# =============================================================================

def cluster_multi_inspiral(mi_table, timeWindow, loudest_by="snr"):
    """Cluster a LIGOLw MultiInspiralTable by SNR according to a given
    clustering timeWindow.
    """
    cluster_table = table.new_from_template(mi_table)
    if not len(mi_table):
        return cluster_table

    # get data
    end_time = numpy.asarray(mi_table.get_end()).astype(float)
    if hasattr(mi_table, "get_%s" % loudest_by):
        snr = numpy.asarray(getattr(mi_table, "get_%s" % loudest_by)())
    else:
        snr = numpy.asarray(mi_table.get_column(loudest_by))

    # get times
    start = round(end_time.min())
    end = round(end_time.max()+1)

    #
    # bin all triggers in time
    #

    # generate bins
    numBins  = int((end-start)//timeWindow + 1) 
    timeBins = []
    loudestTrigSNR = numpy.zeros(numBins)
    loudestTrigTime = numpy.zeros(numBins)
    for n in range(numBins):
        timeBins.append([])

    # bin triggers
    for i,(t,s) in enumerate(itertools.izip(end_time, snr)):
        bin = int(float(t-start)//timeWindow)
        timeBins[bin].append(i)
        if not loudestTrigSNR[bin]:
            loudestTrigSNR[bin] = s
            loudestTrigTime[bin] = t
        else:
            if loudestTrigSNR[bin] < s:
                loudestTrigSNR[bin] = s
                loudestTrigTime[bin] = t

    #
    # cluster bins
    #

    # loop over all bins
    for i,bin in enumerate(timeBins):
        if len(bin)<1:
            continue
        first = i==0
        last = (i==numBins-1)
 
        prev = i-1
        next_ = i+1
        check_prev = (not first and len(timeBins[prev]) > 0)
        check_next = (not last and len(timeBins[next_]) > 0)

        # loop all triggers in bin
        for idx in bin:
            # search this trigger's own bin
            s = snr[idx]
            if s < loudestTrigSNR[i]:
                continue

            t = end_time[idx]

            # trigger was loudest in it's bin, search loudest event
            # in previous bin
            if (check_prev and (t - loudestTrigTime[prev]) < timeWindow and
                    s < loudestTrigSNR[prev]):
                continue

            # Same for the next_ bin
            if (check_next and (loudestTrigTime[next_] - t) < timeWindow and
                    s < loudestTrigSNR[next_]):
                continue
 
            loudest=True

            # trigger was loudest in it's bin, search previous bin
            if check_prev and not (t - loudestTrigTime[prev]) < timeWindow:
                for idx2 in timeBins[prev]:
                    t2 = end_time[idx2]
                    if (t - end_time[idx2]) < timeWindow and s < snr[idx2]:
                        loudest = False
                        break
            if not loudest:
                continue

            # if still loudest, check the next_ bin
            if check_next and not (loudestTrigTime[next_] - t) < timeWindow:
                for idx2 in timeBins[next_]:
                    if (end_time[idx2] - t) < timeWindow and s < snr[idx2]:
                        loudest = False
                        break
            if not loudest:
                continue
           
            # this was the loudest trigger in its vicinity,
            # keep it and move to the next_ bin
            cluster_table.append(mi_table[idx])
            break

    return cluster_table


# =============================================================================
# Run from command line
# =============================================================================

if __name__=='__main__':

    # parse command line
    opts, args = parse_command_line()
    VERBOSE = opts.verbose
    PROFILE = opts.profile

    outfile = opts.output_file

    #
    # setup output
    #

    # generate LIGOLw document
    outxml = ligolw.Document()
    outxml.appendChild(ligolw.LIGO_LW())

    # append our process
    process = ligolw_process.append_process(outxml, program=__file__,
                                            version=__version__)
    options = [("--time-window", opts.time_window), ("--output-file", outfile),
               ("--loudest-by", opts.loudest_by)] 
    if opts.cache_file:
        options.append(("--cache-file", opts.cache_file))
    for fp in opts.trig_file:
        options.append(("--trig-file", opts.trig_file))
    for key,val in options:
        ligolw_process.append_process_params(outxml, process,
                                             [(key, "lstring", val)])

    # 
    # load triggers
    #

    # list files
    trig_cache = cache.Cache()
    if opts.trig_file:
        trig_cache.extend(map(cache.CacheEntry.from_T050017, opts.trig_file))
    if opts.cache_file:
        trig_cache.extend(cache.Cache.fromfile(open(opts.cache_file, "r")))
    trig_cache.sort(key=lambda e: e.segment[0])
    trig_cache.checkfilesexist(on_missing="error")

    # load triggers with only those columns the parent job actually wrote
    N = len(trig_cache)
    print_verbose("Loading triggers from %d files...     \r" % N)
    trig_table = None
    if opts.preserve_sim_inspiral:
        inj_table = None
        inj_times = []
    for i,fp in enumerate(trig_cache.pfnlist()):
        # read XML from file (with more helpful error message)
        try:
            xmldoc = ligolw_utils.load_filename(fp, gz=fp.endswith("gz"))
        except:
            print_verbose("\nERROR: failed to load XML from %s.\n" % fp,
                          stream=sys.stderr)
            raise
        # read MultiInspiralTable
        try:
            mi_table = table.get_table(xmldoc,
                                       lsctables.MultiInspiralTable.tableName)
        except ValueError:
            mi_table = []
            print_verbose("\nwarning: failed to read MultiInspiralTable from "
                          "%s.\n" % fp, stream=sys.stderr)
        else:
            if mi_table and not trig_table:
                columns = [slot for slot in mi_table[0].__slots__ if
                           hasattr(mi_table[0], slot)]
                lsctables.MultiInspiralTable.loadcolumns = columns
                trig_table = lsctables.New(lsctables.MultiInspiralTable,
                                          columns=columns)
            if trig_table is not None:
                trig_table.extend(mi_table)
        # read SimInspiralTable
        if opts.preserve_sim_inspiral:
            try:
                sim_table = table.get_table(
                                xmldoc, lsctables.SimInspiralTable.tableName)
            except:
                print_verbose("\nwarning: failed to read SimInspiralTable "
                              "from %s.\n" % fp, stream=sys.stderr)
                sim_table = []
            else:
                if sim_table and not inj_table:
                    columns = [slot for slot in sim_table[0].__slots__ if
                               hasattr(sim_table[0], slot)]
                    lsctables.SimInspiralTable.loadcolumns = columns
                    inj_table = lsctables.New(lsctables.SimInspiralTable,
                                              columns=columns)
                if inj_table is not None:
                    inj_table.extend(sim for sim in sim_table
                                     if float(sim.get_end()) not in inj_times)
                    inj_times = [float(sim.get_end()) for sim in inj_table]
        print_verbose("Loading triggers from %d files...  %.2d%%\r"
                      % (N, int(100*(i)/N)))
    if not trig_table: 
        trig_table = lsctables.New(lsctables.MultiInspiralTable)
    print_verbose("Loading triggers from %d files...  100%%\n" % N)
    print_verbose("%d triggers found.\n" % (len(trig_table)), profile=False)
    if opts.preserve_sim_inspiral and not inj_table:
        inj_table = lsctables.New(lsctables.SimInspiralTable)
    if opts.preserve_sim_inspiral:
        print_verbose("%d unique SimInspirals identified.\n"
                      % len(inj_table), profile=False)

    #
    # cluster the triggers
    #

    cluster_table = cluster_multi_inspiral(trig_table, opts.time_window,
                                           loudest_by=opts.loudest_by)
    print_verbose("Clustering complete.\n")
    print_verbose("%d triggers remaining.\n" % (len(cluster_table)),
                  profile=False)

    #
    # preserve tables
    #

    # uniquify the SimInspiral IDs
    if opts.preserve_sim_inspiral:
        for i,idx in enumerate(inj_table):
            sim.simulation_id = "sim_inspiral:simulation_id:%d" % i
        outxml.childNodes[-1].appendChild(inj_table)

    #
    # write the clusters to file
    #

    outxml.childNodes[-1].appendChild(cluster_table)
    outxml.childNodes[-1].appendChild(
        lsctables.New(lsctables.SearchSummaryTable))
    ligolw_search_summary.append_search_summary(outxml, process)
    process.end_time = XLALGPSTimeNow().seconds
    ligolw_utils.write_filename(outxml, outfile, gz=outfile.endswith(".gz"),
                                verbose=opts.verbose)
    print_verbose("Done.\n")

#!/usr/bin/python

# Copyright (C) 2012 Ian W. Harry, Duncan M. Macleod
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""Cluster MultiInspiral events generated by the CBC coherent (PTF) analysis.
"""

from __future__ import division
import sys
import time
import optparse
import numpy
import warnings
from os.path import basename

from pylal import (git_version, MultiInspiralUtils)
from pylal.xlal.date import XLALGPSTimeNow

from glue import (lal as cache, iterutils)
from glue.segments import (segment as Segment, segmentlist as SegmentList,
                           segmentlistdict as SegmentListDict)
from glue.ligolw import (ligolw, lsctables, table, ilwd, utils as ligolw_utils)
from glue.ligolw.utils import (process as ligolw_process,
                               search_summary as ligolw_search_summary)
warnings.filterwarnings("ignore", "column name (.*) is not lower case",
                        UserWarning)

__author__ = "Ian W. Harry <ian.harry@astro.cf.ac.uk>, Duncan M. Macleod <duncan.macleod@ligo.org>"
__version__ = git_version.id
__date__ = git_version.date

# set up timer
start = time.time()
elapsed_time = lambda: time.time()-start

# global print options
VERBOSE = False
PROFLE = False


def print_verbose(message, verbose=True, stream=sys.stdout, profile=True):
    """Print verbose messages to a file stream.

    @param message
        text to print
    @param verbose
        flag to print or not, default: False (don"t print)
    @param stream
        file object stream in which to print
    @param profile
        flag to print timestamp, default: False
    """
    if stream != sys.stderr:
        profile &= PROFILE
        verbose &= VERBOSE
    if profile and message.endswith("\n"):
        message = "%s (%.2f)\n" % (message.rstrip("\n"), elapsed_time())
    elif profile and message.endswith("\r"):
        message = "%s (%.2f)\r" % (message.rstrip("\r"), elapsed_time())
    if verbose:
        stream.write(message)
        stream.flush()


if __name__=='__main__':

    # parse command line
    epilog = "For help, just ask.ligo.org"

    parser = optparse.OptionParser(description=__doc__, epilog=epilog,
                                   formatter=optparse.IndentedHelpFormatter(4))
    parser.add_option("-p", "--profile", action="store_true", default=False,
                      help="timestamp output, default: %default")
    parser.add_option("-v", "--verbose", action="store_true", default=False,
                      help="verbose output, default: %default")
    parser.add_option("-V", "--version", action="version",
                      help="show program's version number and exit")
    parser.version = git_version.verbose_msg

    # input options
    inputopts = parser.add_option_group("Input options")
    inputopts.add_option("-t", "--trig-file", action="append", type="string",
                         default=[],
                         help="Path to xml file containing MultiInspiralTable")
    inputopts.add_option("-c", "--cache-file", action="store", type="string",
                         default=None,
                         help=("Path to LAL-format cache file containing "
                               "paths to xml files containing "
                               "MultiInspiralTables"))

    # output options
    outputopts = parser.add_option_group("Output options")
    outputopts.add_option("-o", "--output-file", action="store",
                          type="string", help="File path for output xml.")
    outputopts.add_option("-s", "--preserve-sim-inspiral", action="store_true",
                          help=("copy the unique sim_inspiral rows into "
                                "output file, default: %default"))

    # clustering options
    clusteropts = parser.add_option_group("Clustering options")
    clusteropts.add_option("-W", "--time-window", action="store",
                           type="float", default=None,
                           help="The cluster time window")
    clusteropts.add_option("-l", "--loudest-by", type="string", default="snr",
                           metavar="COLUMN",
                           help=("return only the loudest MultiInspiral event "
                                 "for each injection, as ranked by COLUMN."))

    (opts,args) = parser.parse_args()

    if not opts.trig_file and not opts.cache_file:
        parser.error("Must provide either --trig-file or --cache-file.")

    if not opts.time_window or opts.time_window <= 0:
        parser.error("A positive --time-window must be given.")

    VERBOSE = opts.verbose
    PROFILE = opts.profile
    outfile = opts.output_file

    # generate LIGOLw document
    outxml = ligolw.Document()
    outxml.appendChild(ligolw.LIGO_LW())

    # append our process
    process = ligolw_process.append_process(outxml, program=__file__,
                                            version=__version__)
    options = [("--time-window", opts.time_window), ("--output-file", outfile),
               ("--loudest-by", opts.loudest_by)]
    if opts.cache_file:
        options.append(("--cache-file", opts.cache_file))
    for fp in opts.trig_file:
        options.append(("--trig-file", opts.trig_file))
    for key,val in options:
        ligolw_process.append_process_params(outxml, process,
                                             [(key, "lstring", val)])

    # load trigger files
    trig_cache = cache.Cache()
    if opts.trig_file:
        trig_cache.extend(map(cache.CacheEntry.from_T050017, opts.trig_file))
    if opts.cache_file:
        trig_cache.extend(cache.Cache.fromfile(open(opts.cache_file, "r")))
    trig_cache.sort(key=lambda e: e.segment[0])
    trig_cache.checkfilesexist(on_missing="error")

    # get time slide row class
    TimeSlideId = ilwd.get_ilwdchar_class("multi_inspiral", "time_slide_id")

    # initialise search summary
    search_summ_in = SegmentList()
    search_summ_out = SegmentList()
    search_summ_ifos = None

    # load events
    N = len(trig_cache)
    print_verbose("Loading triggers from %d files...     \r" % N)
    trig_table = lsctables.New(lsctables.MultiInspiralTable)
    append = trig_table.append
    if opts.preserve_sim_inspiral:
        inj_table = lsctables.New(lsctables.SimInspiralTable)
    slide_table = lsctables.New(lsctables.TimeSlideTable)
    for i,fp in enumerate(trig_cache.pfnlist()):
        # read XML from file (with more helpful error message)
        xmldoc = ligolw_utils.load_filename(fp, gz=fp.endswith("gz"))
        #table.reassign_ids(xmldoc) FIXME: doesn't map slides<-->multis

        # read process_id
        process_table = table.get_table(xmldoc,
                                        lsctables.ProcessTable.tableName)
        process_id = process_table[0].process_id

        # read SearchSummaryTable
        search_summ_table = table.get_table(
                                xmldoc, lsctables.SearchSummaryTable.tableName)
        iterutils.inplace_filter(
            lambda row: row.process_id == process_id, search_summ_table)
        search_summ_in += search_summ_table.get_inlist()
        search_summ_out += search_summ_table.get_outlist()
        try:
            search_summ_ifos = search_summ_table[0].get_ifos()
        except IndexError:
            pass

        # read MultiInspiralTable and remap time slides
        mi_table = table.get_table(xmldoc,
                                   lsctables.MultiInspiralTable.tableName)

        # read TimeSlideTable, remapping ids for duplicate slides
        time_slide_table = table.get_table(
                               xmldoc, lsctables.TimeSlideTable.tableName)
        slide_map = dict()
        for id_, vector in time_slide_table.as_dict().items():
            slide_map[int(id_)] = int(slide_table.get_time_slide_id(
                                          vector, create_new=process))
        for mi in mi_table:
            idx = slide_map[int(mi.time_slide_id)]
            mi.time_slide_id = TimeSlideId(idx)
            append(mi)
        trig_table.sync_next_id()

        # read SimInspiralTable
        if opts.preserve_sim_inspiral:
            sim_table = table.get_table(xmldoc,
                                        lsctables.SimInspiralTable.tableName)
            inj_table.extend(filter(lambda row: row.get_end() not in
                                                inj_table.get_end(), sim_table))
            inj_table.sync_next_id()

        print_verbose("Loading triggers from %d files...  %.2d%%\r"
                      % (N, int(100*(i)/N)))

    search_summ_in.coalesce()
    search_summ_out.coalesce()
    gps_start,gps_end = search_summ_out.extent()

    print_verbose("Loading triggers from %d files...  100%%\n" % N)
    print_verbose("%d triggers found.\n" % (len(trig_table)), profile=False)
    if opts.preserve_sim_inspiral:
        print_verbose("%d unique SimInspirals identified.\n"
                      % len(inj_table), profile=False)

    # cluster the triggers separately for each time slide
    slides = slide_table.as_dict()
    cluster_table = table.new_from_template(trig_table)
    expr_table = lsctables.New(lsctables.ExperimentTable)
    expr_summ_table = lsctables.New(lsctables.ExperimentSummaryTable)
    for slide_id,vector in sorted(slides.items(), key=lambda (a,b): int(a)):
        print_verbose("Clustering time slide %d... " % int(slide_id))
        mi_slide_table = table.new_from_template(cluster_table)
        mi_slide_table.extend(filter(lambda row: int(row.time_slide_id) ==
                                                 int(slide_id), trig_table))
        clusters = MultiInspiralUtils.cluster_multi_inspirals(
                       mi_slide_table, opts.time_window,
                       loudest_by=opts.loudest_by)
        cluster_table.extend(clusters)
        # work out livetime for this slide
        expr_span = SegmentList([Segment(gps_start, gps_end)])
        slide_segments = SegmentListDict((ifo, expr_span) for ifo in
                                         vector.keys()).copy()
        slide_segments.offsets.update(dict((ifo, -offset) for ifo,offset in
                                           vector.iteritems()))
        expr_start, expr_end = (
            slide_segments.intersection(vector.keys()).extent())
        # construct experiment
        expr_id = expr_table.write_new_expr_id("cbc", "coh_PTF_inspiral",
                                               None, vector.keys(),
                                               expr_start, expr_end)
        datatype = any(vector.values()) and "full_data_slide" or "full_data"
        expr_summ_table.write_experiment_summ(expr_id, slide_id, None, datatype)
        expr_summ_table[-1].nevents = len(clusters)
        expr_summ_table[-1].duration = int(expr_end-expr_start)
        print_verbose("%d events selected.\n" % len(clusters))
    print_verbose("Clustering complete.\n")

    # write the output file
    table.reset_next_ids(lsctables.TableByName.values())
    outxml.childNodes[-1].appendChild(slide_table)
    outxml.childNodes[-1].appendChild(expr_summ_table)
    outxml.childNodes[-1].appendChild(expr_table)
    outxml.childNodes[-1].appendChild(
        lsctables.New(lsctables.SearchSummaryTable))
    for in_seg,out_seg in zip(search_summ_in, search_summ_out):
        ligolw_search_summary.append_search_summary(outxml, process,
                                                    nevents=len(cluster_table),
                                                    comment=basename(__file__),
                                                    inseg=in_seg,
                                                    outseg=out_seg,
                                                    ifos=search_summ_ifos)
    if opts.preserve_sim_inspiral:
        outxml.childNodes[-1].appendChild(inj_table)
    outxml.childNodes[-1].appendChild(cluster_table)
    #table.reassign_ids(outxml) # FIXME: replace when slide<-->multi works
    process.set_ifos(search_summ_ifos)
    process.end_time = XLALGPSTimeNow().seconds
    ligolw_utils.write_filename(outxml, outfile, gz=outfile.endswith(".gz"),
                                verbose=opts.verbose)
    print_verbose("Done.\n")

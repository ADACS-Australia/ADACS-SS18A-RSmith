#!/usr/bin/python

# Copyright (C) 2012 Ian W. Harry, Duncan M. Macleod
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""Cluster MultiInspiral events generated by the CBC coherent (PTF) analysis.
"""

from __future__ import division
import os
import sys
import time
import optparse
import numpy
import warnings

from pylal import (git_version, MultiInspiralUtils)
from pylal.xlal.date import XLALGPSTimeNow

from glue import (lal as cache, iterutils)
from glue.segments import segmentlist as SegmentList
from glue.ligolw import (ligolw, lsctables, table, ilwd, utils as ligolw_utils)
from glue.ligolw.utils import (process as ligolw_process,
                               search_summary as ligolw_search_summary)
warnings.filterwarnings("ignore", "column name (.*) is not lower case",
                        UserWarning)

__author__ = "Ian W. Harry <ian.harry@astro.cf.ac.uk>, Duncan M. Macleod <duncan.macleod@ligo.org>"
__version__ = git_version.id
__date__ = git_version.date

# set up timer
start = time.time()
elapsed_time = lambda: time.time()-start

# global print options
VERBOSE = False
PROFLE = False


def print_verbose(message, verbose=True, stream=sys.stdout, profile=True):
    """Print verbose messages to a file stream.

    @param message
        text to print
    @param verbose
        flag to print or not, default: False (don"t print)
    @param stream
        file object stream in which to print
    @param profile
        flag to print timestamp, default: False
    """
    if stream != sys.stderr:
        profile &= PROFILE
        verbose &= VERBOSE
    if profile and message.endswith("\n"):
        message = "%s (%.2f)\n" % (message.rstrip("\n"), elapsed_time())
    elif profile and message.endswith("\r"):
        message = "%s (%.2f)\r" % (message.rstrip("\r"), elapsed_time())
    if verbose:
        stream.write(message)
        stream.flush()


if __name__=='__main__':

    # parse command line
    epilog = "For help, just ask.ligo.org"

    parser = optparse.OptionParser(description=__doc__, epilog=epilog,
                                   formatter=optparse.IndentedHelpFormatter(4))
    parser.add_option("-p", "--profile", action="store_true", default=False,
                      help="timestamp output, default: %default")
    parser.add_option("-v", "--verbose", action="store_true", default=False,
                      help="verbose output, default: %default")
    parser.add_option("-V", "--version", action="version",
                      help="show program's version number and exit")
    parser.version = git_version.verbose_msg

    # input options
    inputopts = parser.add_option_group("Input options")
    inputopts.add_option("-t", "--trig-file", action="append", type="string",
                         default=[],
                         help="Path to xml file containing MultiInspiralTable")
    inputopts.add_option("-c", "--cache-file", action="store", type="string",
                         default=None,
                         help=("Path to LAL-format cache file containing "
                               "paths to xml files containing "
                               "MultiInspiralTables"))

    # output options
    outputopts = parser.add_option_group("Output options")
    outputopts.add_option("-o", "--output-file", action="store",
                          type="string", help="File path for output xml.")
    outputopts.add_option("-s", "--preserve-sim-inspiral", action="store_true",
                          help=("copy the unique sim_inspiral rows into "
                                "output file, default: %default"))
    outputopts.add_option("-x", "--preserve-time-slides",
                          action="store_true",
                          help=("build a new TimeSlideTable from those in the"
                                "input files, default: %default"))

    # clustering options
    clusteropts = parser.add_option_group("Clustering options")
    clusteropts.add_option("-W", "--time-window", action="store",
                           type="float", default=None,
                           help="The cluster time window")
    clusteropts.add_option("-l", "--loudest-by", type="string", default="snr",
                           metavar="COLUMN",
                           help=("return only the loudest MultiInspiral event "
                                 "for each injection, as ranked by COLUMN."))

    (opts,args) = parser.parse_args()

    if not opts.trig_file and not opts.cache_file:
        parser.error("Must provide either --trig-file or --cache-file.")

    if not opts.time_window or opts.time_window <= 0:
        parser.error("A positive --time-window must be given.")

    VERBOSE = opts.verbose
    PROFILE = opts.profile
    outfile = opts.output_file

    # generate LIGOLw document
    outxml = ligolw.Document()
    outxml.appendChild(ligolw.LIGO_LW())

    # append our process
    process = ligolw_process.append_process(outxml, program=__file__,
                                            version=__version__)
    options = [("--time-window", opts.time_window), ("--output-file", outfile),
               ("--loudest-by", opts.loudest_by)]
    if opts.cache_file:
        options.append(("--cache-file", opts.cache_file))
    for fp in opts.trig_file:
        options.append(("--trig-file", opts.trig_file))
    for key,val in options:
        ligolw_process.append_process_params(outxml, process,
                                             [(key, "lstring", val)])

    # load trigger files
    trig_cache = cache.Cache()
    if opts.trig_file:
        trig_cache.extend(map(cache.CacheEntry.from_T050017, opts.trig_file))
    if opts.cache_file:
        trig_cache.extend(cache.Cache.fromfile(open(opts.cache_file, "r")))
    trig_cache.sort(key=lambda e: e.segment[0])
    trig_cache.checkfilesexist(on_missing="error")

    # get time slide row class
    TimeSlideId = ilwd.get_ilwdchar_class("multi_inspiral", "time_slide_id")

    # initialise search summary
    search_summ_in = SegmentList()
    search_summ_out = SegmentList()
    search_summ_ifos = None

    # load events
    N = len(trig_cache)
    print_verbose("Loading triggers from %d files...     \r" % N)
    trig_table = lsctables.New(lsctables.MultiInspiralTable)
    append = trig_table.append
    if opts.preserve_sim_inspiral:
        inj_table = lsctables.New(lsctables.SimInspiralTable)
    if opts.preserve_time_slides:
        slide_table = lsctables.New(lsctables.TimeSlideTable)
    for i,fp in enumerate(trig_cache.pfnlist()):
        # read XML from file (with more helpful error message)
        xmldoc = ligolw_utils.load_filename(fp, gz=fp.endswith("gz"))
        #table.reassign_ids(xmldoc) FIXME: doesn't map slides<-->multis

        # read process_id
        process_table = table.get_table(xmldoc,
                                        lsctables.ProcessTable.tableName)
        process_id = process_table[-1].process_id

        # read SearchSummaryTable
        search_summ_table = table.get_table(
                                xmldoc, lsctables.SearchSummaryTable.tableName)
        iterutils.inplace_filter(
            lambda row: row.process_id == process_id, search_summ_table)
        search_summ_in += search_summ_table.get_inlist()
        search_summ_out += search_summ_table.get_outlist()
        try:
            search_summ_ifos = search_summ_table[0].get_ifos()
        except IndexError:
            pass

        # read MultiInspiralTable and remap time slides
        mi_table = table.get_table(xmldoc,
                                   lsctables.MultiInspiralTable.tableName)

        # read TimeSlideTable, remapping ids for duplicate slides
        if opts.preserve_time_slides:
            time_slide_table = table.get_table(
                                   xmldoc, lsctables.TimeSlideTable.tableName)
            slide_map = dict()
            for id_, vector in time_slide_table.as_dict().items():
                slide_map[int(id_)] = int(slide_table.get_time_slide_id(
                                              vector, create_new=process))
            for mi in mi_table:
                idx = slide_map[int(mi.time_slide_id)]
                mi.time_slide_id = TimeSlideId(idx)
                append(mi)
        else:
            trig_table.extend(mi_table)
        trig_table.sync_next_id()

        # read SimInspiralTable
        if opts.preserve_sim_inspiral:
            sim_table = table.get_table(xmldoc,
                                        lsctables.SimInspiralTable.tableName)
            inj_table.extend(filter(lambda row: row.get_end() not in
                                                inj_table.get_end(), sim_table))
            inj_table.sync_next_id()

        print_verbose("Loading triggers from %d files...  %.2d%%\r"
                      % (N, int(100*(i)/N)))

    print_verbose("Loading triggers from %d files...  100%%\n" % N)
    print_verbose("%d triggers found.\n" % (len(trig_table)), profile=False)
    if opts.preserve_sim_inspiral:
        print_verbose("%d unique SimInspirals identified.\n"
                      % len(inj_table), profile=False)

    # cluster the triggers
    cluster_table = MultiInspiralUtils.cluster_multi_inspirals(
                        trig_table, opts.time_window,
                        loudest_by=opts.loudest_by)
    print_verbose("Clustering complete.\n")
    print_verbose("%d triggers remaining.\n" % (len(cluster_table)),
                  profile=False)

    # write the clusters to file
    table.reset_next_ids(lsctables.TableByName.values())
    if opts.preserve_time_slides:
        outxml.childNodes[-1].appendChild(time_slide_table)
    if opts.preserve_sim_inspiral:
        outxml.childNodes[-1].appendChild(inj_table)
    outxml.childNodes[-1].appendChild(
        lsctables.New(lsctables.SearchSummaryTable))
    outxml.childNodes[-1].appendChild(cluster_table)
    search_summ_in.coalesce()
    search_summ_out.coalesce()
    for in_seg,out_seg in zip(search_summ_in, search_summ_out):
        ligolw_search_summary.append_search_summary(outxml, process,
                                                    nevents=len(cluster_table),
                                                    comment=os.path.basename(
                                                                __file__),
                                                    inseg=in_seg,
                                                    outseg=out_seg,
                                                    ifos=search_summ_ifos)
    #table.reassign_ids(outxml) # FIXME: replace when slide<-->multi works
    process.set_ifos(search_summ_ifos)
    process.end_time = XLALGPSTimeNow().seconds
    ligolw_utils.write_filename(outxml, outfile, gz=outfile.endswith(".gz"),
                                verbose=opts.verbose)
    print_verbose("Done.\n")

#!/usr/bin/python
#
# Copyright (C) 2008  Drew G. Keppel
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


#
# =============================================================================
#
#				   Preamble
#
# =============================================================================
#


import bisect
from new import instancemethod
from optparse import OptionParser
try:
	import sqlite3
except ImportError:
	# pre 2.5.x
	from pysqlite2 import dbapi2 as sqlite3
import sys


from glue import segments
from glue import iterutils
from glue.ligolw import lsctables
from glue.ligolw import table
from glue.ligolw import dbtables
from glue.ligolw import utils
from pylal import git_version
from pylal import rate
from pylal import db_thinca_rings
from pylal.xlal.datatypes.ligotimegps import LIGOTimeGPS
import scipy
import numpy
lsctables.LIGOTimeGPS = LIGOTimeGPS


__author__ = "Drew G. Keppel <drew.keppel@ligo.org>"
__version__ = "git id %s" % git_version.id
__date__ = git_version.date


#
# =============================================================================
#
#				 Command Line
#
# =============================================================================
#


def parse_command_line():
	parser = OptionParser(
		version = "Name: %%prog\n%s" % git_version.verbose_msg,
		usage = "%prog [options] [file ...]",
		description = "%prog does blah blah blah."
	)
	parser.add_option("-t", "--tmp-space", metavar = "path", help = "Path to a directory suitable for use as a work area while manipulating the database file.  The database file will be worked on in this directory, and then moved to the final location when complete.  This option is intended to improve performance when running in a networked environment, where there might be a local disk with higher bandwidth than is available to the filesystem on which the final output will reside.")
	parser.add_option("--output-dir", metavar = "path", help = "Path to directory to store output files")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")
	options, filenames = parser.parse_args()

	return options, (filenames or [None])


#
# =============================================================================
#
#				 Book-Keeping
#
# =============================================================================
#


class Summaries(object):
	def __init__(self, Nbins):
		self.Nbins = Nbins
		self.rings = None
		self.offset_vectors = None
		self.ifos = set()
		self.dbls = set()
		self.likelihoods = {}
		self.sngl_slices = [('snr', 'chisq'), ('snr', 'mtotal'), ('chisq', 'mtotal')]
		self.slices_bins = {}
		sngls_set = set()
		for col1,col2 in self.sngl_slices:
			sngls_set.add(col1)
			sngls_set.add(col2)
		self.idx_sngls = {}
		for id,key in enumerate(list(sngls_set) + ['weight', 'coinc_event_id', 'filename']):
			self.idx_sngls[key] = id
		self.minmax = {}
		for key in sngls_set:
			self.minmax.setdefault(key, {})

	def calc_delta_t_inj(self, trigger1_end_time, trigger1_end_time_ns, trigger2_end_time, trigger2_end_time_ns):
		try:
			return abs((trigger1_end_time - trigger2_end_time) + (trigger1_end_time_ns - trigger2_end_time)*1e-9)
		except: print "calc_delta_t_inj() failed"

	def calc_delta_t(self, trigger1_ifo, trigger1_end_time, trigger1_end_time_ns, trigger2_ifo, trigger2_end_time, trigger2_end_time_ns, time_slide_id):
		#print >>sys.stderr, "calculating delta_t"
		trigger1_true_end_time = dbtables.lsctables.LIGOTimeGPS(trigger1_end_time, trigger1_end_time_ns)
		trigger2_true_end_time = dbtables.lsctables.LIGOTimeGPS(trigger2_end_time, trigger2_end_time_ns)
		# find the instruments that were on at trigger 1's end time and
		# find the ring that contains this trigger
		try:
			[ring] = [segs[segs.find(trigger1_end_time)] for segs in self.rings.values() if trigger1_end_time in segs]
		except ValueError:
			# FIXME THERE SEEMS TO BE A BUG IN  THINCA!  Occasionally thinca records a trigger on the upper boundary
			# of its ring.  This would make it outside the ring which is very problematic.  It needs to be fixed in thinca
			# for now we'll allow the additional check that the other trigger is in the ring and use it.
			print >>sys.stderr, "trigger1 found not on a ring, trying trigger2"
			[ring] = [segs[segs.find(trigger2_end_time)] for segs in self.rings.values() if trigger2_end_time in segs]
			# now we can unslide the triggers on the ring
		try:
			trigger1_true_end_time = SnglInspiralUtils.slideTimeOnRing(trigger1_true_end_time, self.offset_vectors[time_slide_id][trigger1_ifo], ring)
			trigger2_true_end_time = SnglInspiralUtils.slideTimeOnRing(trigger2_true_end_time, self.offset_vectors[time_slide_id][trigger2_ifo], ring)
			out = abs(trigger1_true_end_time - trigger2_true_end_time)
			return float(out)
		except:
			print "calc delta t failed",trigger1_true_end_time, trigger2_true_end_time, ring
			return float(abs(trigger1_true_end_time - trigger2_true_end_time)) % 1

	def add_sngl_minmax(self, ifo, values):
		for key in self.minmax.keys():
			if values[2*self.idx_sngls[key]]:
				self.minmax[key].setdefault(ifo, []).extend(list(values[2*self.idx_sngls[key]:2*self.idx_sngls[key]+2]))

	def setup_binned_ratios(self):
		for ifo in self.ifos:
			self.slices_bins[ifo] = {}
			for key in self.sngl_slices:
				self.slices_bins[ifo][key] = rate.BinnedRatios(rate.NDBins((rate.LogarithmicBins(min(self.minmax[key[0]][ifo]), max(self.minmax[key[0]][ifo]), self.Nbins), rate.LogarithmicBins(min(self.minmax[key[1]][ifo]), max(self.minmax[key[1]][ifo]), self.Nbins))))

	def add_bkg_sngl(self, ifo, values):
		for key in self.sngl_slices:
			self.slices_bins[ifo][key].incdenominator((values[self.idx_sngls[key[0]]],values[self.idx_sngls[key[1]]]), weight=values[self.idx_sngls['weight']])

	def add_inj_sngl(self, ifo, values):
		for key in self.sngl_slices:
			self.slices_bins[ifo][key].incnumerator((values[self.idx_sngls[key[0]]],values[self.idx_sngls[key[1]]]), weight=values[self.idx_sngls['weight']])

	def add_bkg_dbl(self, filename, ifos, values):
		self.dbls.add(frozenset(ifos))
		self.bkg_dbls.setdefault(frozenset(ifos), []).append(tuple([filename] + list(values)))

	def add_inj_dbl(self, filename, ifos, values):
		self.dbls.add(frozenset(ifos))
		self.inj_dbls.setdefault(frozenset(ifos), []).append(tuple([filename] + list(values)))

	def filter_binned_ratios(self):
		xmldoc = lsctables.ligolw.Document()
		xmldoc.appendChild(lsctables.ligolw.LIGO_LW())
		# FIXME should be key2[1] vs key2[0]
		for key1 in self.slices_bins.keys():
			for key2 in self.slices_bins[key1].keys():
				tablename = "binned_ratio_"+"".join(key1)+"_"
				if len(key2[0]) > 1 or len(key2[1]) > 1:
					tablename += "".join(key2[0]) + "_vs_" + "".join(key2[1])
				else:
					tablename += "_vs_".join(key2)
				if options.verbose:
					print >>sys.stderr, "\tsmoothing %s ..." % tablename
				rate.filter_binned_ratios(self.slices_bins[key1][key2], rate.gaussian_window2d(self.slices_bins[key1][key2].numerator.bins.shape[0]/30, self.slices_bins[key1][key2].numerator.bins.shape[1]/30, sigma=60))
				xmldoc.childNodes[-1].appendChild(rate.binned_ratios_to_xml(self.slices_bins[key1][key2], tablename))

		if options.output_dir:
			utils.write_filename(xmldoc, options.output_dir + "/likelihood_snr_chisq.xml.gz", gz = True, verbose = True)
		else:
			utils.write_filename(xmldoc, "likelihood_snr_chisq.xml.gz", gz = True, verbose = True)
		sys.exit(0)

	def compute_sngl_likelihood(self, ifo, values):
		for key in self.sngl_slices:
			self.likelihoods[(values[self.idx_sngls['filename']],values[self.idx_sngls['coinc_event_id']])] *= self.slices_bins[ifo][key][(values[self.idx_sngls[key[0]]],values[self.idx_sngls[key[1]]])]

	def likelihood_map(self, filename, coinc_event_id):
		return self.likelihoods[(filename, coinc_event_id)]


#
# =============================================================================
#
#				SQLITE Queries
#
# =============================================================================
#

def single_inj_minmax(values):
	query = """
SELECT"""
	keys = values.items()
	keys.sort(cmp=lambda x,y: cmp(x[1],y[1]))
	for value in keys:
		if value[0] in ['coinc_event_id', 'filename', 'weight']:
			continue
		if not value == keys[0]:
			query += ""","""
		query += """
	MIN(snglA.""" + value[0] + """),
	MAX(snglA.""" + value[0] + """)"""

	query += """,
	coinc_inspiral.coinc_event_id
FROM
	coinc_inspiral
	JOIN coinc_event_map AS mapA ON (mapA.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN sngl_inspiral AS snglA ON (snglA.event_id == mapA.event_id)
	JOIN coinc_event_map AS mapB ON (mapB.event_id == coinc_inspiral.coinc_event_id)
	JOIN coinc_event_map AS mapC ON (mapC.coinc_event_id == mapC.coinc_event_id)
	JOIN sim_inspiral ON (sim_inspiral.simulation_id == mapC.event_id)
	JOIN coinc_event AS sim_coinc_event ON (sim_coinc_event.coinc_event_id == mapC.coinc_event_id)
	JOIN coinc_definer ON (coinc_definer.coinc_def_id == sim_coinc_event.coinc_def_id)
WHERE
	coinc_definer.search == 'inspiral'
	AND coinc_definer.search_coinc_type == 2
	AND mapA.table_name == 'sngl_inspiral'
	AND mapB.table_name == 'coinc_event'
	AND mapC.table_name == 'sim_inspiral'
	AND snglA.ifo == ?
	-- require coinc to not be background (= at least one of its time slide offsets is non-zero)
	-- FIXME this has to call a function to get coinc_def id
	AND NOT EXISTS (
		SELECT
			*
		FROM
			time_slide
		WHERE
			time_slide.time_slide_id == sim_coinc_event.time_slide_id
			AND time_slide.offset != 0
	)
"""

	return query

def single_inj(values):
	query = """
SELECT"""
	keys = values.items()
	keys.sort(cmp=lambda x,y: cmp(x[1],y[1]))
	for value in keys:
		if value[0] == 'coinc_event_id' or value[0] == 'filename':
			continue
		if not value == keys[0]:
			query += ""","""
		if value[0] == 'weight':
			query += """
	-- Work out the correction factor for injection population distances
	-- FIXME this breaks if more than one inspinj job
	CASE (SELECT value FROM process_params WHERE program =="inspinj" AND param =="--d-distr")
		WHEN "log10" THEN  sim_inspiral.distance * sim_inspiral.distance * sim_inspiral.distance
		WHEN "linear" THEN  sim_inspiral.distance * sim_inspiral.distance
		ELSE 1.0 END"""
			continue

		query += """
	snglA.""" + value[0]

	query += """,
	coinc_inspiral.coinc_event_id
FROM
	coinc_inspiral
	JOIN coinc_event_map AS mapA ON (mapA.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN sngl_inspiral AS snglA ON (snglA.event_id == mapA.event_id)
	JOIN coinc_event_map AS mapB ON (mapB.event_id == coinc_inspiral.coinc_event_id)
	JOIN coinc_event_map AS mapC ON (mapC.coinc_event_id == mapC.coinc_event_id)
	JOIN sim_inspiral ON (sim_inspiral.simulation_id == mapC.event_id)
	JOIN coinc_event AS sim_coinc_event ON (sim_coinc_event.coinc_event_id == mapC.coinc_event_id)
	JOIN coinc_definer ON (coinc_definer.coinc_def_id == sim_coinc_event.coinc_def_id)
WHERE
	coinc_definer.search == 'inspiral'
	AND coinc_definer.search_coinc_type == 2
	AND mapA.table_name == 'sngl_inspiral'
	AND mapB.table_name == 'coinc_event'
	AND mapC.table_name == 'sim_inspiral'
	AND snglA.ifo == ?
	-- require coinc to not be background (= at least one of its time slide offsets is non-zero)
	-- FIXME this has to call a function to get coinc_def id
	AND NOT EXISTS (
		SELECT
			*
		FROM
			time_slide
		WHERE
			time_slide.time_slide_id == sim_coinc_event.time_slide_id
			AND time_slide.offset != 0
	)
"""

	return query

def double_inj():
	return """
SELECT
	coinc_inspiral.coinc_event_id,
	calc_delta_t_inj(snglA.end_time, snglA.end_time_ns, snglB.end_time, snglB.end_time_ns),
	abs(2*(snglA.mchirp - snglB.mchirp)/(snglA.mchirp+snglB.mchirp)),
	abs(2*(snglA.eta - snglB.eta)/(snglA.eta+snglB.eta)),
	snglA.snr,
	snglB.snr,
	snglA.chisq,
	snglB.chisq,
	snglA.rsqveto_duration,
	snglB.rsqveto_duration,
	snglA.bank_chisq,
	snglB.bank_chisq,
	snglA.cont_chisq,
	snglB.cont_chisq,
	-- Work out the correction factor for injection population distances
	-- FIXME this breaks if more than one inspinj job
	CASE (SELECT value FROM process_params WHERE program =="inspinj" AND param =="--d-distr")
		WHEN "log10" THEN  sim_inspiral.distance * sim_inspiral.distance * sim_inspiral.distance
		WHEN "linear" THEN  sim_inspiral.distance * sim_inspiral.distance
		ELSE 1.0 END
FROM
	coinc_inspiral
	JOIN coinc_event_map AS mapA ON (mapA.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN coinc_event_map AS mapB ON (mapB.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN sngl_inspiral AS snglA ON (snglA.event_id == mapA.event_id)
	JOIN sngl_inspiral AS snglB ON (snglB.event_id == mapB.event_id)
	JOIN coinc_event_map AS mapC ON (mapC.event_id == coinc_inspiral.coinc_event_id)
	JOIN coinc_event_map AS mapD ON (mapD.coinc_event_id == mapC.coinc_event_id)
	JOIN sim_inspiral ON (sim_inspiral.simulation_id == mapD.event_id)
	JOIN coinc_event AS sim_coinc_event ON (sim_coinc_event.coinc_event_id == mapD.coinc_event_id)
	JOIN coinc_event AS insp_coinc_event ON (insp_coinc_event.coinc_event_id == mapA.coinc_event_id)
	JOIN coinc_definer ON (coinc_definer.coinc_def_id == sim_coinc_event.coinc_def_id)
WHERE
	coinc_definer.search == 'inspiral'
	AND coinc_definer.search_coinc_type == 2
	AND mapA.table_name == 'sngl_inspiral'
	AND mapB.table_name == 'sngl_inspiral'
	AND mapC.table_name == 'coinc_event'
	AND mapD.table_name == 'sim_inspiral'
	AND snglA.ifo == ?
	AND snglB.ifo == ?
	-- require coinc to not be background (= at least one of its time slide offsets is non-zero)
	-- FIXME this has to call a function to get coinc_def id
	AND NOT EXISTS (
		SELECT
			*
		FROM
			time_slide
		WHERE
			time_slide.time_slide_id == coinc_event.time_slide_id
			AND time_slide.offset != 0
	)
"""

def single_bkg_minmax(values):
	query = """
SELECT"""
	keys = values.items()
	keys.sort(cmp=lambda x,y: cmp(x[1],y[1]))
	for value in keys:
		if value[0] in ['coinc_event_id', 'filename', 'weight']:
			continue
		if not value == keys[0]:
			query += ""","""
		query += """
	MIN(snglA.""" + value[0] + """),
	MAX(snglA.""" + value[0] + """)"""

	query += """,
	coinc_inspiral.coinc_event_id,
	EXISTS (
		SELECT
			*
		FROM
			time_slide
		WHERE
			time_slide.time_slide_id == coinc_event.time_slide_id
			AND time_slide.offset != 0
	)
FROM
	coinc_inspiral
	JOIN coinc_event_map AS mapA ON (mapA.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN sngl_inspiral AS snglA ON (snglA.event_id == mapA.event_id)
	JOIN coinc_event ON (mapA.coinc_event_id == coinc_event.coinc_event_id)
	JOIN coinc_definer ON (coinc_definer.coinc_def_id == coinc_event.coinc_def_id)
WHERE
	coinc_definer.search == 'inspiral'
	AND coinc_definer.search_coinc_type == 0
	AND mapA.table_name == 'sngl_inspiral'
	AND snglA.ifo == ?
"""

	return query

def single_bkg(values):
	query = """
SELECT"""
	keys = values.items()
	keys.sort(cmp=lambda x,y: cmp(x[1],y[1]))
	for value in keys:
		if value[0] in ['coinc_event_id', 'filename']:
			continue
		if not value == keys[0]:
			query += ""","""
		if value[0] == 'weight':
			query += """
	1.0"""
			continue

		query += """
	snglA.""" + value[0]

	query += """,
	coinc_inspiral.coinc_event_id,
	EXISTS (
		SELECT
			*
		FROM
			time_slide
		WHERE
			time_slide.time_slide_id == coinc_event.time_slide_id
			AND time_slide.offset != 0
	)
FROM
	coinc_inspiral
	JOIN coinc_event_map AS mapA ON (mapA.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN sngl_inspiral AS snglA ON (snglA.event_id == mapA.event_id)
	JOIN coinc_event ON (mapA.coinc_event_id == coinc_event.coinc_event_id)
	JOIN coinc_definer ON (coinc_definer.coinc_def_id == coinc_event.coinc_def_id)
WHERE
	coinc_definer.search == 'inspiral'
	AND coinc_definer.search_coinc_type == 0
	AND mapA.table_name == 'sngl_inspiral'
	AND snglA.ifo == ?
"""

	return query

def double_bkg():
	return """
SELECT
	coinc_inspiral.coinc_event_id,
	calc_delta_t(snglA.ifo, snglA.end_time, snglA.end_time_ns, snglB.ifo, snglB.end_time, snglB.end_time_ns, coinc_event.time_slide_id),
	abs(2*(snglA.mchirp - snglB.mchirp)/(snglA.mchirp+snglB.mchirp)),
	abs(2*(snglA.eta - snglB.eta)/(snglA.eta+snglB.eta)),
	snglA.snr,
	snglB.snr,
	snglA.chisq,
	snglB.chisq,
	snglA.rsqveto_duration,
	snglB.rsqveto_duration,
	snglA.bank_chisq,
	snglB.bank_chisq,
	snglA.cont_chisq,
	snglB.cont_chisq,
	EXISTS (
		SELECT
			*
		FROM
			time_slide
		WHERE
			time_slide.time_slide_id == coinc_event.time_slide_id
			AND time_slide.offset != 0
	)
FROM
	coinc_inspiral
	JOIN coinc_event_map AS mapA ON (mapA.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN coinc_event_map AS mapB ON (mapB.coinc_event_id == coinc_inspiral.coinc_event_id)
	JOIN sngl_inspiral AS snglA ON (snglA.event_id == mapA.event_id)
	JOIN sngl_inspiral AS snglB ON (snglB.event_id == mapB.event_id)
	JOIN coinc_event ON (mapA.coinc_event_id == coinc_event.coinc_event_id)
	JOIN coinc_definer ON (coinc_definer.coinc_def_id == coinc_event.coinc_def_id)
WHERE
	coinc_definer.search == 'inspiral'
	AND coinc_definer.search_coinc_type == 0
	AND mapA.table_name == 'sngl_inspiral'
	AND mapB.table_name == 'sngl_inspiral'
	AND snglA.ifo == ?
	AND snglB.ifo == ?
"""

#
# =============================================================================
#
#				     Main
#
# =============================================================================
#


#
# command line
#


options, filenames = parse_command_line()


#
# initialize book-keeping
#


likelihood_bins = Summaries(200)


#
# iterate over database files accumulating statistics
#

if options.verbose:
	print >>sys.stderr, "collecting minmax statistics ..."

for n, filename in enumerate(filenames):
	#
	# open the database
	#

	if options.verbose:
		print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
	working_filename = dbtables.get_connection_filename(filename, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)

	if options.verbose:
		print >>sys.stderr, "\textracting all ifos ..."
	# FIXME get ifos from search summary table
	likelihood_bins.ifos |= set(ifo for ifo, in connection.cursor().execute("""SELECT DISTINCT ifo FROM sngl_inspiral"""))

	if options.verbose:
		print >>sys.stderr, "\textracting likelihood from all coinc_events ..."
	for coinc_event_id, likelihood in connection.cursor().execute("""
SELECT
	coinc_event.coinc_event_id,
	coinc_event.likelihood
FROM
	coinc_event
	"""):
		likelihood_bins.likelihoods.setdefault((filename, coinc_event_id), likelihood)

	#
	# extract triggers using appropriate sqlite queries determined
	# by the existence of a sim_inspiral table in the database
	#

	if "sim_inspiral" in dbtables.get_table_names(connection):
		#
		# loop over all single ifos and add sngls to appropriate list
		#

		if options.verbose:
			print >>sys.stderr, "\textracting all sngls ..."
		for ifo in likelihood_bins.ifos:
			if options.verbose:
				print >>sys.stderr, "\t\t%s ..." % (ifo,)
			for values in connection.cursor().execute(single_inj_minmax(likelihood_bins.idx_sngls), (ifo,)):
				likelihood_bins.add_sngl_minmax(ifo, values)

		#
		# loop over all double combinations of ifos and add dbls to appropriate list
		#

#		if options.verbose:
#			print >>sys.stderr, "\textracting all dbls ..."
#		connection.create_function("calc_delta_t_inj", 4, likelihood_bins.calc_delta_t_inj)
#		for ifos in list(iterutils.choices(likelihood_bins.ifos, 2)):
#			if options.verbose:
#				print >>sys.stderr, "\t\t%s ..." % ("".join(ifos))
#			for values in connection.cursor().execute(double_inj, ifos):
#				likelihood_bins.add_inj_dbl(filename, ifos, values)
	else:
		#
		# loop over all single ifos and add sngls to appropriate list
		#

		if options.verbose:
			print >>sys.stderr, "\textracting all sngls ..."
		for ifo in likelihood_bins.ifos:
			if options.verbose:
				print >>sys.stderr, "\t\t%s ..." % (ifo,)
			for values in connection.cursor().execute(single_bkg_minmax(likelihood_bins.idx_sngls), (ifo,)):
					likelihood_bins.add_sngl_minmax(ifo, values)

		#
		# loop over all double combinations of ifos and add dbls to appropriate list
		#

#		if options.verbose:
#			print >>sys.stderr, "\textracting all dbls ..."
#		likelihood_bins.rings = db_thinca_rings.get_thinca_rings_by_available_instruments(connection)
#		likelihood_bins.offset_vectors = dbtables.lsctables.table.get_table(dbtables.get_xml(connection), dbtables.lsctables.TimeSlideTable.tableName).as_dict()
#		connection.create_function("calc_delta_t", 7, likelihood_bins.calc_delta_t)
#		for ifos in list(iterutils.choices(likelihood_bins.ifos, 2)):
#			if options.verbose:
#				print >>sys.stderr, "\t\t%s ..." % ("".join(ifos))
#			for values in connection.cursor().execute(double_bkg, ifos):
#				if values[-1]:
#					background.add_bkg_dbl(filename, ifos, values[0:-1])
#				else:
#					background.add_zero_lag_dbl(filename, ifos, values[0:-1])

	#
	# done extracting info so close database
	#

	connection.close()
	dbtables.discard_connection_filename(filename, working_filename, verbose = options.verbose)

#
# end loop over input database files
#

if options.verbose:
	print >>sys.stderr, "initializing likelihoods to 1.0  ..."
for key in likelihood_bins.likelihoods.keys():
	likelihood_bins.likelihoods[key] = 1.0

if options.verbose:
	print >>sys.stderr, "setting up binned ratio objects ..."
likelihood_bins.setup_binned_ratios()

if options.verbose:
	print >>sys.stderr, "extracting background and injection statistics ..."
for n, filename in enumerate(filenames):
	#
	# open the database
	#

	if options.verbose:
		print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
	working_filename = dbtables.get_connection_filename(filename, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)

	#
	# extract triggers using appropriate sqlite queries determined
	# by the existence of a sim_inspiral table in the database
	#

	if "sim_inspiral" in dbtables.get_table_names(connection):
		#
		# loop over all single ifos and add sngls to appropriate list
		#

		if options.verbose:
			print >>sys.stderr, "\textracting all sngls to populate binned ratio numerator ..."
		for ifo in likelihood_bins.ifos:
			if options.verbose:
				print >>sys.stderr, "\t\t%s ..." % (ifo,)
			for values in connection.cursor().execute(single_inj(likelihood_bins.idx_sngls), (ifo,)):
				likelihood_bins.add_inj_sngl(ifo, values)

		#
		# loop over all double combinations of ifos and add dbls to appropriate list
		#

#		if options.verbose:
#			print >>sys.stderr, "\textracting all dbls ..."
#		connection.create_function("calc_delta_t_inj", 4, likelihood_bins.calc_delta_t_inj)
#		for ifos in list(iterutils.choices(likelihood_bins.ifos, 2)):
#			if options.verbose:
#				print >>sys.stderr, "\t\t%s ..." % ("".join(ifos))
#			for values in connection.cursor().execute(double_inj, ifos):
#				likelihood_bins.add_inj_dbl(filename, ifos, values)
	else:
		#
		# loop over all single ifos and add sngls to appropriate list
		#

		if options.verbose:
			print >>sys.stderr, "\textracting all sngls to populate binned ratio denominator ..."
		for ifo in likelihood_bins.ifos:
			if options.verbose:
				print >>sys.stderr, "\t\t%s ..." % (ifo,)
			for values in connection.cursor().execute(single_bkg(likelihood_bins.idx_sngls), (ifo,)):
				if values[-1]:
					likelihood_bins.add_bkg_sngl(ifo, values)

		#
		# loop over all double combinations of ifos and add dbls to appropriate list
		#

#		if options.verbose:
#			print >>sys.stderr, "\textracting all dbls ..."
#		likelihood_bins.rings = db_thinca_rings.get_thinca_rings_by_available_instruments(connection)
#		likelihood_bins.offset_vectors = dbtables.lsctables.table.get_table(dbtables.get_xml(connection), dbtables.lsctables.TimeSlideTable.tableName).as_dict()
#		connection.create_function("calc_delta_t", 7, likelihood_bins.calc_delta_t)
#		for ifos in list(iterutils.choices(likelihood_bins.ifos, 2)):
#			if options.verbose:
#				print >>sys.stderr, "\t\t%s ..." % ("".join(ifos))
#			for values in connection.cursor().execute(double_bkg, ifos):
#				if values[-1]:
#					background.add_bkg_dbl(filename, ifos, values[0:-1])
#				else:
#					background.add_zero_lag_dbl(filename, ifos, values[0:-1])

	#
	# done extracting info so close database
	#

	connection.close()
	dbtables.discard_connection_filename(filename, working_filename, verbose = options.verbose)

#
# end loop over input database files
#

if options.verbose:
	print >>sys.stderr, "smoothing binned ratios ..."
likelihood_bins.filter_binned_ratios()

if options.verbose:
	print >>sys.stderr, "computing likelihoods ..."
for n, filename in enumerate(filenames):
	#
	# open the database
	#

	if options.verbose:
		print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
	working_filename = dbtables.get_connection_filename(filename, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)

	#
	# extract triggers using appropriate sqlite queries determined
	# by the existence of a sim_inspiral table in the database
	#

	if "sim_inspiral" in dbtables.get_table_names(connection):
		#
		# loop over all single ifos and add sngls to appropriate list
		#

		if options.verbose:
			print >>sys.stderr, "\textracting all sngls for likelihood computation..."
		for ifo in likelihood_bins.ifos:
			if options.verbose:
				print >>sys.stderr, "\t\t%s ..." % (ifo,)
			for values in connection.cursor().execute(single_inj(likelihood_bins.idx_sngls), (ifo,)):
				likelihood_bins.compute_sngl_likelihood(ifo, tuple(list(values) + [filename]))

		#
		# loop over all double combinations of ifos and add dbls to appropriate list
		#

#		if options.verbose:
#			print >>sys.stderr, "\textracting all dbls ..."
#		connection.create_function("calc_delta_t_inj", 4, likelihood_bins.calc_delta_t_inj)
#		for ifos in list(iterutils.choices(likelihood_bins.ifos, 2)):
#			if options.verbose:
#				print >>sys.stderr, "\t\t%s ..." % ("".join(ifos))
#			for values in connection.cursor().execute(double_inj, ifos):
#				likelihood_bins.add_inj_dbl(filename, ifos, values)
	else:
		# 
		# loop over all single ifos and add sngls to appropriate list 
		#

		if options.verbose:
			print >>sys.stderr, "\textracting all sngls for likelihood computation ..."
		for ifo in likelihood_bins.ifos:
			if options.verbose:
				print >>sys.stderr, "\t\t%s ..." % (ifo,)
			for values in connection.cursor().execute(single_bkg(likelihood_bins.idx_sngls), (ifo,)):
				likelihood_bins.compute_sngl_likelihood(ifo, tuple(list(values[0:-1]) + [filename]))
 
		# 
		# loop over all double combinations of ifos and add dbls to appropriate list 
		#

#		if options.verbose:
#			print >>sys.stderr, "\textracting all dbls ..."
#		likelihood_bins.rings = db_thinca_rings.get_thinca_rings_by_available_instruments(connection)
#		likelihood_bins.offset_vectors = dbtables.lsctables.table.get_table(dbtables.get_xml(connection), dbtables.lsctables.TimeSlideTable.tableName).as_dict()
#		connection.create_function("calc_delta_t", 7, likelihood_bins.calc_delta_t)
#		for ifos in list(iterutils.choices(likelihood_bins.ifos, 2)):
#			if options.verbose:
#				print >>sys.stderr, "\t\t%s ..." % ("".join(ifos))
#			for values in connection.cursor().execute(double_bkg, ifos):
#				if values[-1]:
#					background.add_bkg_dbl(filename, ifos, values[0:-1])
#				else:
#					background.add_zero_lag_dbl(filename, ifos, values[0:-1])

	#
	# done extracting info so close database
	#

	connection.close()
	dbtables.discard_connection_filename(filename, working_filename, verbose = options.verbose)

#
# end loop over input database files
#

#
# iterate over database files assigning likelihoods to coincs
#

if options.verbose:
	print >>sys.stderr, "updating likelihoods in databases ..."
for n, filename in enumerate(filenames):
	#
	# open the database
	#

	if options.verbose:
		print >>sys.stderr, "%d/%d: %s" % (n + 1, len(filenames), filename)
	working_filename = dbtables.get_connection_filename(filename, tmp_path = options.tmp_space, verbose = options.verbose)
	connection = sqlite3.connect(working_filename)

	#
	# prepare the database
	#

	connection.create_function("likelihood_map", 2, likelihood_bins.likelihood_map)
	if options.verbose:
		print >>sys.stderr, "\trecording likelihood ..."
	connection.cursor().execute("""
UPDATE
	coinc_event
SET
	likelihood = likelihood_map(
			?,
			coinc_event.coinc_event_id
	)
	""", (filename,))
	connection.commit()

	#
	# close the database
	#

	connection.close()
	dbtables.put_connection_filename(filename, working_filename, verbose = options.verbose)

#!/usr/bin/python
#
# $Id$
#
# Copyright (C) 2006  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#

"""
Build a LAL cache from a list of LIGO LW XML files containing search
summary tables.
"""

__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]

import glob
from optparse import OptionParser
import os
import sys
# Python 2.3 compatibility
try:
	set
except NameError:
	from sets import Set as set

from glue.lal import CacheEntry
from glue import segments
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import utils

#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#

def parse_command_line():
	parser = OptionParser(version = "%prog CVS $Id$")
	parser.add_option("--description", metavar = "DESCRIPTION", help = "set all descriptions to DESCRIPTION")
	parser.add_option("--observatory", metavar = "OBSERVATORY", help = "set all observatories to OBSERVATORY")
	parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
	parser.add_option("-o", "--output", metavar = "filename", help = "set output file (default = stdout)")
	parser.add_option("-p", "--program", metavar = "name", help = "obtain start and durations from search summary entries corresponding to the given program (default = whatever is there)")
	options, patterns = parser.parse_args()

	if options.output:
		options.output = file(options.output, "w")
	else:
		options.output = sys.stdout

	return options, patterns

options, patterns = parse_command_line()


#
# =============================================================================
#
#                                    Input
#
# =============================================================================
#

def element_filter(name, attrs):
	"""
	Return True if name & attrs describe a search summary table or a
	process table.
	"""
	return lsctables.IsTableProperties(lsctables.SearchSummaryTable, name, attrs) or lsctables.IsTableProperties(lsctables.ProcessTable, name, attrs)

class ContentHandler(ligolw.PartialLIGOLWContentHandler):
	def __init__(self, doc):
		ligolw.PartialLIGOLWContentHandler.__init__(self, doc, element_filter)

utils.ContentHandler = ContentHandler


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


def column_value(search_summary_table, column, process_ids = None):
	"""
	Scan a column in a table element, checking that all rows have the
	same value, and return that value.
	"""
	if process_ids is None:
		vals = search_summary_table.getColumnByName(column)
	else:
		vals = [getattr(row, column) for row in search_summary_table if row.process_id in process_ids]
	value = vals[0]
	for v in vals:
		if v != value:
			raise ValueError, "%s: not all search_summary rows have the same value for \"%s\"" % column
	return value


for pattern in patterns:
	for filename in glob.glob(pattern):
		# load document and extract search summary table
		doc = utils.load_filename(filename, options.verbose, gz = filename.endswith(".gz"))
		searchsumm = table.get_table(doc, lsctables.SearchSummaryTable.tableName)

		# extract process_ids for the requested program
		if options.program:
			process_ids = table.get_table(doc, lsctables.ProcessTable.tableName).get_ids_by_program(options.program)
		else:
			process_ids = None

		# extract segment lists
		seglists = searchsumm.get_out_segmentlistdict(process_ids)

		# extract observatory
		if options.observatory:
			observatory = options.observatory
		else:
			observatory = seglists.keys()
			observatory.sort()
			observatory = "+".join(observatory)
			if not observatory:
				raise ValueError, "%s: observatory column is empty" % filename

		# extract description
		if options.description:
			description = options.description
		else:
			try:
				description = column_value(searchsumm, "comment", process_ids).strip()
				if not description:
					raise ValueError, "description column is empty"
			except ValueError, e:
				raise ValueError, "%s: %s" % (filename, str(e))

		# set URL
		url = "file://localhost" + os.path.abspath(filename)

		# write cache entry
		print >>options.output, str(CacheEntry(observatory, description, seglists.extent_all(), url))

		# allow garbage collection
		doc.unlink()

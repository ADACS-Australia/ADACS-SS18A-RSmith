#!/usr/bin/python

"""
Build a LAL cache from a list of LIGO LW XML files containing search
summary tables.
"""

__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__date__ = "$Date$"
__version__ = "$Revision$"


#
# Preamble.
#

import glob
from optparse import OptionParser
import os
import sys
from xml import sax

from glue import lal
from glue import segments
from glue.ligolw import docutils
from glue.ligolw import ligolw
from glue.ligolw import lsctables
from glue.ligolw import metaio


#
# Filter function for partial LIGO LW document loading.
#

def SearchSummaryFilter(name, attrs):
	if name != ligolw.Table.tagName:
		return False
	return attrs["Name"] == lsctables.SearchSummaryTable.tableName


#
# Parse command line.
#

parser = OptionParser(version = "%prog CVS $Id$")
parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
parser.add_option("-o", "--output", metavar = "FILENAME", help = "write output to FILENAME (default = stdout")
options, patterns = parser.parse_args()
del parser

if options.output:
	output = file(options.output)
else:
	output = sys.stdout


#
# Process files one-by-one.
#

def all_identical(table, column):
	vals = [getattr(row, column) for row in table.rows]
	for i in range(1, len(vals)):
		if vals[i] != vals[0]:
			raise Exception, "not all identical"
	return vals[0]


cwd = os.getcwd()


for pattern in patterns:
	for name in glob.glob(pattern):
		# Load and merge search summary tables
		doc = ligolw.Document()
		handler = docutils.PartialLIGOLWContentHandler(doc, SearchSummaryFilter)
		sax.parse(file(name), handler)
		docutils.MergeCompatibleTables(doc)
		if len(doc.childNodes) != 1:
			raise Exception, "Missing or incompatible search summary tables in document %s" % name

		# initialize cache entry info
		cache = lal.CacheEntry()

		# extract segment
		cache.segment = doc.childNodes[0].get_outlist().extent()

		# extract observatory
		try:
			cache.observatory = all_identical(doc.childNodes[0], "ifos")
		except:
			raise Exception, "Not all search summary entries list the same ifo(s) in %s" % name

		# extract description
		try:
			cache.description = all_identical(doc.childNodes[0], "comment")
		except:
			raise Exception, "Not all search summary entries list the same comment in %s" % name

		# set URL
		cache.url = "file://localhost" + cwd.strip() + "/" + name.strip()

		# write cache entry
		print >>output, str(cache)

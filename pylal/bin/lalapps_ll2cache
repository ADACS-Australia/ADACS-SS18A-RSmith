#!/usr/bin/python
#
# $Id$
#
# Copyright (C) 2006  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#

"""
Build a LAL cache from a list of LIGO LW XML files containing search
summary tables.
"""

__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__version__ = "$Revision$"[11:-2]
__date__ = "$Date$"[7:-2]

import glob
from optparse import OptionParser
import os
import sys

from glue.lal import CacheEntry
from glue import segments
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from pylal import llwapp

#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#

def parse_command_line():
	parser = OptionParser(version = "%prog CVS $Id$")
	parser.add_option("--description", metavar = "DESCRIPTION", help = "set all descriptions to DESCRIPTION")
	parser.add_option("--observatory", metavar = "OBSERVATORY", help = "set all observatories to OBSERVATORY")
	parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
	parser.add_option("-o", "--output", metavar = "filename", help = "set output file (default = stdout)")
	parser.add_option("-p", "--program", metavar = "name", help = "obtain start and durations from search summary entries corresponding to the given program (default = whatever is there)")
	options, patterns = parser.parse_args()

	if options.output:
		options.output = file(options.output, "w")
	else:
		options.output = sys.stdout

	return options, patterns

options, patterns = parse_command_line()


#
# =============================================================================
#
#                                    Input
#
# =============================================================================
#

def element_filter(name, attrs):
	"""
	Return True if name & attrs describe a search summary table or a
	process table.
	"""
	return lsctables.IsTableProperties(lsctables.SearchSummaryTable, name, attrs) or lsctables.IsTableProperties(lsctables.ProcessTable, name, attrs)

class ContentHandler(ligolw.PartialLIGOLWContentHandler):
	def __init__(self, doc):
		ligolw.PartialLIGOLWContentHandler.__init__(self, doc, element_filter)

llwapp.ContentHandler = ContentHandler


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#

def column_value(table, column):
	"""
	Scan a column in a table element, checking that all rows have the
	same value, and return that value.
	"""
	if options.program:
		vals = [getattr(row, column) for row in table if row.process_id.program == options.program]
	else:
		vals = table.getColumnByName(column)
	value = vals[0]
	for v in vals:
		if v != value:
			raise ValueError, "%s: not all rows have the same value for \"%s\"" % (table.tableName, column)
	return value


for pattern in patterns:
	for filename in glob.glob(pattern):
		# load document and extract search summary table
		doc = llwapp.load_filename(filename, options.verbose, gz = filename[-3:] == ".gz")
		lsctables.makeReference(doc)
		searchsumm = table.get_table(doc, lsctables.SearchSummaryTable.tableName)

		# extract observatory
		if options.observatory:
			observatory = options.observatory
		else:
			try:
				observatory = column_value(searchsumm, "ifos").strip()
				if not observatory:
					raise ValueError, "observatory column is empty"
			except ValueError, e:
				raise ValueError, "%s: %s" % (filename, str(e))

		# extract description
		if options.description:
			description = options.description
		else:
			try:
				description = column_value(searchsumm, "comment").strip()
				if not description:
					raise ValueError, "description column is empty"
			except ValueError, e:
				raise ValueError, "%s: %s" % (filename, str(e))

		# extract segment
		if options.program:
			segment = segments.segmentlist([row.get_out() for row in searchsumm if row.process_id.program == options.program]).extent()
		else:
			segment = searchsumm.get_outlist().extent()

		# set URL
		url = "file://localhost" + os.path.abspath(filename)

		# write cache entry
		print >>options.output, str(CacheEntry(observatory, description, segment, url))

		# allow garbage collection
		doc.unlink()

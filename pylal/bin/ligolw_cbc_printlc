#!/usr/bin/env python

#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


usage = \
'''
Prints the largest triggers in either foreground or background along with
relevant statistics and parameters to stdout.
'''

from optparse import OptionParser
try:
    import sqlite3
except ImportError:
    # pre 2.5.x
    from pysqlite2 import dbapi2 as sqlite3
import sys
import os

from glue.ligolw import lsctables
from glue.ligolw import dbtables
from glue.ligolw.utils.ligolw_sqlite import extract

from pylal import ligolw_sqlutils as sqlutils

__prog__ = "ligolw_cbc_printlc"
__author__ = "Collin Capano <cdcapano@physics.syr.edu>"
__date__ = "$Date$" 
__version__ = "$Revision$"

# =============================================================================
#
#                                   Set Options
#
# =============================================================================


def parse_command_line():
    """
    Parse the command line, return options and check for consistency among the
    options.
    """
    parser = OptionParser( version = "", usage = usage )

    # following are related to file input and output naming
    parser.add_option( "-i", "--input", action = "store", type = "string",
        default = None,                  
        help = 
            "Input database to read. Can only input one at a time." 
            )
    parser.add_option("-o", "--output", action = "store", type = "string",
        default = None,
        help =
            "Save summary table to file. If no output specified, result " +
            "will be printed to stdout."
            )
    parser.add_option( "-t", "--tmp-space", action = "store", type = "string",
        default = None, metavar = "path",
        help = 
            "Location of local disk on which to do work. " +
            "This is used to enhance performance in a networked " +
            "environment and is needed if extracting an xml file."
            )
    parser.add_option("-f", "--output-format", action = "store", type = "string",
        default = "wiki", metavar = "wiki, html, OR xml",
        help =
            "Format of output summary table. Choices are 'wiki', 'html', or 'xml'. " +
            "Default is wiki."
            )
    parser.add_option("-x", "--extract-to-xml", action = "store", type = "string",
        default = None, metavar = "filename",
        help =
            "Will extract a full xml file from the database containing only the " +
            "triggers that are printed. Requries --tmp-space. "
            )
    parser.add_option( "-v", "--verbose", action = "store_true", default = False,
        help = 
            "Print the SQLite query that is used to stdout." 
            )
    # following are generic inspiral_sql options
    parser.add_option( "", "--param-name", metavar = "PARAMETER",
        action = "store", default = None,
        help = 
            "Can be any parameter in the coinc_inspiral table. " +
            "Specifying this and param-ranges will only select " +
            "triggers that fall within the parameter ranges. " 
            )
    parser.add_option( "", "--param-ranges", action = "store", default = None,
        metavar = " [ LOW1, HIGH1 ); ( LOW2, HIGH2]; etc.",
        help = 
            "Requires --param-name. Specify the parameter ranges " +
            "to select triggers in. A '(' or ')' implies an open " +
            "boundary, a '[' or ']' a closed boundary. To specify " +
            "multiple ranges, separate each range by a ';'. If " +
            "multiple ranges are specified, the triggers picked for " +
            "ranking will come from the union of the ranges."
            )
    parser.add_option( "", "--exclude-coincs", action = "store", type = "string", default = None,
        metavar = " [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];"
            "[ALL in INSTRUMENTS_ON2]; etc.",
        help = 
            "Exclude coincident types in specified detector times, " +
            "e.g., '[H2,L1 in H1,H2,L1]'. Some rules: " +
                "* Coinc-types and detector time must be separated by " +
                "an ' in '. When specifying a coinc_type or detector " +
                "time, detectors and/or ifos must be separated by " +
                "commas, e.g. 'H1,L1' not 'H1L1'. " +
                "* To specify multiple coinc-types in one type of time, " +
                "separate each coinc-type by a '+', e.g., " +
                "'[H1,H2 + H2,L1 in H1,H2,L1]'. " +
                "* To exclude all coincs in a specified detector time " +
                "or specific coinc-type in all times, use 'ALL'. E.g., " +
                "to exclude all H1,H2 triggers, use '[H1,H2 in ALL]' " +
                "or to exclude all H2,L1 time use '[ALL in H2,L1]'. " + 
                "* To specify multiple exclusions, separate each " +
                "bracket by a ';'. " +
                "* Order of the instruments nor case of the letters " +
                "matter. So if your pinky is broken and you're " +
                "dyslexic you can type '[h2,h1 in all]' without a " +
                "problem." 
            )
    parser.add_option( "", "--include-only-coincs", action = "store", type = "string", default = None,
        metavar = " [COINC_INSTRUMENTS1 + COINC_INSTRUMENTS2 in INSTRUMENTS_ON1];" +
            "[ALL in INSTRUMENTS_ON2]; etc.",
        help =
            "Opposite of --exclude-coincs: only rank the specified coinc types. "
            )
    # following are options specific to this program
    parser.add_option("", "--datatype", action = "store", type = "string", default = None,
        metavar = "slide, all_data, playground, exclude_play, OR simulation",
        help =
            "Required. Specify what datatype to print triggers from. "
            )
    parser.add_option( "", "--ranking-stat", action = "store", type = "string", default = None,
        help =
            "Requried. Statistic to rank by (can be any column " +
            "in the coinc_inspiral table)." 
            )
    parser.add_option( "", "--rank-by", action = "store", type = "string", default = None, 
        metavar = "MAX or MIN",
        help = 
            "Requried. Options are MAX or MIN. " +
            "This specifies whether to rank triggers by maximum or " +
            "minimum stat value." 
            )
    parser.add_option( "", "--limit", action = "store", type = "int", default = 10,
        help =
            "Specify how many triggers to print. Default is 10. "
            )
    parser.add_option( "", "--convert-durations", action = "store", type = "string", default = "s",
        metavar = "s, min, hr, d, OR yr",
        help =
            "Convert the duration from seconds to a different unit of time. Options are: " +
            "s (seconds), min (minutes), hr (hours), d (days), or yr (years). " +
            "(Setting to s is the equivalent of a no-op.)"
            )

    (options, args) = parser.parse_args()

    # check for required options and for self-consistency
    if not options.input:
        raise ValueError, "No input specified."
    if options.extract_to_xml and not options.tmp_space:
        raise ValueError, "extract-to-xml requires tmp-space"
    if not options.ranking_stat:
        raise ValueError, "No ranking stat specified."
    if not (options.rank_by.strip().upper() == 'MIN' or options.rank_by.strip().upper() == 'MAX'):
        raise ValueError, "--rank-by must be specified and set to either MIN or MAX."
    if not options.datatype:
        raise ValueError, "--datatype must be specified."
    if options.datatype.strip().lower() not in lsctables.ExperimentSummaryTable.datatypes:
        raise ValueError, "Unrecognized datatype %s. See help for options." % options.datatype
    if not (options.convert_durations.strip().lower() == "s" or options.convert_durations.strip().lower() == "min" or 
        options.convert_durations.strip().lower() == "hr" or options.convert_durations.strip().lower() == "d" or
        options.convert_durations.strip().lower() == "yr"):
        raise ValueError, "--convert-duration must be either s, min, hr, d, or yr"


    return options, sys.argv[1:]

# =============================================================================
#
#                                     Main
#
# =============================================================================

opts, args = parse_command_line()

# get input database filename
filename = opts.input
if not os.path.isfile( filename ):
    raise ValueError, "The input file, %s, cannot be found." % filename

# Setup working databases and connections
if opts.verbose and opts.tmp_space: 
    print >> sys.stdout, "Setting up temp. database..."
working_filename = dbtables.get_connection_filename( 
    filename, tmp_path = opts.tmp_space, verbose = opts.verbose )
connection = sqlite3.connect( working_filename )
dbtables.DBTable_set_connection( connection )

# Get ranking stat and append coinc_inspiral table name
if " " in opts.ranking_stat.strip():
  raise ValueError, "ranking-stat must not contain spaces"
ranking_stat =  '.'.join([ 'coinc_inspiral', opts.ranking_stat.strip() ])

# Get rank_by
if opts.rank_by.strip().upper() == "MIN":
  rank_by = 'ASC'
else:
  rank_by = 'DESC'

#
#
#   Set filter
#

# Set datatype
in_this_filter = ''.join([ 'experiment_summary.datatype == "', opts.datatype.strip().lower(), '"' ])

# Get param and param-ranges if specified
if opts.param_name:
    param_filters = sqlutils.parse_param_ranges( 'coinc_inspiral', opts.param_name, 
        opts.param_ranges, verbose = opts.verbose ).get_param_filters()
    # since want triggers that fall within all the parameters, concatenate
    # all param ranges
    param_filters = '\n\t\tOR '.join( param_filters )
    in_this_filter = ''.join([ in_this_filter, '\n\tAND (\n\t\t', param_filters, '\n\t)' ])

# Get exclude_coincs list if specified
if opts.exclude_coincs:
    exclude_coinc_filters = sqlutils.parse_coinc_options( opts.exclude_coincs, 
        verbose = opts.verbose ).get_coinc_filters()
    # concatenate exclude_coinc_filters
    exclude_coinc_filters = '\n\t\tOR '.join( exclude_coinc_filters )
    # add to in_this_filter
    in_this_filter = ''.join([ in_this_filter, '\n\tAND NOT (\n\t\t', exclude_coinc_filters, '\n\t)' ]) 

# Get include_only_coincs list if specified
if opts.include_only_coincs:
    include_coinc_filters = sqlutils.parse_coinc_options( opts.include_only_coincs, 
        verbose = opts.verbose ).get_coinc_filters()
    # concatenate include_coinc_filters
    include_coinc_filters = '\n\t\tOR '.join( include_coinc_filters )
    # add to in_this_filter
    in_this_filter = ''.join([ in_this_filter, '\n\tAND (\n\t\t', include_coinc_filters, '\n\t)' ])

# establish what units will be converting duration to; this has to be done
# by defining a function which calls sqlutils.convert_duration with the desired
# conversion. This function is then sqlitized so that it just takes one argument,
# the duration, and automatically converts. We do this because we cannot set the
# appropiate conversion flag from within the sql statement

def convert_duration( duration ):
    return sqlutils.convert_duration( duration, opts.convert_durations.strip().lower() )
connection.create_function( 'convert_duration', 1, convert_duration )
    
# Set up sqlquery
sqlquery = ''.join([ """
    SELECT
        experiment.instruments,
        convert_duration(experiment_summary.duration),
        coinc_inspiral.*
    FROM
        coinc_inspiral
    JOIN
        experiment, experiment_summary, experiment_map 
    ON ( 
        experiment.experiment_id == experiment_summary.experiment_id
        AND experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
        AND experiment_map.coinc_event_id == coinc_inspiral.coinc_event_id )
    WHERE 
        """, in_this_filter, """
    ORDER BY
        """, ranking_stat, ' ',  rank_by, """
    LIMIT """, str(opts.limit) ])

if opts.verbose:
    print >> sys.stdout, "Sqlite query is:"
    print >> sys.stdout, sqlquery
    if not opts.output:
        print >> sys.stdout, "\nResults are:\n"

info = connection.cursor().execute( sqlquery ).fetchall()

# Get column-names: the first two columns are the instruments_on (from the experiment table), and the duration
# (with the datatype and time-unit in the column name) followed by all the columns in the coinc_inspiral table
durname = ''.join([ opts.datatype.strip().lower(), u'_duration_', opts.convert_durations.strip().lower(), '' ])
column_names = [ u'instruments_on', durname ]
# Get list of column names from coinc_inspiral table
column_names.extend(sqlutils.get_column_names_from_table( connection, 'coinc_inspiral' ))

#
# Prepare for printing summary info to output
#

# set output
if opts.output and opts.output_format != 'xml':
    output = open(opts.output, 'w')
else:
    output = sys.stdout

# set output-format
if opts.output_format == 'wiki':
    tx = ''
    xt = ''
    rx = '||'
    xr = '||'
    xccx = '||'

elif opts.output_format == "html":
    tx = '<table border = "1">'
    xt = '</table>'
    rx = '<tr><td>'
    xr = '</td></tr>'
    xccx = '</td><td>'

elif opts.output_format == "xml":
    # get needed imports
    from glue.ligolw import ligolw
    from glue.ligolw import table
    from glue.ligolw import utils
    from glue.ligolw.utils import ligolw_add
    from glue.ligolw.utils import process

    # Define the table
    class LoudestEventsTable(table.Table):
        tableName = "loudest_events:table"
        # as we don't know apriori what the column types are, just set everything to lstring
        validcolumns = dict([ [col_name, "lstring"] for col_name in column_names ])

    # Define the row
    class LoudestEvents(object):
        __slots__ = LoudestEventsTable.validcolumns.keys()
    
        def get_pyvalue(self):
            if self.value is None:
                return None
            return ligolwtypes.ToPyType[self.type or "lstring"](self.value)

    # connect the row to the table
    LoudestEventsTable.RowType = LoudestEvents

    # Create a document
    lcdoc = ligolw.Document()
    # setup the LIGOLW tag
    lcdoc.appendChild(ligolw.LIGO_LW())
    # add this programs metadata
    lcproc_id = process.register_to_xmldoc(lcdoc, __prog__, opts.__dict__)
    # add the table
    lctable = lsctables.New(LoudestEventsTable)
    # connect the table to the document
    lcdoc.childNodes[0].appendChild(lctable)

    
else:
    raise ValueError, 'unrecognized output-format; must be either wiki, html, or xml'
    
#
# Print the summary data
#
if opts.output_format != "xml":
    header = ''.join([ tx, rx, xccx.join( column_names  ), xr ])
    print >> output, header
    for row in info:
        row = xccx.join(str(data) for data in row)
        print >> output, "%s%s%s" % (rx, row, xr)
    # close the table
    print >> output, xt
    if output != sys.stdout:
        output.close()

else:
    for row in info:
        lcrow = LoudestEvents()
        for column, data in zip(column_names, row):
            setattr(lcrow, column, data)
        # add the row to the table
        lctable.append(lcrow)
    # write to opts.output (if opts.output is None, will write to sys.stdout)
    utils.write_filename(lcdoc, opts.output)

#
# If extract-to-xml, generate the full xml
#

if opts.extract_to_xml:
    if opts.verbose:
        print >> sys.stdout, "\nPreparing temp. database for xml extraction..."
        print >> sys.stdout, "Deleting unwanted triggers from coinc_inspiral table..."
    # use the coinc_event_ids to figure out what to keep
    ceid_index_num = coinc_inspiral_cols.index("coinc_event_id") + 2
    save_ids = [''.join(['"', row[ceid_index_num], '"']) for row in info]
    # delete all other ids from the coinc_inspiral table
    sqlquery = ''.join([ """
        DELETE
        FROM 
            coinc_inspiral
        WHERE
            coinc_event_id NOT IN (
            """, ','.join(save_ids), """
            )""" ])
    connection.cursor().execute(sqlquery)

    # clean up the other tables that point to the deleted ids
    sqlutils.clean_inspiral_tables(connection, verbose = opts.verbose)

    # also remove experiments that don't have loud events in them
    if opts.verbose:
        print >> sys.stdout, "Removing experiments that no longer have events in them..."

    sqlscript = """
        DELETE FROM
            experiment
        WHERE
            experiment_id NOT IN (
                SELECT DISTINCT
                    experiment_summary.experiment_id
                FROM
                    experiment_summary, experiment_map
                WHERE
                    experiment_summary.experiment_summ_id == experiment_map.experiment_summ_id
                );
        DELETE FROM
            experiment_summary
        WHERE
            experiment_id NOT IN (
                SELECT
                    experiment_id
                FROM
                    experiment
                );
        DELETE FROM
            time_slide
        WHERE
            time_slide_id NOT IN (
                SELECT DISTINCT
                    time_slide_id
                FROM
                    experiment_summary
                );
        """
    connection.cursor().executescript(sqlscript)

    # remove additional meta-data from other tables who's process_ids are not in
    # the experiment or coinc. tables
    if opts.verbose:
        print >> sys.stdout, "Removing unneeded metadata..."

    sqlscript = """
        -- create a temp. table of process_ids to keep
        CREATE TEMP TABLE save_proc_ids AS
            SELECT DISTINCT
                process_id AS process_id
            FROM
                coinc_event;
        INSERT INTO save_proc_ids (process_id)
            SELECT DISTINCT
                process_id
            FROM
                sngl_inspiral;
        INSERT INTO save_proc_ids (process_id)
            SELECT DISTINCT
                process_id
            FROM
                time_slide;
        INSERT INTO save_proc_ids (process_id)
            SELECT DISTINCT
                sim_proc_id
            FROM
                experiment_summary
            WHERE
                sim_proc_id IS NOT NULL;
        CREATE INDEX proc_index ON save_proc_ids (process_id);
        """
    # now step through all tables with process_ids and remove rows who's ids 
    # aren't in save_proc_ids
    for table in ['process','process_params','search_summary','search_summvars','summ_value']:
        sqlscript = ''.join([ sqlscript, 
            """
            DELETE FROM
            """, table, """
            WHERE
                process_id NOT IN (
                    SELECT
                        process_id
                    FROM
                        save_proc_ids
                    );
            """ ])
    connection.cursor().executescript(sqlscript)

    # now remove any veto segments that don't apply by first getting all the
    # end times in the sngl_inspiral table
    if opts.verbose:
        print >> sys.stdout, "Removing veto-segments that don't apply..."
        print >> sys.stdout, "\tgetting event end_times..."

    sqlquery = "SELECT DISTINCT end_time FROM sngl_inspiral"
    in_this_filter = [''.join([ "(start_time <= ", str(end_time[0]), " AND end_time > ", str(end_time[0]), ")"]) for end_time in connection.cursor().execute(sqlquery)]

    # now remove segments that don't intersect with the event_end_times
    if opts.verbose:
        print >> sys.stdout, "\tdeleting segments that don't intersect..."

    sqlquery = ''.join([ """
        DELETE FROM
            segment
        WHERE NOT
            """, ' OR '.join(in_this_filter) ])
    connection.cursor().execute(sqlquery)

    # extract to the xml file
    extract(connection, opts.extract_to_xml, verbose = opts.verbose)

# close connection and exit
connection.close()
# discard the working_filename; if a temporary database was not
# created in tmp_space (opts.tmp_space), this will do nothing. If a temporary database
# was created, however, this will delete it. (see dbtables.py for more info)
dbtables.discard_connection_filename( filename, working_filename, verbose = opts.verbose)

if opts.verbose and opts.tmp_space:
    print >> sys.stdout, "Finshed!"

sys.exit(0)

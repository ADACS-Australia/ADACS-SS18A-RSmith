#!/usr/bin/python
#
# $Id$
#
# Copyright (C) 2007  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


"""
Transfer table data between LIGO Light Weight XML files and SQLite
databases.
"""


from optparse import OptionParser
from pysqlite2 import dbapi2 as sqlite3
import sys

from glue.lal import CacheEntry
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import dbtables
from glue.ligolw import utils
from glue.ligolw.utils import ligolw_add

__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__date__ = "$Date$"[7:-2]
__version__ = "$Revision$"[11:-2]


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	"""
	Parse the command line, return an options object and a list of file
	names.
	"""
	parser = OptionParser(version = "%prog CVS $Id$")
	parser.add_option("-d", "--database", metavar = "filename", help = "use the SQLite3 database named filename")
	parser.add_option("-i", "--input-cache", metavar = "filename", action = "append", default = [], help = "get XML files to insert from the LAL cache named filename")
	parser.add_option("--preserve-ids", action = "store_true", help = "preserve row IDs from the XML in the database (the default is to assign new IDs to prevent collisisions;  inserts will fail if collisions occur)")
	parser.add_option("-x", "--extract", action = "store_true", help = "extract database contents to XML file (default is to insert from XML files)")
	parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
	options, filenames = parser.parse_args()

	for cache in options.input_cache:
		filenames += [c.path() for c in map(CacheEntry, file(cache))]

	if options.extract:
		if len(filenames) > 1:
			raise ValueError, "multiple output files specified"
		if options.input_cache:
			raise ValueError, "cannot set --input-cache with --extract"
	elif not filenames:
		raise ValueError, "no input files"

	if not options.database:
		raise ValueError, "must set --database"

	return options, (filenames or [None])


#
# =============================================================================
#
#                                 Library Code
#
# =============================================================================
#


#
# How to insert
#


def insert(filenames, preserve_ids = True, verbose = False):
	"""
	Iterate over the give filenames, and parse and insert each one into
	the database the dbtables.DBTable class is currently connected to.
	"""
	if not preserve_ids:
		# enable ID remapping
		dbtables.DBTable_idmap_create()
		dbtables.DBTable.append = dbtables.DBTable._remapping_append
	for n, filename in enumerate(filenames):
		# load document (if enabled, row IDs are reassigned on
		# input)
		if verbose:
			print >>sys.stderr, "%d/%d:" % (n + 1, len(filenames)),
		doc = utils.load_filename(filename, verbose = verbose, gz = filename[-3:] == ".gz")

		# update references to row IDs
		if not preserve_ids:
			table_elems = doc.getElementsByTagName(ligolw.Table.tagName)
			for i, tbl in enumerate(table_elems):
				if verbose:
					print >>sys.stderr, "updating IDs: %d%%\r" % (100 * i / len(table_elems)),
				tbl.applyKeyMapping()
			if verbose:
				print >>sys.stderr, "updating IDs: 100%"

			# reset ID mapping for next document
			dbtables.DBTable_idmap_reset()

		# delete cursors
		doc.unlink()
	dbtables.DBTable_commit()


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


options, filenames = parse_command_line()


#
# Open database
#


connection = sqlite3.connect(options.database)
dbtables.DBTable_set_connection(connection)


#
# Do selected operation
#


if options.extract:
	doc = ligolw.Document()
	doc.appendChild(dbtables.DBTable_get_xml())
	filename = filenames[0]
	utils.write_filename(doc, filename, gz = (filename or "stdout")[-3:] == ".gz", verbose = options.verbose)
else:
	insert(filenames, preserve_ids = options.preserve_ids, verbose = options.verbose)
	# check for coincidence tables, and index as needed
	table_names = dbtables.DBTable_table_names()
	if "coinc_event" in table_names:
		if options.verbose:
			print >>sys.stderr, "indexing coinc_event table ..."
		connection.cursor().execute("""
			CREATE INDEX IF NOT EXISTS ce_cdi_index ON coinc_event (coinc_def_id);
		""")
		connection.cursor().execute("""
			CREATE INDEX IF NOT EXISTS ce_tsi_index ON coinc_event (time_slide_id);
		""")
	if "coinc_event_map" in table_names:
		if options.verbose:
			print >>sys.stderr, "indexing coinc_event_map table ..."
		connection.cursor().execute("""
			CREATE INDEX IF NOT EXISTS cem_tn_ei_index ON coinc_event_map (table_name, event_id)
		""")
		connection.cursor().execute("""
			CREATE INDEX IF NOT EXISTS cem_cei_index ON coinc_event_map (coinc_event_id)
		""")


#
# Close database
#


connection.close()

if options.verbose:
	print >>sys.stderr, "done."

#!/usr/bin/python
#
# $Id$
#
# Copyright (C) 2007  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


"""
Transfer table data between LIGO Light Weight XML files and SQLite
databases.
"""


from optparse import OptionParser
from pysqlite2 import dbapi2 as sqlite3
import sys

from glue.lal import CacheEntry
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import dbtables
from glue.ligolw import utils
from glue.ligolw.utils import ligolw_add

__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__date__ = "$Date$"[7:-2]
__version__ = "$Revision$"[11:-2]


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	"""
	Parse the command line, return an options object and a list of file
	names.
	"""
	parser = OptionParser(version = "%prog CVS $Id$")
	parser.add_option("-d", "--database", metavar = "filename", help = "use the SQLite3 database named filename")
	parser.add_option("-i", "--input-cache", metavar = "filename", action = "append", default = [], help = "get XML files to insert from the LAL cache named filename")
	parser.add_option("--add-coinc-indeces", action = "store_true", help = "after inserting all XML files, construct the standard indeces on the coincidence tables")
	parser.add_option("--preserve-ids", action = "store_true", help = "preserve row IDs from the XML in the database (the default is to assign new IDs to prevent collisisions;  inserts will fail if collisions occur)")
	parser.add_option("-x", "--extract", action = "store_true", help = "extract database contents to XML file (default is to insert from XML files)")
	parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
	options, filenames = parser.parse_args()

	for cache in options.input_cache:
		filenames += [c.path() for c in map(CacheEntry, file(cache))]

	if not filenames:
		raise ValueError, "no input files"

	if options.extract:
		if len(filenames) > 1:
			raise ValueError, "multiple output files specified"
		if options.input_cache:
			raise ValueError, "cannot set --input-cache with --extract"
		if options.add_coinc_indeces:
			raise ValueError, "cannot set --add-coinc-indeces with --extract"

	if not options.database:
		raise ValueError, "must set --database"

	return options, filenames


#
# =============================================================================
#
#                                 Library Code
#
# =============================================================================
#


#
# How to insert
#


def insert(filenames, preserve_ids = True, verbose = False):
	"""
	Iterate over the give filenames, and parse and insert each one into
	the database the dbtables.DBTable class is currently connected to.
	"""
	if not preserve_ids:
		# enable ID remapping
		dbtables.DBTable_idmap_create()
		dbtables.DBTable.append = dbtables.DBTable._remapping_append
	for n, filename in enumerate(filenames):
		# load document (if enabled, row IDs are reassigned on
		# input)
		if verbose:
			print >>sys.stderr, "%d/%d:" % (n + 1, len(filenames)),
		doc = utils.load_filename(filename, verbose = verbose, gz = filename[-3:] == ".gz")

		# update references to row IDs
		if not preserve_ids:
			table_elems = doc.getElementsByTagName(ligolw.Table.tagName)
			for i, tbl in enumerate(table_elems):
				if verbose:
					print >>sys.stderr, "updating IDs: %d%%\r" % (100 * i / len(table_elems)),
				tbl.applyKeyMapping()
			if verbose:
				print >>sys.stderr, "updating IDs: 100%"

			# reset ID mapping for next document
			dbtables.DBTable_idmap_reset()

		# delete cursors
		doc.unlink()
	dbtables.DBTable_commit()


#
# Standard coinc indeces
#


def add_coinc_indeces(connection):
	connection.cursor().execute("""
CREATE INDEX cem_tn_cei_index ON coinc_event_map (table_name, coinc_event_id)
	""")
	connection.cursor().execute("""
CREATE INDEX ce_cdi_index ON coinc_event (coinc_def_id);
	""")
	connection.cursor().execute("""
CREATE INDEX ce_tsi_index ON coinc_event (time_slide_id);
	""")


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


options, filenames = parse_command_line()


#
# Open database
#


connection = sqlite3.connect(options.database)
dbtables.DBTable_set_connection(connection)


#
# Do selected operation
#


if options.extract:
	doc = ligolw.Document()
	doc.appendChild(dbtables.DBTable_get_xml())
	filename = filenames[0]
	utils.write_filename(doc, filename, gz = filename[-3:] == ".gz", verbose = options.verbose)
else:
	insert(filenames, preserve_ids = options.preserve_ids, verbose = options.verbose)
	if options.add_coinc_indeces:
		if options.verbose:
			print >>sys.stderr, "constructing coincidence indeces ..."
		add_coinc_indeces(connection)


#
# Close database
#


connection.close()

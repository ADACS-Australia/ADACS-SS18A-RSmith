#!/usr/bin/python

"""
Add (merge) LIGO Lw XML files containing LSC tables.
"""

__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__date__ = "$Date$"
__version__ = "$Revision$"


#
# Preamble.
#

from optparse import OptionParser
import sys
import urllib
from xml import sax

from glue import lal
from glue import segments
from glue.ligolw import ligolw
from glue.ligolw import metaio
from glue.ligolw import lsctables
from glue.ligolw import docutils


#
# Parse command line.
#

parser = OptionParser(version = "%prog CVS $Id$")
parser.add_option("-i", "--input-cache", metavar = "CACHEFILE", action = "append", help = "get input files from trigger cache CACHEFILE")
parser.add_option("--no-duplicate-process", action = "store_true", help = "delete duplicate processes")
parser.add_option("-o", "--output", metavar = "FILENAME", help = "write output to FILENAME (default = stdout")
parser.add_option("-v", "--verbose", action = "store_true", help = "be verbose")
options, urls = parser.parse_args()
del parser

# add urls from cache files
if options.input_cache:
	for cache in options.input_cache:
		urls += [c.url for c in map(lal.CacheEntry, file(cache))]


#
# Load all input documents.  The top-level LIGO_LW elements are all
# appended to a single in-RAM document.
#

if len(urls) < 1:
	raise Exception, "no input files!"

def LoadDocuments(urls):
	doc = ligolw.Document()
	handler = lsctables.LIGOLWContentHandler(doc)
	for url in urls:
		if options.verbose:
			print >>sys.stderr, "Reading %s" % url
		parser = sax.make_parser("xml.sax.drivers2.drv_xmlproc")
		parser.setContentHandler(handler)
		parser.setFeature(sax.handler.feature_validation, False)
		parser.parse(urllib.urlopen(url))
	return doc

doc = LoadDocuments(urls)


#
# Reassign process IDs to prevent collisions.
#

new_process_ids = lsctables.ProcessIDs()

def IsProcessTable(elem):
	return lsctables.IsTableElement(lsctables.ProcessTable, elem)

def BuildProcessMapping(elem):
	# loop over all process tables below elem, constructing a map of
	# old process ID --> new process ID
	mapping = {}
	for table in elem.getElements(IsProcessTable):
		for key in table.keys():
			mapping[key] = str(new_process_ids.next())
	return mapping

# loop over all top-level LIGO_LW elements (input documents)
if options.verbose:
	print >>sys.stderr, "Remapping process IDs in each document..."
for elem in doc.getElementsByTagName(ligolw.LIGO_LW.tagName):
	# build process ID mapping
	idmap = BuildProcessMapping(elem)
	if options.verbose:
		print >>sys.stderr, "ID mapping: %s" % str(idmap)

	# loop over recognized LSC tables, replacing process IDs
	docutils.RemapProcessIDs(elem, idmap)


#
# Merge LIGO_LW elements.
#

reduce(docutils.MergeElements, doc.getElementsByTagName(ligolw.LIGO_LW.tagName))


#
# Merge tables of like type.
#

docutils.MergeCompatibleTables(doc)


#
# Search for duplicate processes, and delete.
#

if options.no_duplicate_process:
	plist = docutils.ProcessList(doc)
	ids = plist.keys()

	duplicates = []
	for i in range(len(ids)):
		for j in range(i + 1, len(ids)):
			if (plist[ids[j]] == plist[ids[i]]) and (ids[j] not in duplicates):
				duplicates.append(ids[j])

	#for id in duplicates:
	#	del plist[id]

	if len(duplicates):
		for table in doc.getElements(lambda e: (e.tagName == ligolw.Table.tagName) and (metaio.StripTableName(e.getAttribute("Name")) in lsctables.TablesByName.keys()) and ("process_id" in e.validcolumns.keys())):
			table.filterRows(lambda r: r.process_id not in duplicates)


#
# Write output.
#

if options.verbose:
	print >>sys.stderr, "Writing output..."
if options.output:
	doc.write(file(options.output, "w"))
else:
	doc.write(sys.stdout)

#!/usr/bin/env tclshexe
#
# File: buildStackSlideAtoBCondorDag.tclsh Started: 01/18/06
# Author: Greg Mendell
#

# Changes

if { !($argc == 21) } {
    puts " ";
    puts "$argv0: creates a Condor DAG for the StackSlide code of the form"
    puts " ";
    puts "  A   ";
    puts "  |   ";
    puts "  B   ";
    puts " ";
    puts "Typically the A jobs find the Loudest Event and the B jobs runs Monte Carlo Simulations to determine an UL";
    puts " ";    
    puts "Usage:";
    puts " ";
    puts "$argv0 <base_name> <ifo> <start_time> <duration> <start_freq> <full_band_width> <num_sub_bands> <sft_time> <num_sfts> <sft_path_pattern> <nodeA_param_file> <nodeA_outputEventFlag> <nodeA_testFlag> <nodeB_param_file> <nodeB_outputEventFlag> <nodeB_testFlag> <sun_edat_file> <earth_edat_file> <computeStackSlideSumsAndPath> <logDir> <dagWorkingDir>";
    puts " ";
    puts "base_name:                    the base filename from which to create all .dag, .sub, .xml, and .txt filenames."
    puts "ifo:                          the IFO for which to create jobs.";
    puts "start_time:                   start time of first SFT to use.";
    puts "duration:                     duration of the search.";
    puts "start_freq:                   start frequency to run on.";
    puts "full_band_width:              full frequency band width to run on.";
    puts "num_sub_bands:                the full band will be divided into this number of sub-bands, and the dag will run A - B jobs on each sub-band.";
    puts "sft_time:                     time baseline of the SFTs used.";
    puts "num_sfts:                     number of sfts used in job."
    puts "sft_path_pattern:             path to SFTs plus glob style pattern to match to find SFT files." 
    puts "nodeA_param_file:             parameter file to use to set up node A."
    puts "nodeA_outputEventFlag         event flag to use with nodeA_param_file. Must have this syntax in nodeA_param_file:"
    puts "                                    set searchOutputEventFlag \"\$outputEventFlagFromDagGen\""
    puts "nodeA_testFlag                test flag to use with nodeA_param_file. Must have this syntax in nodeA_param_file:"
    puts "                                    set searchTestFlag \"\$testFlagFromDagGen\""
    puts "nodeB_param_file:                 parameter file to use to set up node B. (Note that this can be the same as nodeA_param_file.)"
    puts "nodeB_outputEventFlag         event flag to use with nodeB_param_file. Must have this syntax in nodeB_param_file:"
    puts "                                    set searchOutputEventFlag \"\$outputEventFlagFromDagGen\""
    puts "nodeB_testFlag                test flag to use with nodeB_param_file. Must have this syntax in nodeB_param_file:"
    puts "                                    set searchTestFlag \"\$testFlagFromDagGen\""
    puts "sun_edat_file:                path and name of sun ephemeris file to use.";
    puts "earth_edat_file:              path and name of earth ephemeris file to use.";
    puts "computeStackSlideSumsAndPath: path and name of ComputeStackSlideSums executable for nodes A and B."
    puts "logDir:                       directory for log files given in the .sub files; must be on filesystem local to the condor head node.";
    puts "dagWorkingDir:                working directory from where all condor dag and submit files will run.";
    puts " ";
    puts "                              Note that if this line is set in either nodeA_param_file or nodeB_param_file,"
    puts "                                    set searchPriorResultsFile      \"\$priorResultsFileFromDagGen\""
    puts "                              then this dag generator sets priorResultsFileFromDagGen to priorResults_\$base_name.\$jobID (where \$jobID is the job ID number.)"
    puts " ";
    if { $argc !=0 } {
       puts " ";
       puts "!!! There was an error in the command line arguments !!! See usage above."
       puts " ";
    }
    return;
}

# Names of parameters used in the script
set base_name [lindex $argv 0];
set ifo [lindex $argv 1];
set start_time [lindex $argv 2];
set duration [lindex $argv 3];
set start_freq [lindex $argv 4];
set full_band_width [lindex $argv 5];
set num_sub_bands [lindex $argv 6];
set sft_time [lindex $argv 7];
set num_sfts [lindex $argv 8];
set sft_path_pattern [lindex $argv 9];
set nodeA_param_file [lindex $argv 10];
set nodeA_outputEventFlag [lindex $argv 11];
set nodeA_testFlag [lindex $argv 12];
set nodeB_param_file [lindex $argv 13];
set nodeB_outputEventFlag [lindex $argv 14];
set nodeB_testFlag [lindex $argv 15];
set sun_edat_file [lindex $argv 16];
set earth_edat_file [lindex $argv 17];
set computeStackSlideSumsAndPath [lindex $argv 18];
set logDir [lindex $argv 19];
set dagWorkingDir [lindex $argv 20];

# Create submit files for DAG:

# Write submit file for node A.
set submitFileNodeA $base_name;
append submitFileNodeA "_nodeA.sub";
set pAFid [open $submitFileNodeA "w"];
puts $pAFid "universe   = standard";
puts $pAFid "executable = $computeStackSlideSumsAndPath";
puts $pAFid "output     = nodeA.out.\$(JobID)";
puts $pAFid "error      = nodeA.err.\$(JobID)";
set    logFileName $base_name;
append logFileName "_nodeA.log";
puts $pAFid "log        = $logDir/$logFileName";
puts $pAFid "";
puts $pAFid "arguments = \$(argList)";
puts $pAFid "queue";
close $pAFid;

# Write submit file for node B.
set submitFileNodeB $base_name;
append submitFileNodeB "_nodeB.sub";
set pBFid [open $submitFileNodeB "w"];
puts $pBFid "universe   = standard";
puts $pBFid "executable = $computeStackSlideSumsAndPath";
puts $pBFid "output     = nodeB.out.\$(JobID)";
puts $pBFid "error      = nodeB.err.\$(JobID)";
set    logFileName $base_name;
append logFileName "_nodeB.log";
puts $pBFid "log        = $logDir/$logFileName";
puts $pBFid "";
puts $pBFid "arguments = \$(argList)";
puts $pBFid "queue";
close $pBFid;

# Open condor dag file.
set dagFile $base_name;
append  dagFile "_submitAll.dag";
set dagFid [open $dagFile "w"];
puts $dagFid "# DAG for base_name = $base_name";

# find band_width for each job
set band_width [expr $full_band_width/$num_sub_bands]

set outputFileList $base_name;  # file with list of output files
append outputFileList "_fileList.txt";
set pListFid [open $outputFileList "w"];

# loop over jobs:
for {set j 0} {$j<$num_sub_bands} {incr j} {
   set freq [expr $start_freq + ($j*$band_width)];    
   
   # Create nodeA.
   set outputNodeA $base_name;        # Name of files with output from nodeA
   append outputNodeA  "_outputA";
   set mid_freq [expr $freq + ($band_width/2.0)];
   set jobID "$j";
   set outputFileName "$outputNodeA$jobID";
   set cmd "exec ./runComputeStackSlideSUM.tclsh $ifo $start_time $duration $mid_freq $band_width $sft_time $num_sfts \"$sft_path_pattern\" $nodeA_param_file runStackSlideSearch.job $sun_edat_file $earth_edat_file $outputFileName condor";
   set nodeName "A$jobID";
   set outputEventFlagFromDagGen $nodeA_outputEventFlag;
   set testFlagFromDagGen        $nodeA_testFlag;
   set priorResultsFileFromDagGen "$dagWorkingDir/priorResults_"
   append priorResultsFileFromDagGen "$base_name.$j";
   set argList [lindex [split [lindex [split [eval $cmd] "\n"] 1] "="] 1];
   set argList [subst $argList]; # substitute for variables set by this dag generator
   puts $dagFid "JOB $nodeName $submitFileNodeA";
   puts $dagFid "VARS $nodeName JobID=\"$j\" argList=\"$argList\"";
   append outputFileName ".xml";
   puts $pListFid "A$j $outputFileName";
   puts $pListFid "";
   puts $dagFid "";

   # Create nodeB.
   set outputNodeB $base_name;        # Name of files with output from nodeB
   append outputNodeB  "_outputB";
   set mid_freq [expr $freq + ($band_width/2.0)];
   set jobID "$j";
   set outputFileName "$outputNodeB$jobID";
   set cmd "exec ./runComputeStackSlideSUM.tclsh $ifo $start_time $duration $mid_freq $band_width $sft_time $num_sfts \"$sft_path_pattern\" $nodeB_param_file runStackSlideSearch.job $sun_edat_file $earth_edat_file $outputFileName condor";
   set nodeName "B$jobID";
   set outputEventFlagFromDagGen $nodeB_outputEventFlag;
   set testFlagFromDagGen        $nodeB_testFlag;
   set priorResultsFileFromDagGen "$dagWorkingDir/priorResults_"
   append priorResultsFileFromDagGen "$base_name.$j";
   set argList [lindex [split [lindex [split [eval $cmd] "\n"] 1] "="] 1];
   set argList [subst $argList]; # substitute for variables set by this dag generator
   puts $dagFid "JOB $nodeName $submitFileNodeB";
   puts $dagFid "VARS $nodeName JobID=\"$j\" argList=\"$argList\"";
   append outputFileName ".xml";
   puts $pListFid "B$j $outputFileName";
   puts $pListFid "";
   puts $dagFid "";

}
# END loop over jobs: for {set j 0} {$j<$num_sub_bands} {incr j}

# write dependencies into condor dag file and close.
for {set j 0} {$j<$num_sub_bands} {incr j} {
   puts $dagFid "PARENT A$j CHILD B$j\n";
}

close $dagFid;
close $pListFid;
   
exit 0;

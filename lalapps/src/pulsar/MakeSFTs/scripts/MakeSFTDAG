#!/usr/bin/env python
"""

MakeSFTDAG.py - Creates DAGs to run jobs that generates SFTs; can act as a dag generator for use with onasys.
Loosely based on lalapps_strain_pipe

$Id$

"""

__author__ = 'Greg Mendell<gmendell@ligo-wa.caltech.edu>'
__date__ = '$Date$'
__version__ = '$Revision$'[11:-2]


# import standard modules and append the lalapps prefix to the python path
import sys, os
import getopt, re, string
import tempfile
#import ConfigParser
#sys.path.append('')

# import the modules we need to build the pipeline
#from glue import pipeline
#import strain

#
# USAGE FUNCTION
#
def usage():
  msg = """\
Usage: MakeSFTDAG [options]

  -h, --help                display this message
  -s, --gps-start-time      GPS start time of data segment
  -e, --gps-end-time        GPS end time of data segment
  -a, --analysis-start-time GPS start time of data from which to generate SFTs
  -b, --analysis-end-time   GPS end time of data from which to generate SFTs
  -f, --dag-file            filename for .dag file (excluding the .dag)
  -t, --aux-path            path to auxiliary data files
  -G, --tag-string          tag string used in names of various files unique to jobs run under DAG
  -d, --input-data-type     input data type for use with LSCdataFind --type option
  -k  --filter-knee-freq    high pass filter knee frequency used on time domain data before generating SFTs.
  -T  --time-baseline       time baseline of SFTs  (e.g., 60 or 1800 seconds)
  -p  --output-sft-path     path to output SFTs
  -C  --cache-path          path to cache files (cache files will follow a naming convention based on analysis times)
  -N  --channel-name        name of input time-domain channel to read from frames
  -r  --sample-rate         sample rate of input time-domain channel
  -w  --window-type         type of windowing of time-domain to do before generating SFTs (currently unused)
  -v, --sft-ver             sft version to output (1 or 2).
  -m, --max-num-per-node    maximum number of SFTs to generate on one node (this and next option control max number of parallel jobs)
  -L, --max-length-all-jobs maximum amount of data to process, in seconds
  -g, --segment-file        alternative file with segments to use, rather than input times. (currently unused)
  -H  --use-hot             input data is from h(t) calibrated frames (h of t = hot!) (0 or 1).
"""
  print >> sys.stderr, msg

#
# FUNCTION THAT WRITE ONE JOB TO DAG FILE
#
def writeToDag(dagFID, nodeCount, filterKneeFreq, timeBaseline, outputSFTPath, cachePath, startTimeThisNode, endTimeThisNode, channelName, site, inputDataType, useHoT, tagString):
  LSCdataFind = 'LSCdataFind_%i' % nodeCount
  MakeSFTs    = 'MakeSFTs_%i' % nodeCount
  tagStringOut = '%s_%i' % (tagString, nodeCount)
  cacheFile   = '%s/%s-%s-%s.cache' % (cachePath, site,startTimeThisNode,endTimeThisNode)
  dagFID.write('JOB %s datafind.sub\n' % LSCdataFind)
  dagFID.write('RETRY %s 10\n' % LSCdataFind)
  dagFID.write('VARS %s gpsstarttime="%s" gpsendtime="%s" observatory="%s" inputdatatype="%s" tagstring="%s"\n' % (LSCdataFind, startTimeThisNode, endTimeThisNode, site, inputDataType, tagStringOut))
  dagFID.write('JOB %s MakeSFTs.sub\n' % MakeSFTs)
  dagFID.write('RETRY %s 1\n' % MakeSFTs)
  argList = '-f %s -t %s -p %s -C %s -s %s -e %s -N %s' %(filterKneeFreq, timeBaseline, outputSFTPath, cacheFile, startTimeThisNode, endTimeThisNode, channelName)
  if useHoT: argList = argList + ' -H'
  dagFID.write('VARS %s argList="%s" tagstring="%s"\n'%(MakeSFTs,argList, tagStringOut))
  dagFID.write('PARENT %s CHILD %s\n'%(LSCdataFind,MakeSFTs))
  
#
# MAIN CODE START HERE 
#
 
# parse the command line options
shortop = "s:e:a:b:f:t:G:d:k:T:p:C:N:r:w:v:m:L:g:hH"
longop = [
  "help",
  "gps-start-time=",
  "gps-end-time=",
  "analysis-start-time=",
  "analysis-end-time=",
  "dag-file=",
  "aux-path=",
  "tag-string=",
  "input-data-type=",
  "filter-knee-freq=",
  "time-baseline=",
  "output-sft-path=",
  "cache-path=",
  "channel-name=",
  "sample-rate=",
  "window-type=",
  "sft-ver=",
  "max-num-per-node=",
  "max-length-all-jobs",
  "segment-file",
  "use-hot",
  ]

try:
  opts, args = getopt.getopt(sys.argv[1:], shortop, longop)
except getopt.GetoptError:
  usage()
  sys.exit(1)

# initialize with default values or with None
config_file = None
log_path = None
gpsStartTime = None
gpsEndTime = None
analysisStartTime = None
analysisEndTime = None
dagFileName = None
auxPath = None
tagString = None
inputDataType = None
filterKneeFreq = -1
timeBaseline = None
outputSFTPath = None
cachePath = None
channelName = None
sampleRate = None
windowType = None
sftVersion = None
maxNumPerNode = None
maxLengthAllJobs = None
segmentFile = None
useHoT = False

for o, a in opts:
  if o in ("-h", "--help"):
    usage()
    sys.exit(0)
  elif o in ("-s", "--gps-start-time"):
    gpsStartTime = long(a)
  elif o in ("-e", "--gps-end-time"):
    gpsEndTime = long(a)
  elif o in ("-a", "--analysis-start-time"):
    analysisStartTime = long(a)
  elif o in ("-b", "--analysis-end-time"):
    analysisEndTime = long(a)    
  elif o in ("-f", "--dag-file"):
    dagFileName = a   
  elif o in ("-t", "--aux-path"):
    auxPath = a
  elif o in ("-G", "--tag-string"):
    tagString = a
  elif o in ("-d", "--input-data-type"):
    inputDataType = a
  elif o in ("-k", "--filter-knee-freq"):
    filterKneeFreq = long(a)
  elif o in ("-T", "--time-baseline"):
    timeBaseline = long(a)
  elif o in ("-p", "--output-sft-path"):
    outputSFTPath = a
  elif o in ("-C", "--cache-path"):
    cachePath = a
  elif o in ("-N", "--channel-name"):
    channelName = a
  elif o in ("-r", "--sample-rate"):
    sampleRate = long(a)
  elif o in ("-w", "--window-type"):
    windowType = a
  elif o in ("-v", "--sft-ver"):
    sftVersion = long(a)
  elif o in ("-m", "--max-num-per-node"):
    maxNumPerNode = long(a)
  elif o in ("-L", "--max-length-all-jobs"):
    maxLengthAllJobs = long(a)
  elif o in ("-g", "--segment-file"):
    segmentFile = a
  elif o in ("-H", "--use-hot"):
    useHoT = True
  else:
    print >> sys.stderr, "Unknown option:", o
    usage()
    sys.exit(1)

if not gpsStartTime:
  print >> sys.stderr, "No GPS start time specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not gpsEndTime:
  print >> sys.stderr, "No GPS end time specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not analysisStartTime:
  print >> sys.stderr, "No GPS analysis start time specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not analysisEndTime:
  print >> sys.stderr, "No GPS analysis end time specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not dagFileName:
  print >> sys.stderr, "No dag filename specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not auxPath:
  print >> sys.stderr, "No auxilary data path specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not tagString:
  print >> sys.stderr, "No tag string specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not inputDataType:
  print >> sys.stderr, "No input data type specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if filterKneeFreq < 0:
  print >> sys.stderr, "No filter knee frequency specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not timeBaseline:
  print >> sys.stderr, "No time baseline specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not outputSFTPath:
  print >> sys.stderr, "No output SFT path specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)
  
if not cachePath:
  print >> sys.stderr, "No cache path specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not channelName:
  print >> sys.stderr, "No channel name specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not sampleRate:
  print >> sys.stderr, "No sample rate specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)
  
if not windowType:
  print >> sys.stderr, "No window type specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not sftVersion:
  print >> sys.stderr, "No SFT version specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not maxNumPerNode:
  print >> sys.stderr, "No maximum number of SFTs per node specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not maxLengthAllJobs:
  print >> sys.stderr, "No maximum length of all jobs specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

# initialize other variable
config_file = auxPath + '/MakeSFTDAG.ini' 
log_path = './'

# vet variables for errors:
if not config_file:
  print >> sys.stderr, "No configuration file specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)

if not log_path:
  print >> sys.stderr, "No log file path specified."
  print >> sys.stderr, "Use --help for usage details."
  sys.exit(1)
  
# try and make a directory to store the cache files and job logs
try: os.mkdir('logs')
except: pass
try: os.mkdir('cache')
except: pass

# create the config parser object and read in the ini file
#cp = ConfigParser.ConfigParser()
#cp.read(config_file)

# create a log file that the Condor jobs will write to
#tempfile.tempdir = log_path
#tempfile.template = auxPath + '.dag.log.'
#logfile = tempfile.mktemp()
#fh = open( logfile, "w" )
#fh.close()

# Check if segment file was given, else set up one segment from the command line
segList = [];
adjustSegExtraTime = False
if (segmentFile != None):
    # the next flag causes extra time that cannot be processes to be trimmed from the start and end of a segment
    adjustSegExtraTime = True
    try:
         for line in open(segmentFile):
             try: 
                 splitLine = line.split();
                 try: 
                     oneSeg = [];
                     oneSeg.append(long(splitLine[0]));
                     oneSeg.append(long(splitLine[1]));
                     segList.append(oneSeg);
                 except:
                     pass
             except:
                 pass
         # End for line in open(segmentFile)
         if (len(segList) < 1):
             print >> sys.stderr, "No segments found in segment file: %s." % segmentFile
             sys.exit(1)
    except:
         print >> sys.stderr, "Error reading or parsing segment file: %s." % segmentFile
         sys.exit(1)
else:
    try:
        oneSeg = [];
        oneSeg.append(analysisStartTime);
        oneSeg.append(analysisEndTime);
        segList.append(oneSeg);
    except:
        print >> sys.stderr, "There was a problem setting up the segment to run on: [%s, %s)." % (analysisStartTime,analysisEndTime)
        sys.exit(1)
    
# END if (segmentFile != None)

# Make sure not to exceed maximum allow analysis
if (analysisEndTime > analysisStartTime + maxLengthAllJobs):
    analysisEndTime = analysisStartTime + maxLengthAllJobs

# Get the IFO site, which is the first letter of the channel name.
site = channelName[0]

# initialize count of nodes
nodeCount         = 0L

# create the DAG file with the jobs to run
dagFileName = dagFileName + '.dag'
dagFID = file(dagFileName,'w')

startTimeAllNodes = None
for seg in segList:
    # Each segment in the segList runs on one or more nodes; initialize the number SFTs produced by the current node:
    numThisNode = 0L
    if (adjustSegExtraTime):
       segStartTime = seg[0]
       segEndTime = seg[1]
       segExtraTime = (segEndTime - segStartTime) % timeBaseline
       segExtraStart =  long(segExtraTime / 2)
       segExtraEnd = segExtraTime - segExtraStart
       #print segStartTime,segEndTime, segExtraTime, segExtraStart, segExtraEnd
       analysisStartTime = segStartTime + segExtraStart
       if analysisStartTime > segEndTime: analysisStartTime = segEndTime
       analysisEndTime = segEndTime - segExtraEnd
       if analysisEndTime < segStartTime: analysisEndTime = segStartTime
    else:
       analysisStartTime = seg[0]
       analysisEndTime = seg[1]     
    #print analysisStartTime, analysisEndTime
    # Loop through the analysis time; make sure no more than maxNumPerNode SFTs are produced by any one node
    startTimeThisNode = analysisStartTime
    endTimeThisNode   = analysisStartTime
    endTimeAllNodes   = analysisStartTime
    while (endTimeAllNodes < analysisEndTime):
         # increment endTimeAllNodes by the timeBaseline until we get past the analysisEndTime
         endTimeAllNodes = endTimeAllNodes + timeBaseline
         if (endTimeAllNodes <= analysisEndTime):
            # increment the number of SFTs output from this node, and update the end time this node.
            numThisNode = numThisNode + 1
            endTimeThisNode = endTimeAllNodes
            if (numThisNode < maxNumPerNode):
               continue
            else:
               # write jobs to dag for this node
               nodeCount = nodeCount + 1
               if (nodeCount ==1): startTimeAllNodes = startTimeThisNode
               writeToDag(dagFID,nodeCount, filterKneeFreq, timeBaseline, outputSFTPath, cachePath, startTimeThisNode, endTimeThisNode, channelName, site, inputDataType, useHoT, tagString)
               # Update for next node
               startTimeThisNode = endTimeThisNode
               numThisNode       = 0L
    else:
         # we are at or past the analysisEndTime; output job for last node if needed.
         if (numThisNode > 0L):
            # write jobs to dag for this node
            nodeCount = nodeCount + 1
            if (nodeCount ==1): startTimeAllNodes = startTimeThisNode
            writeToDag(dagFID,nodeCount, filterKneeFreq, timeBaseline, outputSFTPath, cachePath, startTimeThisNode, endTimeThisNode, channelName, site, inputDataType, useHoT, tagString)
    # END while (endTimeAllNodes < analysisEndTime)
# END for seg in segList

# Close the DAG file
dagFID.close

# Update actual end time of the last job and print out the times all jobs will run on:
endTimeAllNodes = endTimeThisNode

if not startTimeAllNodes:
  print >> sys.stderr, "The startTimeAllNodes == none; the DAG file contains no jobs!"
  sys.exit(1)

if (endTimeAllNodes <= startTimeAllNodes):
  print >> sys.stderr, "The endTimeAllNodes <= startTimeAllNodes; the DAG file contains no jobs!"
  sys.exit(1)

print >> sys.stdout, startTimeAllNodes, endTimeAllNodes

sys.exit(0)

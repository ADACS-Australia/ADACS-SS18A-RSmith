#!/usr/bin/env python
"""
plot_inspiral_hipe.in - generates plots from ihope output

$Id$

This script generates a condor DAG to make plots that summarize the
results of an inspiral search
"""

__author__ = 'Patrick Brady <patrick@gravity.phys.uwm.edu>'
__date__ = '$Date$'
__version__ = '$Revision$'[11:-2]

##############################################################################
# import standard modules and append the lalapps prefix to the python path
import sys, os, copy, math
import socket, time
import re, string
from optparse import *
import tempfile
import ConfigParser
import urlparse
from pylal import CoincInspiralUtils
from pylal import itertools
sys.path.append('@PYTHONLIBDIR@')
##############################################################################
# import the modules we need to build the pipeline
from glue import pipeline

from lalapps import inspiral

##############################
# Convert ifo list to string
def combo2str(combo):
  ifo_list = ""
  for ifo in combo:
    ifo_list += ifo
  return ifo_list

#############################################################################
#
#  MAIN PROGRAM
#
##############################################################################
usage = """usage: %prog [options] 
"""

parser = OptionParser( usage )

parser.add_option("-v", "--version",action="store_true",default=False,\
    help="print version information and exit")
    
parser.add_option("-u", "--user-tag",action="store",type="string",\
    default=None,metavar=" USERTAG",\
    help="tag the jobs with USERTAG (overrides value in ini file)")

parser.add_option("-G", "--g1-data",action="store_true",default=False,\
    help="analyze g1 data")

parser.add_option("-H", "--h1-data",action="store_true",default=False,\
    help="analyze h1 data")

parser.add_option("-B", "--h2-data",action="store_true",default=False,\
    help="analyze h2 data")

parser.add_option("-L", "--l1-data",action="store_true",default=False,\
    help="analyze l1 data")

parser.add_option("-V", "--v1-data",action="store_true",default=False,\
    help="analyze v1 data")

parser.add_option("-S", "--one-ifo",action="store_true",default=False,\
    help="analyze single ifo data (not usable for GEO)")

parser.add_option("-D", "--two-ifo",action="store_true",default=False,\
    help="analyze two interferometer data")

parser.add_option("-T", "--three-ifo",action="store_true",default=False,\
    help="analyze three interferometer data")

parser.add_option("-Q", "--four-ifo",action="store_true",default=False,\
    help="analyze four intereferometer data")
  
parser.add_option("-R", "--five-ifo",action="store_true",default=False,\
    help="analyze five intereferometer data")

parser.add_option("-a", "--analyze-all",action="store_true",default=False,\
    help="analyze all ifos and all data (over-rides above)")

parser.add_option("-i", "--plotinspiral" ,action="store_true",default=False,\
    help="run plotinspiral to summarize filtering output")

parser.add_option("-t", "--plotthinca" ,action="store_true",default=False,\
    help="run plotthina to summarize coincidence")

parser.add_option("-n", "--plotnumtemplates" ,action="store_true",default=False,\
    help="run plotnumtemplates to plot trigbanks and templtbanks")

parser.add_option("-r", "--plotinjnum" ,action="store_true",default=False,\
    help="run plotinj")

parser.add_option("-e", "--plotethinca" ,action="store_true",default=False,\
    help="run plotethinca parameter for a pair of ifo combos")

parser.add_option("-M", "--plotinspmissed" ,action="store_true",default=False,\
    help="run plotinspmissed to plot missed triggers")

parser.add_option("-j", "--plotinspinj" ,action="store_true",default=False,\
    help="run plotinspinj to plot inspiral injections.")

parser.add_option("-s", "--plotsnrchi" ,action="store_true",default=False,\
    help="run plotsnrchi to plot  snr vs chisq for a glob of triggers.")

parser.add_option("-z", "--plotinspiralrange" ,action="store_true",default=False,\
    help="run plotinspiralrange to plot range of inspiral (Mpc) vs end time (in days).")

parser.add_option("-f", "--config-file",action="store",type="string",\
    metavar=" FILE",help="use configuration file FILE")

parser.add_option("-p", "--log-path",action="store",type="string",\
    metavar=" PATH",help="directory to write condor log file")
#################################

parser.add_option("-P", "--playground_only",action="store_true",default=True,\
    help="Run plot_hipe only one the playground directory")

parser.add_option("-A", "--analysis_only",action="store_true",default=True,\
    help="Run plot_hipe on analysis directory")

parser.add_option("-I", "--injections_only",action="store_true",default=True,\
    help="Run plot_hipe on injection directory")




command_line = sys.argv[1:]
(opts,args) = parser.parse_args()

#################################
#ALPHABETS USED IN THIS CODE.
# a, b, e, f, g, i, I, j, l, M, n, p ,P , s, t, u, v, A, D, R, S, T, Q

#################################
# if --version flagged
if opts.version:
  print "$Id$"
  sys.exit(0)

#################################
# Sanity check of input arguments
################################

# Checks for config file
if not opts.config_file:
  print >> sys.stderr, "No configuration file specified."
  print >> sys.stderr, "Use --config-file FILE to specify location."
  sys.exit(1)

# Checks for log path
if not opts.log_path:
  print >> sys.stderr, "No log file path specified."
  print >> sys.stderr, "Use --log-path PATH to specify a location."
  sys.exit(1)

# Checks for atleast one ifo is specified  
if not opts.g1_data and not opts.h1_data and not opts.h2_data and \
    not opts.l1_data and not opts.analyze_all:
  print >> sys.stderr, "No ifos specified.  Please specify at least one of"
  print >> sys.stderr, "--g1-data, --h1-data, --h2-data, --l1-data"
  print >> sys.stderr, "or use --analyze-all to analyze all ifos all data"
  sys.exit(1)

# Checks for ifos dependind on plotting routine.
# Checks for plots which require more than two ifos.
if ((opts.plotthinca or opts.plotethinca or opts.plotinspmissed or opts.plotinjnum or opts.plotinspinj \
    or opts.plotsnrchi ) and not (opts.two_ifo or opts.three_ifo or opts.four_ifo or opts.analyze_all)):
  print >> sys.stderr, "No number of ifos given. Please specify at least two"
  print >> sys.stderr, "--two-ifo, --three-ifo, --four-ifo"
  print >> sys.stderr, "or use --analyze-all to analyze all ifos all data"
  sys.exit(1)
 

if ((opts.plotnumtemplates or opts.plotinspiral or opts.plotinspiralrange) and not (opts.g1_data or opts.h1_data or opts.h2_data or\
    opts.l1_data)):
  print >> sys.stderr, "--g1-data, --h1-data, --h2-data, --l1-data"
  sys.exit(1)
 


###############################
# Construct list based on ifos supplied at command line

ifolist = [ifo for ifo in ('G1','H1', 'H2', 'L1', 'V1') \
            if getattr(opts, "%s_data" % ifo.lower())]

if opts.two_ifo:
   ifo_combo=list(itertools.choices(ifolist,2))
if opts.three_ifo:
   ifo_combo=list(itertools.choices(ifolist,2)) + list(itertools.choices(ifolist,3))
if opts.four_ifo:
   ifo_combo=list(itertools.choices(ifolist,2)) + list(itertools.choices(ifolist,3)) + \
             list(itertools.choices(ifolist,4))
if opts.analyze_all: 
   ifo_combo=CoincInspiralUtils.get_ifo_combos(ifolist)


##############################################################################
# try to make a directory to store the cache files and job logs
try: os.mkdir('logs')
except: pass

##############################################################################
# create the config parser object and read in the ini file
cp = ConfigParser.ConfigParser()
cp.read(opts.config_file)

##############################################################################
# if a usertag has been specified, override the config file
if opts.user_tag:
  usertag = opts.user_tag
  cp.set('pipeline','user-tag',usertag)
else:
  try:
    usertag = string.strip(cp.get('pipeline','user-tag'))
  except:
    usertag = None
  
##############################################################################
# create a log file that the Condor jobs will write to
basename = re.sub(r'\.ini',r'',opts.config_file)
tempfile.tempdir = opts.log_path
if usertag:
  tempfile.template = basename + '.' + usertag + '.dag.log.'
else:
  tempfile.template = basename + '.dag.log.'
logfile = tempfile.mktemp()
fh = open( logfile, "w" )
fh.close()

##############################################################################
# create the DAG writing the log to the specified directory
dag = pipeline.CondorDAG(logfile)
if usertag:
  dag.set_dag_file(basename + '.' + usertag )
else:
  dag.set_dag_file(basename )

# set better submit file names than the default
if usertag:
  subsuffix = '.' + usertag + '.sub'
else:
  subsuffix = '.sub'

##############################################################################
# create the Condor jobs that will be used in the DAG
all_jobs = []

# inspiral:
if opts.plotinspiral:
  
  """ Plotinspiral is looped over all single ifos. Plotinspiral 
      has now an option called opts.description, which sieves the 
      cache file by description "SIRE" and an ifo by ifo-type namely 
      "H1", "H2" or "L1". For a particular ifo file corresponding 
      all times are sieved.
  """
  plotinspiral_jobs = {}

  for ifo in ifolist:
    cp.set('plotinspiral','figure-name','plotinspiral_' + ifo)
    cp.set('plotinspiral','ifo-type',ifo)
    plotinspiral_jobs[ifo] = inspiral.PlotInspiralJob(cp)
    plotinspiral_jobs[ifo].set_sub_file( basename + '.plotinspiral_' + ifo + subsuffix )

 
  all_jobs.extend(plotinspiral_jobs.values())


#plotthinca
if opts.plotthinca:
  plotthinca_jobs = {}
  for ifos in  ifo_combo:
    combostring = combo2str(ifos)
    plotthinca_jobs[combostring] = inspiral.PlotThincaJob(cp)
    for ifo in ifos:
      plotthinca_jobs[combostring].add_opt(ifo.lower() + "-triggers","  ")
    plotthinca_jobs[combostring].add_opt("ifo-times",combostring)
    plotthinca_jobs[combostring].add_opt('figure-name', combostring +'_plotthinca')
    plotthinca_jobs[combostring].set_sub_file( basename + '.plotthinca_' + combostring + subsuffix )
  
  all_jobs.extend(plotthinca_jobs.values())


#plotnumtemplates
if opts.plotnumtemplates:
  """ Plotnumtemplates needs no looping. This code now separates cache files
      either by description = "TMPLTBANK" or "TRIGBANK". In this way TMPLTBANKS 
      and TRIGBANKS for all ifos namely "H1", "H2" and "L1" are sieved together.
  """
  plotnumtemplates_jobs = {}
  plotnumtemplates_jobs = inspiral.PlotNumtemplatesJob(cp)
  plotnumtemplates_jobs.set_sub_file( basename + '.plotnumtemplates' + subsuffix)

  all_jobs.append(plotnumtemplates_jobs)


#plotinjnum
if opts.plotinjnum:
  """ Plotinjnum is now looped over all ifo times. Hence the figure names
      are for times but they can be interchanged with coinc type because 
      plotinjnum now has an option ( ifoexactmatch=True ) which can separate 
      out COIRE files, according to double coincs in  double times, or triple 
      coincs in triple times.

      Example: sieve(ifos="H1H2",description="FOUND").sieve(ifoexactmatch=True)
      will return files of type: H1H2-COIRE_INJECTIONS_1_FOUND_H1H2-866088014-2592000.xml etc.
      and similarly sieve(ifos="H1H2L1",description="FOUND").sieve(ifoexactmatch=True) 
      will return file: H1H2L1-COIRE_INJECTIONS_1_FOUND_H1H2L1-866088014-2592000.xml

  """
  plotinjnum_jobs = {}
  
  for ifos in  ifo_combo:
    combostring = combo2str(ifos)
    cp.set('plotinjnum','ifo-type', combostring)
    cp.set('plotinjnum','figure-name','plotinjnum_' + combostring)
    plotinjnum_jobs[combostring] = inspiral.PlotInjnumJob(cp) 
    plotinjnum_jobs[combostring].set_sub_file( basename + '.plotinjnum_' +  combostring + subsuffix )
  
  all_jobs.extend(plotinjnum_jobs.values())  


# plotethinca
if opts.plotethinca:

  plotethinca_jobs = {}

  for ifos in  ifo_combo:
    combostring = combo2str(ifos)
    plotethinca_jobs[combostring] = inspiral.PlotEthincaJob(cp)
    ifosoption=ifos[0]
    for i in range(1,len(ifos)):
      ifosoption+=' --ifo '+ ifos[i]
    plotethinca_jobs[combostring].add_opt("ifo", ifosoption)
    plotethinca_jobs[combostring].add_opt("ifo-times", combostring)
    plotethinca_jobs[combostring].add_opt("figure-name", combostring + '-plotethinca')
    plotethinca_jobs[combostring].set_sub_file( basename + '.plotethinca_' + combostring + subsuffix )

  all_jobs.extend(plotethinca_jobs.values())


#plotinspmissed
if opts.plotinspmissed:

  plotinspmissed_jobs = {}

  for ifo in ifolist:
    cp.set('plotinspmissed','fig-name','plotinspmissed_' + ifo)
    cp.set('plotinspmissed','ifo-type',ifo)
    cp.set('plotinspmissed','ifo',ifo)
    plotinspmissed_jobs[ifo] = inspiral.PlotInspmissedJob(cp)
    plotinspmissed_jobs[ifo].set_sub_file( basename + '.plotinspmissed_' + ifo + subsuffix )

  all_jobs.extend(plotinspmissed_jobs.values())


#plotinspmissed
if opts.plotinspinj:

  plotinspinj_jobs = {}

  for ifo in ifolist:
    cp.set('plotinspinj','figure-name','plotinspinj_' + ifo)
    cp.set('plotinspinj','ifo-type',ifo)
    plotinspinj_jobs[ifo] = inspiral.PlotInspinjJob(cp)
    plotinspinj_jobs[ifo].set_sub_file( basename + '.plotinspinj_' + ifo + subsuffix )

  all_jobs.extend(plotinspinj_jobs.values())

#plotsnrchi
if opts.plotsnrchi:

  plotsnrchi_jobs = {}

  for ifo in ifolist:
    plotsnrchi_jobs[ifo] = inspiral.PlotSnrchiJob(cp)
    plotsnrchi_jobs[ifo].add_opt("figure-name", ifo + "-plotsnrchi")
    plotsnrchi_jobs[ifo].add_opt("title", ifo)
    plotsnrchi_jobs[ifo].add_opt("single-ifo", ifo)
    plotsnrchi_jobs[ifo].set_sub_file( basename + '.plotsnrchi_' + ifo + subsuffix )

  all_jobs.extend(plotsnrchi_jobs.values())

#plotinspiralrange
if opts.plotinspiralrange:
  """ Plotnumtemplates needs no looping. This code now separates cache files
      either by description = "TMPLTBANK" or "INSPIRAL". In this way TMPLTBANKS
      and TRIGBANKS for all ifos namely "H1", "H2" and "L1" are sieved together.
  """
  plotinspiralrange_jobs = {}
  plotinspiralrange_jobs = inspiral.PlotInspiralrangeJob(cp)
  plotinspiralrange_jobs.set_sub_file( basename + '.plotinspiralrange' + subsuffix)

  all_jobs.append(plotinspiralrange_jobs)


#############################################################################
# set the usertag in the jobs
if usertag:
  for job in all_jobs:
    job.add_opt('user-tag',usertag)

##############################################################################
#  The meat of the DAG generation comes below
#
##############################################################################

if opts.plotinspiral:
  for ifo in ifolist:
  # add an plotinspiral job
    plotinspiral_node=inspiral.PlotInspiralNode(plotinspiral_jobs[ifo])
    dag.add_node(plotinspiral_node)


if opts.plotnumtemplates:
  # add an plotnumtemplates job
  plotnumtemplates_node=inspiral.PlotNumtemplatesNode(plotnumtemplates_jobs)
  dag.add_node(plotnumtemplates_node)


if opts.plotthinca:
  # add an plotthinca job
  for ifos in ifo_combo:
    combostring = combo2str(ifos)
    plotthinca_node=inspiral.PlotThincaNode(plotthinca_jobs[combostring])
    dag.add_node(plotthinca_node)


if opts.plotinjnum:
  for ifos in ifo_combo:
    combostring = combo2str(ifos)
    plotinjnum_node=inspiral.PlotInjnumNode(plotinjnum_jobs[combostring])
    dag.add_node(plotinjnum_node)


if opts.plotethinca:
  for ifos in ifo_combo:
    combostring = combo2str(ifos)
    plotethinca_node =inspiral.PlotEthincaNode(plotethinca_jobs[combostring])
    dag.add_node(plotethinca_node)


if opts.plotinspmissed:
  for ifo in ifolist:
    plotinspmissed_node =inspiral.PlotInspmissedNode(plotinspmissed_jobs[ifo])
    dag.add_node(plotinspmissed_node)


if opts.plotinspinj:
   for ifo in ifolist:
  # add an plotinspinj job
    plotinspinj_node =inspiral.PlotInspinjNode(plotinspinj_jobs[ifo])
    dag.add_node(plotinspinj_node)


if opts.plotsnrchi:
   for ifo in ifolist:
  # add an plotinspinj job
    plotsnrchi_node =inspiral.PlotSnrchiNode(plotsnrchi_jobs[ifo])
    dag.add_node(plotsnrchi_node)

if opts.plotinspiralrange:
  # add an plotnumtemplates job
  plotinspiralrange_node=inspiral.PlotInspiralrangeNode(plotinspiralrange_jobs)
  dag.add_node(plotinspiralrange_node)

##############################################################################
# Step 10: Write out the DAG, help message and log file
dag.write_sub_files()
dag.write_dag()

##############################################################################  
# write a message telling the user that the DAG has been written
print "\nCreated a DAG file which can be submitted by executing"
print "\n   condor_submit_dag", dag.get_dag_file()
print """\nfrom a condor submit machine (e.g. hydra.phys.uwm.edu)\n
If you are running LSCdataFind jobs, do not forget to initialize your grid 
proxy certificate on the condor submit machine by running the commands

  unset X509_USER_PROXY
  grid-proxy-init -hours 72

Enter your pass phrase when promted. The proxy will be valid for 72 hours. 
If you expect the LSCdataFind jobs to take longer to complete, increase the
time specified in the -hours option to grid-proxy-init. You can check that 
the grid proxy has been sucessfully created by executing the command:

  grid-cert-info -all -file /tmp/x509up_u`id -u`

This will also give the expiry time of the proxy. 
"""

##############################################################################
# write out a log file for this script
if usertag:
  log_fh = open(basename + '.plotter.' + usertag + '.log', 'w')
else:
  log_fh = open(basename + '.plotter.log', 'w')
  
log_fh.write( "$Id$" + "\n" )
log_fh.write( "$Name$" + "\n\n" )
log_fh.write( "Invoked with arguments:" )
for arg in command_line:
  if arg[0] == '-':
    log_fh.write( "\n" )
  log_fh.write( arg + ' ')

log_fh.write( "\n" )
log_fh.write( "Config file has CVS strings:\n" )
#log_fh.write( cp.get('pipeline','version') + "\n" )
#log_fh.write( cp.get('pipeline','cvs-tag') + "\n\n" )

log_fh.close()

sys.exit(0)


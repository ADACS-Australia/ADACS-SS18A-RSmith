#!/usr/bin/env @PYTHONPROG@
"""
Something

$Id$

This program creates cache files for the output of inspiral hipe
"""

__author__ = 'Chad Hanna <channa@phys.lsu.edu>'
__date__ = '$Date$'
__version__ = '$Revision$'[11:-2]

##############################################################################
# import standard modules and append the lalapps prefix to the python path
import sys, os, copy, math, random
import socket, time
import re, string
from optparse import *
import tempfile
import ConfigParser
import urlparse
import urllib
from UserDict import UserDict
sys.path.append('@PYTHONLIBDIR@')

##############################################################################
# import the modules we need to build the pipeline
from glue import pipeline
from glue import lal
from glue import segments 
from glue import segmentsUtils
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import utils
from pylal import CoincInspiralUtils
from pylal.fu_utils import *
from pylal.fu_writeXMLparams import * 
from pylal.fu_Condor import *
from pylal import Fr
from lalapps import inspiral
from lalapps import inspiralutils

##############################################################################
#
#  MAIN PROGRAM
#
##############################################################################

######################## OPTION PARSING  #####################################
usage = """usage: %prog [options]
"""

parser = OptionParser( usage )

parser.add_option("-v", "--version",action="store_true",default=False,\
    help="print version information and exit")

parser.add_option("-l", "--log-path",action="store",type="string",\
    metavar=" PATH",help="directory to write condor log file")

parser.add_option("-f", "--config-file",action="store",type="string",\
    metavar=" FILE",help="ini file")

parser.add_option("-g", "--generate-fu-cache",action="store_true",\
    default=False, help="create hipe caches")

parser.add_option("-m", "--datafind",action="store_true",\
    default=False, help="use datafind to get qscan/trends data")

parser.add_option("-M", "--hoft-datafind",action="store_true",\
    default=False, help="use datafind to get hoft data (for qscan)")

parser.add_option("-q", "--qscan",action="store_true",default=False,\
    help="do qscans")

parser.add_option("-G", "--generate-segments",action="store_true",\
    default=False, help="generate the science segments for background qscans")

parser.add_option("-Q", "--background-qscan",action="store_true",default=False,\
    help="do qscans over a list of times")

parser.add_option("-n", "--hoft-qscan",action="store_true",\
    default=False, help="do hoft qscans")

parser.add_option("-N", "--background-hoft-qscan",action="store_true",\
    default=False, help="do hoft qscans over a list of times")

parser.add_option("-s", "--seis-qscan",action="store_true",\
    default=False, help="do seismic qscans")

parser.add_option("-S", "--background-seis-qscan",action="store_true",\
    default=False, help="do seismic qscans over a list of times")

parser.add_option("-d", "--data-quality",action="store_true",default=False,\
    help="do data quality lookup - CURRENTLY BROKEN, DO NOT USE IT")

parser.add_option("-t", "--trig-bank",action="store_true",default=False,\
    help="generate a pseudo trigbank xml file for single triggers")

parser.add_option("-i", "--inspiral",action="store_true",default=False,\
    help="do inspirals for single triggers - output SNR/CHISQ/PSD")

parser.add_option("-p", "--plots",action="store_true",default=False,\
    help="plot SNR/CHISQ from inspiral stage")

parser.add_option("-w", "--write-to-iulgroup",action="store_true", \
    default=False, help="publish the page to the iulgroup")

command_line = sys.argv[1:]
(opts,args) = parser.parse_args()

if opts.version:
  print "$Id$"
  sys.exit(0)

####################### SANITY CHECKS #####################################

if not opts.config_file:
  print >> sys.stderr, "No configuration file specified."
  print >> sys.stderr, "Use --config-file FILE to specify location" 
  sys.exit(1)

if not opts.log_path and not opts.write_to_iulgroup:
  print >> sys.stderr, "No log file path specified"
  print >> sys.stderr, "Use --log-path PATH to specify a location"
  sys.exit(1)

if not opts.write_to_iulgroup and not opts.generate_fu_cache and \
  not opts.datafind and not opts.qscan and not opts.background_qscan \
  and not opts.trig_bank and not opts.inspiral and not opts.plots and not \
  opts.hoft_qscan and not opts.seis_qscan and not opts.background_hoft_qscan \
  and not opts.background_seis_qscan and not opts.hoft_datafind and not \
  opts.generate_segments:
  print >> sys.stderr, "No steps of the pipeline specified."
  print >> sys.stderr, "Please specify at least one of"
  print >> sys.stderr, "--generate-fu-cache, --trig-bank, --inspiral, --plots,"
  print >> sys.stderr, "--datafind, --qscan, --hoft-qscan, --seis-qscan"
  print >> sys.stderr, "--background-qscan, --background-hoft-qscan"
  print >> sys.stderr, "--background-seis-qscan, --hoft-datafind"
  print >> sys.stderr, "--generate-segments"
  print >> sys.stderr, "or --write-to-iulgroup (use this option alone for now)"  
  sys.exit(1)


#################### READ IN THE CONFIG (.ini) FILE ########################
cp = ConfigParser.ConfigParser()
cp.read(opts.config_file)

## get the directory where the code is run
currentPath = os.path.abspath('.')

############# TURN THE HIPE OUTPUT INTO LAL CACHE FILES #######################

cache = getCache(opts,cp,currentPath)

##############################################################################
# create the DAG writing the log to the specified directory
page = string.strip(cp.get('output','page'))
dag = followUpDAG(opts.config_file, opts.log_path)
dag.setupDAGWeb('followup web page','index.html',page)

#if not opts.read_triggers and opts.write_to_iulgroup:
#if opts.write_to_iulgroup:
#  publishOnHydra(page)
  # don't overwrite anything, just publish what we have
#  sys.exit(0)

############# READ IN THE COIRE FILES #########################################

numtrigs, found, coincs, search = cache.readTriggerFiles(cp)
missed = None

if opts.trig_bank: trigbank_test = 1
else: trigbank_test = 0  
followuptrigs = getfollowuptrigs(numtrigs,page,coincs,missed,search,trigbank_test)

print "\n.......Found " + str(len(followuptrigs)) + " trigs to follow up" 

############ SET UP THE REQUESTED JOBS ########################################

inspJob        = followUpInspJob(cp)
plotJob        = plotSNRCHISQJob(opts,cp)
dataJob        = qscanDataFindJob('datafind_cache','logs',cp,'futrig')
qscanFgJob     = qscanJob(opts,cp)
qscanBgJob     = qscanLiteJob(opts,cp)


prev_dNode = None
prev_dHoftNode = None

print "\n.......Setting up pipeline jobs"

dq_url_pattern = "http://ldas-cit.ligo.caltech.edu/segments/S5/%s/dq_segments.txt"

segFile = {}
ifos_list = ['H1','H2','L1','G1','V1','T1']


############# LOOP OVER RANDOM BACKGROUND TIMES ###############################
###############################################################################
# Prepare the qscan background
for ifo in ifos_list:
  times = getQscanBackgroundTimes(cp,opts,ifo, dq_url_pattern,segFile)
  for time in times:
    # SETUP DATAFIND JOBS FOR BACKGROUND QSCANS (REGULAR DATA SET)
    dNode = qscanDataFindNode(dataJob,'futrig','q-datafind',cp,time,ifo, opts, prev_dNode, dag)

    # SETUP DATAFIND JOBS FOR BACKGROUND QSCANS (HOFT)
    dHoftNode = qscanDataFindNode(dataJob,'futrig','q-hoft-datafind',cp,time,ifo,opts,prev_dHoftNode,dag)
    
      # SETUP BACKGROUND QSCAN JOBS
    qBgNode = qscanNode(qscanBgJob,time,cp,dHoftNode.outputFileName,ifo,'background-qscan-hoft',opts,dHoftNode,dag,'hoft_datafind','background_hoft_qscan')
    qBgNode = qscanNode(qscanBgJob,time,cp,dNode.outputFileName,ifo,'background-qscan',opts, dNode, dag,'datafind','background_qscan')
    qBgNode = qscanNode(qscanBgJob,time,cp,dNode.outputFileName,ifo,'background-qscan-seismic',opts, dNode, dag,'datafind','background_seis_qscan')


################# LOOP OVER FOLLOWUP TRIGGERS #################################
###############################################################################
prev_plotnode = None
# Prepare the followup jobs
for trig in followuptrigs:

  #Lets make a new section for this event
  dag.appendSection('Trigger ID = '+str(trig.eventID)+ ' Stat = '+str(trig.statValue))  

  # TRY GETTING INSPIRAL PROCESS PARAMS... 
  # currently done even when inspiral jobs are not requested... fix?
  inspiral_process_params = cache.processFollowupCache(cp, opts, trig)

  # loop over ifos
  for ifo in trig.ifolist_in_coinc:
    
    try: trig.gpsTime[ifo]
    except: continue
    
    #Lets append a new subsection to the last section
    dag.appendSubSection(str(ifo)+' @ GPS '+str(trig.gpsTime[ifo]))

    # SETUP DATAFIND JOBS FOR HOFT QCANS
    dHoftNode = qscanDataFindNode(dataJob,'futrig','q-hoft-datafind',cp,trig.gpsTime[ifo],ifo,opts, prev_dHoftNode, dag)

    # SETUP DATAFIND JOBS FOR REGULAR QCANS
    dNode = qscanDataFindNode(dataJob,'futrig','q-datafind',cp,trig.gpsTime[ifo],ifo,opts, prev_dNode, dag)
    
    # SETUP FOREGROUND QSCAN JOBS
    qFgNode = qscanNode(qscanFgJob,trig.gpsTime[ifo],cp,dHoftNode.outputFileName,ifo,'qscan-hoft',opts,dHoftNode,dag,'hoft_datafind','hoft_qscan',trig)
    qFgNode = qscanNode(qscanFgJob,trig.gpsTime[ifo],cp,dNode.outputFileName,ifo,'qscan',opts,dNode,dag,'datafind','qscan',trig)
    qFgNode = qscanNode(qscanFgJob,trig.gpsTime[ifo],cp,dNode.outputFileName,ifo,'qscan-seismic',opts,dNode,dag,'datafind','seis_qscan',trig)

    # SETUP INSPIRAL JOBS
    inspiralNode = followUpInspNode(inspJob,inspiral_process_params[ifo], ifo, trig, cp, opts, dag)

    # SETUP PLOT JOBS
    plotNode = plotSNRCHISQNode(plotJob,ifo,inspiralNode.output_file_name,trig,page,dag,inspiralNode,opts,prev_plotnode)


# MOVE THIS INTO A DAG CLASS, THIS IS USEFUL FOR MORE THAN JUST QSCANS
# Write out the cache files for the various output data
###############################################################################

if opts.qscan or opts.background_qscan or opts.hoft_qscan or opts.background_hoft_qscan or opts.seis_qscan or opts.background_seis_qscan:

  qscan_cache = qscanCache()
  for node in dag.get_nodes():
    if isinstance(node,qscanNode):
      qscan_cache.addLine(node)
    else: continue
  qscan_cache.writeCache()


##########################################################################
dag.writeAll()
if opts.write_to_iulgroup:
  dag.publishToHydra()

sys.exit(0)

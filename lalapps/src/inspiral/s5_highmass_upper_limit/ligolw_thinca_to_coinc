#!/usr/bin/python
#
# $Id: ligolw_thinca_to_coinc,v 1.42 2009/03/08 21:28:42 kipp Exp $
#
# Copyright (C) 2006  Kipp C. Cannon
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.


#
# =============================================================================
#
#                                   Preamble
#
# =============================================================================
#


"""
Translate thinca-style sngl_inspiral coincs to coinc-tables-style coincs.
"""


import itertools
import math
from optparse import OptionParser
import sys
import re


from glue import iterutils
from glue import lal
from glue import segments
from glue.ligolw import ligolw
from glue.ligolw import table
from glue.ligolw import lsctables
from glue.ligolw import utils
from glue.ligolw.utils import ligolw_add
from glue.ligolw.utils import segments as ligolw_segments
from glue.ligolw.utils import process as ligolw_process
from pylal import llwapp
from pylal import ligolw_thinca
from pylal import ligolw_tisi
from pylal import SnglInspiralUtils


__author__ = "Kipp Cannon <kipp@gravity.phys.uwm.edu>"
__version__ = "$Revision: 1.42 $"[11:-2]
__date__ = "$Date: 2009/03/08 21:28:42 $"[7:-2]


#
# =============================================================================
#
#                                 Command Line
#
# =============================================================================
#


def parse_command_line():
	parser = OptionParser(
		version = "%prog CVS $Id: ligolw_thinca_to_coinc,v 1.42 2009/03/08 21:28:42 kipp Exp $",
		usage = "%prog [options] --output filename",
		description = "Converts thinca output files to coinc tables format.  Files whose names end in \".gz\" are assumed to be gzip-compressed."
	)
	parser.add_option("--zero-lag-file", help = "Thinca output file containing zero lag triggers.")
	parser.add_option("--time-slide-file", help = "Thinca output file containing time slide triggers.")
	parser.add_option("--ihope-cache", help = "Get thinca files from this ihope cache.")
	parser.add_option("--cache-description-expression", help = "Description string to look for, example EOBNRINJ or FULL_DATA")
	parser.add_option("--output", help = "Output file name (required).")
	parser.add_option("--veto-segments", help = "Load veto segments from this XML document.  See ligolw_segments for information on constructing such a document.")
	parser.add_option("--veto-segments-name", help = "Set the name of the veto segments to use from the XML document.")
	parser.add_option("-v", "--verbose", action = "store_true", help = "Be verbose.")
	options, args = parser.parse_args()

	if options.ihope_cache:
		if not options.cache_description_expression:
			raise ValueError, "must provide --cache-description-expression"
		else: cdexp = options.cache_description_expression
		if options.zero_lag_file or options.time_slide_file:
			raise ValueError, "cannot specify --zero-lag-file or --time-slide-file with --ihope-cache"
		if options.verbose:
			print >>sys.stderr, "reading %s ..." % options.ihope_cache
		# find CAT3 full data cache entries
		url_pairs = [c for c in map(lal.CacheEntry, file(options.ihope_cache)) if cdexp in c.description and "CAT_3" in c.description]
		#url_pairs = [c for c in map(lal.CacheEntry, file(options.ihope_cache)) if "FULL_DATA" in c.description and "CAT_3" in c.description]
		# separate zero-lag and slides files
		zero_lag_urls = [c.url for c in sorted(c for c in url_pairs if "THINCA_SECOND" in c.description)]
		slide_urls = [c.url for c in sorted(c for c in url_pairs if "THINCA_SLIDE_SECOND" in c.description)]
		# pad both lists with None's so they have the same number
		# of entries
		zero_lag_urls += [None,] * (max(len(zero_lag_urls), len(slide_urls)) - len(zero_lag_urls))
		slide_urls += [None,] * (max(len(zero_lag_urls), len(slide_urls)) - len(slide_urls))
		# match up each zero-lag url with corresponding slides url
		url_pairs = zip(zero_lag_urls, slide_urls)
	else:
		if not (options.zero_lag_file or options.time_slide_file):
			raise ValueError, "must specify --ihope-cache or at least one of --zero-lag-file and --time-slide-file"
		url_pairs = (options.zero_lag_file, options.time_slide_file)
	if not options.output:
		raise ValueError, "must specify --output"
	if options.veto_segments and not options.veto_segments_name:
		raise ValueError, "must specify --veto-segments-name if --veto-sements is specified"

	if args:
		raise ValueError, "extraneous command line arguments specified"

	return options, url_pairs


#
# =============================================================================
#
#                             Process Information
#
# =============================================================================
#


#
# create and initialize this job's row in the process table
#


def initialize_process(xmldoc, comment = u""):
	return llwapp.append_process(xmldoc, program = u"ligolw_thinca_to_coinc", version = __version__, cvs_repository = u"lscsoft", cvs_entry_time = __date__, comment = comment)


#
# record command line arguments
#


def set_process_params(xmldoc, process, options):
	params = []
	if options.zero_lag_file:
		params.append((u"--zero-lag-file", u"lstring", options.zero_lag_file))
	if options.time_slide_file:
		params.append((u"--time-slide-file", u"lstring", options.time_slide_file))
	params.append((u"--output", u"lstring", options.output))

	ligolw_process.append_process_params(xmldoc, process, params)

	return xmldoc


#
# =============================================================================
#
#                               Document Fix-Up
#
# =============================================================================
#


#
# add missing ID columns.  this is needed because the cbc 2yr tags are on
# versions of LAL that don't have these columns in the tables.  current
# versions of LAL do.
#


def add_missing_id_columns(xmldoc, verbose = False):
	if verbose:
		print >>sys.stderr, "adding any missing ID columns ...",

	#
	# fix summ_value and search_summ_vars tables
	#

	for name in (lsctables.SummValueTable.tableName, lsctables.SearchSummVarsTable.tableName):
		try:
			tbl = table.get_table(xmldoc, name)
			tbl.appendColumn(tbl.next_id.column_name)
		except ValueError:
			# document doesn't have this table or already has
			# ID column
			continue
		if verbose:
			print >>sys.stderr, name,
		for row in tbl:
			setattr(row, tbl.next_id.column_name, tbl.get_next_id())

	#
	# done
	#

	if verbose:
		print >>sys.stderr


#
# Fix ifos columns by turning strings like "H1H2L1" into strings like
# "H1,H2,L1".
#


def fix_ifos_columns(xmldoc, verbose = False):
	if verbose:
		print >>sys.stderr, "fixing ifos columns ...",

	#
	# fix process and search_summary tables
	#

	for table_name in (lsctables.ProcessTable.tableName, lsctables.SearchSummaryTable.tableName):
		try:
			tbl = table.get_table(xmldoc, table_name)
		except ValueError:
			# document doesn't have this table
			continue
		if options.verbose:
			print >>sys.stderr, table_name,
		for row in tbl:
			row.set_ifos(row.get_ifos())

	#
	# done
	#

	if verbose:
		print >>sys.stderr


#
# =============================================================================
#
#                          Populate time_slide Table
#
# =============================================================================
#


def populate_thinca_time_slide_table(xmldoc, process, verbose = False):
	"""
	Reconstruct the list of time slides from lalapps_thinca's command
	line arguments.
	"""
	if verbose:
		print >>sys.stderr, "populating thinca time_slide table ...",

	#
	# find the time_slide table or add one if needed
	#

	try:
		time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)
	except ValueError:
		time_slide_table = lsctables.New(lsctables.TimeSlideTable)
		xmldoc.childNodes[0].appendChild(time_slide_table)

	#
	# move existing time_slide IDs out of the way
	#

	# find the lowest unused ID not less than 10000 and set next_id to
	# that value
	time_slide_table.sync_next_id()
	if time_slide_table.next_id < type(time_slide_table.next_id)(10000):
		time_slide_table.set_next_id(type(time_slide_table.next_id)(10000))
	# use the updateKeyMapping method to re-label all existing
	# time_slide IDs and record the old-->new mapping
	mapping = {}
	time_slide_table.updateKeyMapping(mapping)
	# apply the mapping to all other tables in the document to update
	# any references to existing time_slide IDs
	for tbl in xmldoc.getElementsByTagName(time_slide_table.tagName):
		tbl.applyKeyMapping(mapping)

	#
	# get process_ids for all thinca jobs, and for thinca jobs that
	# were run with a --num-slides command line option
	#

	thinca_process_ids = table.get_table(xmldoc, lsctables.ProcessTable.tableName).get_ids_by_program("thinca")
	slides_process_ids = thinca_process_ids & set(row.process_id for row in table.get_table(xmldoc, lsctables.ProcessParamsTable.tableName) if row.param == u"--num-slides")

	if len(thinca_process_ids - slides_process_ids) > 1:
		raise ValueError, "document contains more than 1 zero-lag thinca job"
	if len(slides_process_ids) > 1:
		raise ValueError, "document contains more than 1 non-zero-lag thinca job"

	#
	# identify the instrument names in play from the search_summary
	# table
	#

	instruments = set(frozenset(row.get_ifos()) for row in table.get_table(xmldoc, lsctables.SearchSummaryTable.tableName) if row.process_id in thinca_process_ids)
	if len(instruments) < 1:
		raise ValueError, "cannot find entries for thinca jobs in search_summary table"
	if len(instruments) > 1:
		raise ValueError, "search_summary table contains entries for thinca jobs from more than 1 unique set of instruments:  found %s" % ", ".join(instruments)
	instruments = instruments.pop()

	#
	# identify lalapps_thinca's time slides
	#

	if not slides_process_ids:
		#
		# just zero-lag jobs.  synthesize an all-zero vector from
		# the instruments we've retrieved from the search_summary
		# table, and set num_slides to 0
		#

		offset_vector = dict((instrument, 0.0) for instrument in instruments)
		num_slides = 0

	else:
		#
		# construct the offset vector from the --??-slide command
		# line options, and extact num_slides from the --num-slides
		# command line option
		#

		num_slides = None
		offset_vector = {}
		slide_option_pattern = re.compile("--(?P<ifo>[a-zA-Z][0-9])-slide")

		for row in table.get_table(xmldoc, lsctables.ProcessParamsTable.tableName):
			if row.process_id in slides_process_ids:
				if row.param == u"--num-slides":
					num_slides = row.get_pyvalue()
					if num_slides < 0:
						raise ValueError, "invalid --num-slides '%s' for process '%s'" % (row.value, row.process_id)
				else:
					match = re.search(slide_option_pattern, row.param)
					if match is not None:
						offset_vector[match.groupdict()["ifo"].upper()] = row.get_pyvalue()

		#
		# confirm that the offset vector contains offsets for all
		# the instruments named in the search_summary table
		# entries.
		#

		if not instruments.issubset(set(offset_vector.keys())):
			missing_instruments = set(offset_vector.keys()) - instruments
			raise ValueError, "cannot find thinca command line option(s) %s in process_params table for instrument(s) %s found in search_summary table" % (", ".join(["--%s-slide" % instrument.lower() for instrument in missing_instruments]), ", ".join(missing_instruments))

	#
	# build the time slide vectors for the cases when all instruments
	# are on.  these must be given time_slide IDs that match the slide
	# number component of the old-style event_id
	#

	def ids(id_class, num_slides):
		for n in range(-num_slides, +num_slides + 1):
			if n < 0:
				yield id_class(5000 - n)
			else:
				yield id_class(n)

	n = 0
	for id, offset_vector in zip(ids(type(time_slide_table.next_id), num_slides), ligolw_tisi.Inspiral_Num_Slides_Iter(num_slides, offset_vector)):
		n += 1
		for row in ligolw_tisi.RowsFromOffsetDict(offset_vector, id, process):
			time_slide_table.append(row)

	#
	# done
	#

	if verbose:
		print >>sys.stderr, "added %d time slide vectors" % n


def depopulate_time_slide_table(xmldoc, verbose = False):
	"""
	Search for and remove duplicate time slide definitions from the
	time_slide table.
	"""
	if verbose:
		print >>sys.stderr, "depopulating time_slides ...",

	#
	# find the time_slide table
	#

	time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)

	length_before = len(set(time_slide_table.getColumnByName("time_slide_id")))

	#
	# translate time_slide table into a dictionary, and identify
	# redundant IDs
	#
	# NOTE:  the time slide vector comparison code treats {"H1": 0,
	# "L1": 5} and {"H1": 10, "L1": 15} as identical vectors because
	# the relative offsets are identical.  in the inspiral pipeline,
	# these are potentially different time slides because one of the
	# two can result in the pair of triggers straddling a ring boundary
	# while the other does not, so a trigger pair can be coincident for
	# one of these vectors but not the other.  this should never be an
	# issue because the pipeline also has the limitation of only being
	# able to apply vectors that are all multiples of a fixed basis
	# vector --- if two instruments have the same relative offsets in
	# two vectors then they must also have the same absolute offsets in
	# those vectors, so comparing by relative offsets yields the same
	# set of redundant vectors that a comparison by absolute offsets
	# would yield.  the use of the time_slides_vacuum() function here
	# is correct, but one should keep the reason why in mind if one is
	# tempted to copy-and-paste this code elsewhere.
	#

	mapping = ligolw_tisi.time_slides_vacuum(time_slide_table.as_dict())

	#
	# remove rows corresponding to redundant IDs
	#

	for i in xrange(len(time_slide_table) - 1, -1, -1):
		if time_slide_table[i].time_slide_id in mapping:
			del time_slide_table[i]

	#
	# reassign time_slide IDs in the rest of the document
	#

	for tbl in xmldoc.getElementsByTagName(time_slide_table.tagName):
		tbl.applyKeyMapping(mapping)

	#
	# done
	#

	if verbose:
		length_after = len(set(time_slide_table.getColumnByName("time_slide_id")))
		print >>sys.stderr, "removed %d redundant time slide vectors, %d remaining" % (length_before - length_after, length_after)


#
# =============================================================================
#
#       Populate coinc_event, coinc_event_map, and coinc_inspiral Tables
#
# =============================================================================
#


#
# retrieve the ring boundaries
#


def retrieve_ring_boundaries(xmldoc):
	#
	# grab the segment list for any instrument selected at random (they
	# are all the same)
	#

	rings = llwapp.segmentlistdict_fromsearchsummary(xmldoc, program = "thinca").popitem()[1]

	#
	# because the input often contains two thinca jobs the rings might
	# be duplicated;  use set() to uniqueify them then sort them.
	#

	rings = segments.segmentlist(set(rings))
	rings.sort()

	#
	# check that the (sorted) rings are non-intersecting
	#

	for i in range(len(rings) - 1):
		if rings[i].interesects(rings[i + 1]):
			raise ValueError, "non-disjoint thinca rings detected in search_summary table"

	#
	# done
	#

	return rings


#
# For sngl_inspiral <--> sngl_inspiral coincidences
#


def populate_coinc_event_sngls(xmldoc, process, verbose = False):
	if verbose:
		print >>sys.stderr, "constructing coincs ...",

	#
	# retrieve the ring boundaries
	#

	rings = retrieve_ring_boundaries(xmldoc)

	#
	# find the coinc_definer_id for sngl_inspiral <--> sngl_inspiral
	# coincidences, or create it if needed
	#

	coinc_def_id = llwapp.get_coinc_def_id(xmldoc, ligolw_thinca.InspiralCoincDef.search, ligolw_thinca.InspiralCoincDef.search_coinc_type, create_new = True, description = ligolw_thinca.InspiralCoincDef.description)

	#
	# find the coinc_event table or create one if needed
	#

	try:
		coinc_event_table = table.get_table(xmldoc, lsctables.CoincTable.tableName)
	except ValueError:
		coinc_event_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.CoincTable))

	#
	# synchronize the coinc_event table's ID generator with any
	# pre-existing rows
	#

	coinc_event_table.sync_next_id()

	#
	# find the coinc_event_map table or create one if needed
	#

	try:
		coinc_event_map_table = table.get_table(xmldoc, lsctables.CoincMapTable.tableName)
	except ValueError:
		coinc_event_map_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.CoincMapTable))

	#
	# find the coinc_inspiral table or create one if needed
	#

	try:
		coinc_inspiral_table = table.get_table(xmldoc, lsctables.CoincInspiralTable.tableName)
	except ValueError:
		coinc_inspiral_table = xmldoc.childNodes[0].appendChild(lsctables.New(lsctables.CoincInspiralTable))

	#
	# find the sngl_inspiral table
	#

	try:
		sngl_inspiral_table = table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
	except ValueError:
		# no sngl_inspiral table --> no-op
		if verbose:
			print >>sys.stderr, "cannot find sngl_inspiral table"
		return

	#
	# find the time_slide table, and convert it to a dictionary of
	# offset vectors
	#

	time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)
	time_slides = time_slide_table.as_dict()

	#
	# iterate over reconstructed coincs
	#

	sngl_inspiral_table.sort(lambda a, b: cmp(a.event_id, b.event_id))
	for event_id, events in itertools.groupby(sngl_inspiral_table, lambda row: row.event_id):
		#
		# alphabetize events by instrument
		#

		events = tuple(sorted(events, lambda a, b: cmp(a.ifo, b.ifo)))
		if len(events) < 2:
			# not a coincidence, just a single.  assign a new,
			# unique, event_id and continue.
			for event in events:
				event.event_id = sngl_inspiral_table.get_next_id()
			continue

		#
		# build a coinc_event
		#

		coinc = lsctables.Coinc()
		coinc.process_id = process.process_id
		coinc.coinc_event_id = coinc_event_table.get_next_id()
		coinc.coinc_def_id = coinc_def_id
		coinc.nevents = len(events)
		coinc.likelihood = None
		coinc_event_table.append(coinc)

		#
		# construct the time_slide_id from the "slide number" at
		# index 1 in the tuple returned by get_id_parts().  all
		# events in the coinc have the same ID at this stage so it
		# doesn't matter which event's ID we use.  we also use the
		# instruments named in the time slide vector to populate
		# the initial list of instruments for this coinc.  the
		# instrument list might be updated later when vetos are
		# applied.
		#

		coinc.time_slide_id = type(time_slide_table.next_id)(events[0].get_id_parts()[1])
		coinc.set_instruments(time_slides[coinc.time_slide_id].keys())

		#
		# link events to coinc with coinc_event_map rows.  the
		# inspiral triggers are assigned new, unique, event IDs
		# here.
		#

		for event in events:
			coincmap = lsctables.CoincMap()
			coincmap.coinc_event_id = coinc.coinc_event_id
			coincmap.event_id = event.event_id = sngl_inspiral_table.get_next_id()
			coincmap.table_name = coincmap.event_id.table_name
			coinc_event_map_table.append(coincmap)

		#
		# populate coinc_inspiral table with coinc summary:
		#
		# - end_time is the end time of the first trigger in
		#   alphabetical order by instrument (!?) time-shifted
		#   according to the coinc's offset vector
		# - mchirp is average of mchirps
		# - snr is root-sum-square of SNRs
		# - false-alarm rate is blank
		#

		coinc_inspiral = lsctables.CoincInspiral()
		coinc_inspiral.coinc_event_id = coinc.coinc_event_id
		coinc_inspiral.set_ifos(str(event.ifo) for event in events)
		coinc_inspiral.mchirp = sum(event.mchirp for event in events) / len(events)
		coinc_inspiral.snr = math.sqrt(sum(event.snr**2 for event in events))
		coinc_inspiral.false_alarm_rate = None

		#
		# the time of the coinc = the end time of the first trigger
		# in the coinc in alphabetical order by instrument
		#

		coinc_time = events[0].get_end()

		#
		# which ring is it in?
		#

		ring = rings[rings.find(coinc_time)]

		#
		# the amount by which to slide it = the offset recorded in
		# the time_slide table for the instrument from which the
		# coinc's time has been taken
		#

		offset = time_slides[coinc.time_slide_id][events[0].ifo]

		#
		# slide the coinc's time on the ring.
		#

		coinc_inspiral.set_end(SnglInspiralUtils.slideTimeOnRing(coinc_time, offset, ring))

		coinc_inspiral_table.append(coinc_inspiral)

	#
	# done
	#

	if verbose:
		print >>sys.stderr, "constructed %d coincs" % len(coinc_event_table)


#
# =============================================================================
#
#                        Depopulate sngl_inspiral Table
#
# =============================================================================
#


def depopulate_sngl_inspiral(xmldoc, verbose = False):
	if verbose:
		print >>sys.stderr, "depopulating sngl_inspirals ...",

	#
	# find the sngl_inspiral table
	#

	try:
		sngl_inspiral_table = table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
	except ValueError:
		# no sngl_inspiral table --> no-op
		if verbose:
			print >>sys.stderr, "cannot find sngl_inspiral table"
		return

	length_before = len(sngl_inspiral_table)

	#
	# delete duplicates, recording replacement event_ids.  this relies
	# on the SnglInspiral class' __eq__() and __hash__() methods to
	# define when two triggers are the same
	#

	trigger_to_id_index = {}
	mapping = {}
	for i in xrange(len(sngl_inspiral_table) - 1, -1, -1):
		trigger = sngl_inspiral_table[i]
		if trigger in trigger_to_id_index:
			mapping[trigger.event_id] = trigger_to_id_index[trigger]
			del sngl_inspiral_table[i]
		else:
			trigger_to_id_index[trigger] = trigger.event_id

	#
	# update IDs in other tables
	#

	for tbl in xmldoc.getElementsByTagName(sngl_inspiral_table.tagName):
		tbl.applyKeyMapping(mapping)

	#
	# done
	#

	if verbose:
		print >>sys.stderr, "removed %d redundant sngl_inspiral events, %d remaining" % (length_before - len(sngl_inspiral_table), len(sngl_inspiral_table))


#
# =============================================================================
#
#                                 Apply Vetoes
#
# =============================================================================
#


def apply_vetoes(xmldoc, veto_segments, process, verbose = False):
	if verbose:
		print >>sys.stderr, "applying vetoes ..."

	#
	# find the tables we'll need
	#

	try:
		sngl_inspiral_table = table.get_table(xmldoc, lsctables.SnglInspiralTable.tableName)
	except ValueError:
		# no sngl_inspiral table --> no-op
		if verbose:
			print >>sys.stderr, "\tcannot find sngl_inspiral table"
		return
	coinc_table = table.get_table(xmldoc, lsctables.CoincTable.tableName)
	coinc_map_table = table.get_table(xmldoc, lsctables.CoincMapTable.tableName)
	coinc_inspiral_table = table.get_table(xmldoc, lsctables.CoincInspiralTable.tableName)
	time_slide_table = table.get_table(xmldoc, lsctables.TimeSlideTable.tableName)

	#
	# turn the time slide table into a dictionary
	#

	if verbose:
		print >>sys.stderr, "\tindexing time_slide table and computing segment lists ..."
	time_slides = time_slide_table.as_dict()

	#
	# retrieve the ring boundaries
	#

	rings = retrieve_ring_boundaries(xmldoc)

	#
	# performance assist:  remove veto segments that don't fall in any
	# of the rings, then remove veto segment lists that are empty
	#

	coalesced_rings = segments.segmentlist(rings).coalesce()
	veto_segments = segments.segmentlistdict((instrument, seglist & coalesced_rings) for (instrument, seglist) in veto_segments.items() if seglist.intersects(coalesced_rings))
	if not veto_segments:
		if verbose:
			print >>sys.stderr, "\tno vetos were on during the times spanned by this document"
		return

	#
	# create the coinc_event_id --> sngl_inspiral index, and
	# coinc_event_id --> coinc_inspiral index
	#

	if verbose:
		print >>sys.stderr, "\tindexing coinc tables ..."
	index = dict((row.event_id, row) for row in sngl_inspiral_table)

	coinc_map_table.sort(lambda a, b: cmp(a.coinc_event_id, b.coinc_event_id))
	index = dict(
		(coinc_event_id, tuple(index[row.event_id] for row in rows))
		for coinc_event_id, rows in itertools.groupby(
			(row for row in coinc_map_table if row.table_name == "sngl_inspiral"),
			lambda row: row.coinc_event_id
		)
	)

	coinc_inspirals = dict((row.coinc_event_id, row) for row in coinc_inspiral_table)

	#
	# iterate over coincs
	#

	if verbose:
		print >>sys.stderr, "\tchecking for coincs during vetoed times ..."

	cached_vetoes = {}
	N = len(coinc_table) / 1000 or 1

	for n, coinc_event in enumerate(coinc_table):
		if verbose and not (n % N):
			print >>sys.stderr, "\t\t%.1f%%\r" % (100.0 * n / len(coinc_table)),

		if coinc_event.coinc_event_id not in index:
			#
			# not a coinc we care about
			#

			continue

		#
		# retrieve the time slide vector
		#

		offset_vector = time_slides[coinc_event.time_slide_id]

		#
		# compare the instruments participating in the coinc to the
		# instruments named in the time slide vector
		#

		expected_instruments = set(offset_vector.keys())
		found_instruments = set(event.ifo for event in index[coinc_event.coinc_event_id])

		if found_instruments == expected_instruments:
			#
			# all instruments contributed to this coinc:
			# nothing more to check
			#

			continue

		if not found_instruments.issubset(expected_instruments):
			raise ValueError, "coinc '%s' has instrument(s) %s that are not in time slide vector '%s' (%s)" % (coinc_event.coinc_event_id, ", ".join(found_instruments - expected_instruments), coinc_event.time_slide_id, ", ".join(["%s=%g" % item for item in offset_vector.items()]))

		#
		# if we get here, the time shift vector names instruments
		# that did not particicpate in the coinc.  check to see
		# which instruments were on at the time
		#

		#
		# the slid time of the coinc
		#

		coinc_time = coinc_inspirals[coinc_event.coinc_event_id].get_end()

		#
		# which ring is it in?  note:  although the time recorded
		# for the coinc is its time after offsets are applied to
		# triggers, that time is always in the same ring as the
		# original time of the trigger from which the coinc's time
		# has been taken
		#

		ring = rings[rings.find(coinc_time)]

		#
		# slide the veto segments on that ring, cache the results
		# to avoid recalculation
		#

		try:
			vetoes = cached_vetoes[(ring, coinc_event.time_slide_id)]
		except KeyError:
			vetoes = cached_vetoes[(ring, coinc_event.time_slide_id)] = SnglInspiralUtils.slideSegListDictOnRing(ring, veto_segments, offset_vector)

		#
		# set the coinc's instruments to just those that were on at
		# the time of the coinc
		#

		on_instruments = set(instrument for instrument in offset_vector.keys() if instrument not in vetoes or coinc_time not in vetoes[instrument])
		if not found_instruments.issubset(on_instruments):
			# FIXME:  thinca finds, for example, triples in
			# double time.  this is mostly a bug in the
			# definition of what it is that thinca does, but
			# thinca_to_coinc must know what thinca does in
			# order to reconstruct the metadata.  We can't do
			# that correctly right now, but to make progress
			# this is just a warning instead of an error.
			if verbose:
				print >>sys.stderr, "warning: coinc '%s' has instrument(s) %s that were off or vetoed at the slid coinc time %s" % (coinc_event.coinc_event_id, ", ".join(found_instruments - on_instruments), str(coinc_time))
			#raise ValueError, "coinc '%s' has instrument(s) %s that were off or vetoed at the slid coinc time %s" % (coinc_event.coinc_event_id, ", ".join(found_instruments - on_instruments), str(coinc_time))

		coinc_event.set_instruments(on_instruments)

	if verbose:
		print >>sys.stderr, "\t\t100.0%"


#
# =============================================================================
#
#                                     Main
#
# =============================================================================
#


options, url_pairs = parse_command_line()

if options.veto_segments:
	options.veto_segments = ligolw_segments.segmenttable_get_by_name(utils.load_filename(options.veto_segments, gz = (options.veto_segments or "stdin").endswith(".gz"), verbose = options.verbose), options.veto_segments_name).coalesce()


for n, url_pair in enumerate(url_pairs):
	#FIXME A HACK TO MAKE IT GO FASTER FOR TESTING, DOESNT PROCESS ALL THE FILES
	if n > 10: break
	lsctables.SnglInspiralTable.next_id = None
	xmldoc = ligolw_add.ligolw_add(ligolw.Document(), [url for url in url_pair if url], verbose = options.verbose)
	lsctables.SnglInspiralTable.next_id = lsctables.SnglInspiralID(0)

	process = initialize_process(xmldoc)
	set_process_params(xmldoc, process, options)

	add_missing_id_columns(xmldoc, verbose = options.verbose)
	# FIXME:  uncomment this after Kipp talks people into it.
	#fix_ifos_columns(xmldoc, verbose = options.verbose)

	populate_thinca_time_slide_table(xmldoc, process, verbose = options.verbose)

	populate_coinc_event_sngls(xmldoc, process, verbose = options.verbose)

	depopulate_sngl_inspiral(xmldoc, verbose = options.verbose)

	if options.veto_segments:
		apply_vetoes(xmldoc, options.veto_segments, process, verbose = options.verbose)
	elif options.verbose:
		print >>sys.stderr, "no vetoes applied"

	depopulate_time_slide_table(xmldoc, verbose = options.verbose)

	llwapp.set_process_end_time(process)

	output = "%05d_%s" % (n, options.output)
	utils.write_filename(xmldoc, output, verbose = options.verbose, gz = (output or "stdout").endswith(".gz"))
